[ { "title": "Rust 단일 파일 실행하기", "url": "/posts/Rust_Execute/", "categories": "Rust, 설치", "tags": "Rust, Linux, VSCode, 설치", "date": "2023-01-06 22:00:00 +0900", "snippet": "" }, { "title": "Rust 설치 및 VS Code 셋팅(Linux, Debian)", "url": "/posts/Rust_Install/", "categories": "Rust, 설치", "tags": "Rust, Linux, VSCode, 설치", "date": "2023-01-06 22:00:00 +0900", "snippet": "소개최근 Rust에 관심이 생겨 Rust를 공부하고 있습니다.제가 집에서 사용하는 PC는 Mint Linux로 Debian 계열의 리눅스를 사용하고 있습니다.Linux에 Rust를 설치하는 방법과 VS Code에서 Rust를 사용하는 방법에 대해 정리하겠습니다.Rust 설치리눅스에서 Rust를 설치하는 방법은 3가지가 있습니다. rustup 사용 : 공식 사이트에서 가장 추천하는 방법 입니다. 패키지 매니저 사용 : 편리하지만 오래 된 버전의 Rust가 설치 됩니다. 직접 소스코드 빌드 : 특이한 경우가 아니라면 비추입니다.저는 이 중 가장 추천하는 rustup을 사용하여 설치하겠습니다.Rustup으로 설치하기먼저 터미널을 실행 시킵니다.(Ctrl + Alt + T)아래 명령어를 사용합니다.bak:~$ curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | shinfo: downloading installerWelcome to Rust!This will download and install the official compiler for the Rustprogramming language, and its package manager, Cargo.Rustup metadata and toolchains will be installed into the Rustuphome directory, located at: /home/bak/.rustupThis can be modified with the RUSTUP_HOME environment variable.The Cargo home directory is located at: /home/bak/.cargoThis can be modified with the CARGO_HOME environment variable.The cargo, rustc, rustup and other commands will be added toCargo's bin directory, located at: /home/bak/.cargo/binThis path will then be added to your PATH environment variable bymodifying the profile files located at: /home/bak/.profile /home/bak/.bashrcYou can uninstall at any time with rustup self uninstall andthese changes will be reverted.Current installation options: default host triple: x86_64-unknown-linux-gnu default toolchain: stable (default) profile: default modify PATH variable: yes1) Proceed with installation (default)2) Customize installation3) Cancel installation1위와 같은 글씨가 출력되면 1 을 입력한다.info: profile set to 'default'info: default host triple is x86_64-unknown-linux-gnuinfo: syncing channel updates for 'stable-x86_64-unknown-linux-gnu'info: latest update on 2022-12-15, rust version 1.66.0 (69f9c33d7 2022-12-12)info: downloading component 'cargo'info: downloading component 'clippy'info: downloading component 'rust-docs'info: downloading component 'rust-std'info: downloading component 'rustc' 68.0 MiB / 68.0 MiB (100 %) 55.3 MiB/s in 1s ETA: 0sinfo: downloading component 'rustfmt'|-|-|info: installing component 'rust-std' 29.7 MiB / 29.7 MiB (100 %) 14.0 MiB/s in 2s ETA: 0sinfo: installing component 'rustc' 68.0 MiB / 68.0 MiB (100 %) 15.5 MiB/s in 4s ETA: 0sinfo: installing component 'rustfmt'info: default toolchain set to 'stable-x86_64-unknown-linux-gnu' stable-x86_64-unknown-linux-gnu installed - rustc 1.66.0 (69f9c33d7 2022-12-12)Rust is installed now. Great!To get started you may need to restart your current shell.This would reload your PATH environment variable to includeCargo's bin directory ($HOME/.cargo/bin).To configure your current shell, run:source \"$HOME/.cargo/env\"위와 같이 cargo나 rustc 등등 필요한 패키지들이 설치 된다.위 이야기를 보면 최근 shell을 다시 시작하라고 나온다. 그래서 설치한 터미널에서는 rustc를 입력해도 찾을수 없다고 나온다.bak:~$ rustc --version명령어 'rustc' 을(를) 찾을 수 없습니다. 그러나 다음을 통해 설치할 수 있습니다:sudo apt install rustc새로운 터미널을 열어 다시 입력하면 아래와 같이 정상적으로 출력되는 것을 알 수 있다.bak:~$ rustc --versionrustc 1.66.0 (69f9c33d7 2022-12-12)rust는 아래와 같이 세 가지 명령행 도구가 있습니다. 도구 설명 cargo 전체 크레이트를 관리합니다. rustup 러스트 설치를 관리합니다. rustc 러스트 소스 코드의 컴파일을 관리합니다. Rust 완전 삭제 방법삭제하는 방법은 간단 한데 아래와 같이 명령어만 입력하면 환경변수까지 모두 삭제가 된다.bak:~$ rustup self uninstallVS Code에서 Rust 디버깅VS Code에서 Rust를 개발하기 위해서는 아래와 같이 세 가지 extension을 설치해주면 좋습니다. VS code Install Rust Extension 설명 rust-analyzer rust의 자동완성, 구문강조 등 어시스트 기능 CodeLLDB 디버깅을 하기 위해 필요합니다. Better TOML Rust의 설정 파일인 TOML 파일을 지원합니다. hello-world 만들기rust는 cargo를 사용해서 프로젝트를 생성합니다.bak:~$ cargo new hello_worldCreated binary (application) `hello_world` packageVS Code로 rust를 실행시키기 위해서는 프로젝트가 VS code의 root 디렉터리가 되어야 합니다.그래서 아래와 같이 해당 프로젝트로 들어가 VS Code를 실행시켜야 합니다.bak:~$ code hello_worldVS Code를 실행시키면 아래와 같이 src 디렉터리에 main.rs 파일이 있는 것을 볼 수 있습니다.디버깅2번째 라인에 Break Point가 찍히는 것을 볼 수 있습니다.여기서 F5를 누르면 launch.json이 셋팅되지 않았다고 하며, 파일을 생성합니다.중요한 것을 지금 launch.json을 만들어도 F5로는 디버깅이 되지 않습니다.왜냐하면 일반 계정의 vscode에서 cargo를 사용하기 위한 셋팅이 되지 않았기 때문입니다.터미널을 띄워 아래와 같이 입력합니다.bak:~$ sudo ln -s /home/your_user_name/.cargo/bin/cargo /bin/cargo저의 사용자 계정은 bak이기 때문에 your_user_name에 bak을 입력하였습니다.이제 다시 F5를 눌러 launch.json을 만들게 되면 아래와 같이 만들어집니다.{ // IntelliSense를 사용하여 가능한 특성에 대해 알아보세요. // 기존 특성에 대한 설명을 보려면 가리킵니다. // 자세한 내용을 보려면 https://go.microsoft.com/fwlink/?linkid=830387을(를) 방문하세요. \"version\": \"0.2.0\", \"configurations\": [ { \"type\": \"lldb\", \"request\": \"launch\", \"name\": \"Debug executable 'hello_world'\", \"cargo\": { \"args\": [ \"build\", \"--bin=hello_world\", \"--package=hello_world\" ], \"filter\": { \"name\": \"hello_world\", \"kind\": \"bin\" } }, \"args\": [], \"cwd\": \"${workspaceFolder}\" }, { \"type\": \"lldb\", \"request\": \"launch\", \"name\": \"Debug unit tests in executable 'hello_world'\", \"cargo\": { \"args\": [ \"test\", \"--no-run\", \"--bin=hello_world\", \"--package=hello_world\" ], \"filter\": { \"name\": \"hello_world\", \"kind\": \"bin\" } }, \"args\": [], \"cwd\": \"${workspaceFolder}\" } ]}참고 https://github.com/rust-lang/vscode-rust/issues/708 https://rust-kr.org/pages/install/" }, { "title": "JWT의 Access Token과 Refresh Token", "url": "/posts/JWT_Refresh/", "categories": "보안, 인증", "tags": "보안, 인증, Token, JWT", "date": "2022-10-28 13:30:00 +0900", "snippet": "소개JWT를 사용하여 로그인을 구현하게 되면 아래와 같은 문제점에 부딪히게 됩니다.Token 방식의 인증은 제 3자에게 탈취 당할 경우 보안에 매우 취약합니다.보안 상의 이유로 Access Token의 만료기간을 짧게 가진다면 사용자는 Token이 만료 될 때마다 매번 로그인을 새롭게 해야합니다.만료기간을 늘리면, Token을 탈취 당했을 때 보안에 더 취약해집니다.유효기간을 짧게 하면서 좋은 방법이 있을까?라는 질문에 답은 바로 Refresh Token을 사용하는 방법 입니다.Access Token과 Refresh Token의 재발급 원리1. 로그인을 하게 되면 Access Token과 Refresh Token을 모두 발급합니다.Refresh Token은 서버쪽에서 DB에 저장하며, 클라이언트 쪽에서는 Access Token과 Refresh Token을 쿠키 또는 웹 스토리지에 저장합니다.2. 사용자가 인증이 필요한 API에 접근한다면 아래와 같이 유효성을 검사 합니다.   Case 동작 1 Access Token과 Refresh Token 모두 만료가 된 경우 다시 로그인 하도록 유도하고 Access/Refresh Token 모두 새로 발급 합니다. 2 Access Token은 만료 됐지만, Refresh Token은 유효 할 경우 Refresh Token을 검증하여, Access Token을 재발급 합니다. 3 Access Token은 유효하지만, Refresh Token이 만료 됐을 경우 Access Token을 검증하여 Refresh Token을 재발급 합니다. 3 Access Token과 Refresh Token 모두 유효 할 경우 정상적으로 사용 가능 합니다. 3. 로그아웃을 하게 되면 Access/Refresh Token을 모두 만료시킵니다.Refresh Token 인증 과정정상적일 때Access Token이 만료 되었을 때참고 https://inpa.tistory.com/entry/WEB-%F0%9F%93%9A-Access-Token-Refresh-Token-%EC%9B%90%EB%A6%AC-feat-JWT" }, { "title": "JWT(Json Web Token)", "url": "/posts/JWT/", "categories": "보안, 인증", "tags": "보안, 인증, Token, JWT", "date": "2022-10-18 13:30:00 +0900", "snippet": "소개개발을 하다 보면 로그인 관련 기능을 만드는 경우가 많습니다.로그인은 쿠키(Cookie), 세션(Sessions) 등으로 많이 구현하는데, 토큰(Token)을 사용하는 방법도 있습니다.토큰을 사용하는 방법 중 JWT를 많이 사용하기에 JWT에 대해 정리하려고 합니다.JWTJWT(JSON Web Token)는 일반적으로 클라이언트(App FrontEnd)와 서버(App BackEnd)간에 정보를 공유하는 데 사용되는 개방형 산업 표준(RFC7519)입니다.JWT는 Token 자체를 정보로 사용하는 Self-Contained 방식이며, 필요한 모든 정보를 Token에 저장하기 때문에 서버와의 커뮤니케이션에서 오버헤드를 최소화 할 수 있습니다.또한 JSON Content(JWT Claim이라고도 함)을 변경 할 수 없도록 암호화(해싱)되어 있습니다.아래는 Google에 로그인하면 Claim/JSON Payload가 포함 된 JWT를 발생합니다.{ \"iss\": \"https://accounts.google.com\", \"azp\": \"1234987819200.apps.googleusercontent.com\", \"aud\": \"1234987819200.apps.googleusercontent.com\", \"sub\": \"10769150350006150715113082367\", \"at_hash\": \"HK6E_P6Dh8Y93mRNtsDB1Q\", \"email\": \"jsmith@example.com\", \"email_verified\": \"true\", \"iat\": 1353601026, \"exp\": 1353604926, \"nonce\": \"0394852-3190485-2490358\", \"hd\": \"example.com\"}JWT 구조JWT는 Base64Url로 인코딩 되어 있고 마침표(.)로 구분 된 세 부분으로 구성되어 있습니다.[header.payload.signature]eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiaWF0IjoxNTE2MjM5MDIyfQ.tM-nO0TjFp-sF0-TYWjXKX_r9jEZvO1YWjKnWfIDWtM Header : Token 유형에 대한 메타데이터와 해당 콘텐츠를 보호하는 데 사용되는 암호화 알고리즘을 포함합니다. Payload(Claim Set) : 사용자의 ID 및 허용 된 권한과 같은 검증 가능한 보안 설명이 포함 되어 있습니다. Signature : Json Payload의 무결성을 확인하는 데 사용할 수 있는 암호화 알고리즘을 통해 생성 된 문자열 입니다.아래 페이지에서 확인 가능 합니다. JWT DebuggerHeader암호화 작업을 설명하는 매개변수가 포함 된 JSON 객체 입니다.사용 중인 알고리즘과 Type을 기술합니다.{ \"alg\": \"HS256\", \"type\": \"JWT\"}[JSON 객체]Base64URLSafe(UTF-8('{\"alg\": \"HS256\",\"type\": \"JWT\"}'))[직렬화]eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9Payload페이로드에는 엔티티(일반적인 사용자 정보)에 대한 설명과 Claim이라고 하는 추가 엔티티 속성이 포함 됩니다.아래 속성들을 Claim Set이라 부른다. Claim Set JWT에 대한 내용(토큰 생성자 정보, 생성 시간 등) 클라이언트와 서버 간 주고 받기로 한 값들로 구성 { \"sub\": \"1234567890\", \"name\": \"John Doe\", \"admin\": true}[JSON 객체]Base64URLSafe(UTF-8('{\"sub\": \"1234567890\",\"name\": \"John Doe\",\"admin\": true}'))[직렬화]eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiaWF0IjoxNTE2MjM5MDIyfQSignature서명은 JWT를 보낸 사람이 누구인지 확인하고 메시지가 도중에 변경되지 않았는지 확인하는 데 사용됩니다.[Signature]HMACSHA256( base64UrlEncode(header) + \".\" + base64UrlEncode(payload),tqQWhz5BCP(your-256-bit-secret-key)) [직렬화]tM-nO0TjFp-sF0-TYWjXKX_r9jEZvO1YWjKnWfIDWtMJWT 작동 원리 사용자가 ID와 Password를 입력하여 로그인을 시도합니다. 서버는 요청을 확인하고 Secret Key를 통해 Access Token을 발급합니다. JWT 토큰을 클라이언트에 전달합니다. 클라이언트에서 API을 요청할 때, 클라이언트가 Authorization Header에 Access Token을 담아서 보냅니다. 서버는 JWT Signature를 체크하고 Payload로 부터 사용자 정볼르 확인해 데이터를 반환합니다. 클라이언트의 로그인 정보를 서버 메모리에 저장하지 않기 때문에 토큰 기반 인증 메커니즘을 제공합니다.인증이 필요한 경로에 접근 할 때 서버 측은 Authorization 헤더에 유효한 JWT 또는 존재하는지 확인한다.JWT에는 필요한 모든 정보를 토큰에 포함하기 때문에 데이터베이스와 같은 서버와의 커뮤니케이션 오버 헤드를 최호화 할 수 있다.Cross-Origin Resources Sharing(CORS)는 쿠키를 사용하지 않기 때문에 JWT를 채용 한 인증 메커니즘은 두 도메인에서 API를 제공하더라도 문제가 발생하지 않습니다.일반적으로 JWT 토큰 기반의 인증 시스템은 위와 같은 프로세스로 이루어집니다. 처음 사용자를 등록 할 때 Access Token과 Refresh token이 모두 발급되어야 합니다.JWT 장단점장점 보안 : JWT는 클라이언트나 해커가 수정하지 못하도록 보호하는 비밀(HMAC) 또는 공개/개인 키 쌍(RSA 또는 ECDSA)를 사용하여 디지털 서명됩니다. 클라이언트에만 저장 : 서버에서 JWT를 생성하여 클라이언트로 보냅니다. 그런 다음 클라이언트는 모든 요청과 함께 JWT를 제출합니다. 이것은 데이터베이스의 공간을 절약 할 수 있습니다. Efficient / Stateless : 데이터베이스 조회가 필요하지 않기 때문에 JWT를 빠르게 검증 할 수 있습니다. 이는 대규모 분산 시스템에서 특히 유용합니다.단점 취소 기능 : 자체 포함 된 속성 및 상태 확인 프로세스로 인해 JWT가 자연적으로 만료 되기 전에는 취소하기가 어렵습니다. 따라서 사용자를 즉시 차단하는 것과 같은 조치는 쉽게 구현 할 수 없습니다. (JWT 거부 및 블랙리스트로 취소 가능 하지만 어렵습니다.) 사용자 정보 수정 : 취소 기능가 마찬가지로 발급 된 JWT는 수정이 불가능 하기 때문에 사용자의 정보를 데이터베이스에서 수정 했더라도 즉시 적용이 어렵습니다. 1개의 Private 키 종속적 : JWT는 1개의 Private 키에 따라 달라집니다. 해당 키가 손상되면 공격자는 API 계층이 수락할 자체 JWT를 조작 할 수 있습니다. 트래픽 : Stateless 애플리케이션에서 토큰은 거의 모든 요청에 대해 전송 되므로 데이터 트래픽이 증가 할 수 있습니다.ClaimJWT는 Claim에 이름/값 쌍으로 여러 정보를 넣을 수 있습니다. JWT Claim에는 아래와 같은 두 가지 유형이 있습니다. Registered : 등록 된 표준 Claim에 의해 정의되고 JWT 사양 타사 또는 외부 응용 프로그램과의 상호 운용성을 보장합니다. Custom : 등록 되지 않은 public 또는 private claim으로 구성 됩니다. Public Claim : JWT를 사용하는 사람들 마음대로 정의 할 수 있습니다. 그러나 충돌을 방지하려면 IANA JWT Registry에 등록해야 합니다. Private Claim : Private으로 당사자 간의 정보를 공유하기 위해 생성 하는 맞춤형 Claim입니다. Registered ClaimJWT 사양은 필수는 아니지만 상호 운용성을 위해 아래와 같이 권장하는 7개의 예약 Claim이 있습니다. iss(발급자) : JWT 발행자 sub(주제) : JWT의 주제(사용자) aud(청중) : JWT가 의도 된 수신자 exp(만료 시간) : JWT가 만료되는 시간 nbf(not before time) : JWT가 처리를 위해 수락 되어서는 안 되는 시간 iat(발행 시간) : JWT가 발행 된 시간. JWT의 나이를 결정하는 데 사용 할 수 있습니다. jti(JWT ID) : 고유 식별자. JWT가 재생되는 것을 방지함Custom Claim사용자가 자신에게 맞는 Claim을 정의하고 Actions를 사용하여 토큰을에 추가 할 수 있습니다.아래와 같이 사용 가능 합니다. 사용자의 이메일 주소를 액세스 토큰에 추가하고 이를 사용하여 사용자를 고유하게 식별합니다. Auth0 사용자 프로필에 저장 된 사용자 지정 정보를 ID 토큰에 추가합니다.1. Public Claim이름 및 이메일과 같은 일반 정보를 포함할 수 있는 공개 사용을 위한 사용자 지정 Claim을 만들 수 있습니다.공개 Claim을 생성하는 경우 이를 등록하거나 네임스페이스를 통해 충돌 방지 이름을 사용하야 합니다. 아래는 IANA JWT Registry](https://www.iana.org/assignments/jwt/jwt.xhtml)에 등록 된 Public Claim 입니다. auth_time acr nonce2. Private Claim개인 사용자 지정 Claim을 만들어 응용 프로그램과 관련 된 정보를 공유할 수 있습니다.예를 들어 Public Claim 같은 경우 이름 및 이메일과 같은 일반적인 정보라면 Private Claim은 직원 ID, 부서 이름과 같은 더 구체적인 Claim을 만들 수 있습니다.참고 https://jwt.io/introduction https://supertokens.com/blog/what-is-jwt http://www.opennaru.com/opennaru-blog/jwt-json-web-token/" }, { "title": "Visitor 패턴", "url": "/posts/VisitorPattern/", "categories": "Design Pattern, Visitor", "tags": "Design Pattern, Visitor", "date": "2022-09-14 10:30:00 +0900", "snippet": "소개패턴을 활용한 리팩터링이라는 책에서 Switch 문을 좀더 객체지향적인, 다향성을 이용하도록 리팩터링 하기 위해서 Visitor 패턴을 도입하면, 조건 로직도 필요 없어지고 설계도 더 융통성 있게 할 수 있다고 소개한다.방문자 패턴(Visitor Pattern)Visitor는 사전적인 의미로 어떤 장소에 찾아오는 사람이라는 의미를 가지고 있다. 방문자 패턴에서는 데이터 구조와 처리를 분리한다.데이터 구조 안을 돌아다니는 주체인 방문자를 나타내는 클래스를 준비해서 처리를 맡긴다. 새로운 처리를 추가하고 싶을 땐 새로운 방문자를 만들고 데이터 구조는 방문자를 받아들이면 된다.방문자 패턴은 개방-패쇠 원칙을 적용하는 방법 중 한 가지 입니다. 확장에 대해 열려있다. 클래스를 설계할 때, 특별한 이유가 없는 한 확장을 금지해서는 안된다. 수정에 대해 닫혀있다. 확장 할 때 마다 기존의 클래스를 수정하면 안된다. Visitor은 객체 구조의 각 ConcreteElement에 대한 메서드을 정의합니다. ConcreteVisitor은 Visitor에 의해 정의된 각 메서드를 구현합니다. 각 메서드는 해당 개체에 필요한 알고리즘을 구현합니다. Eelement는 Visitor를 인수로 사용하는 Accept 메서드를 정의 합니다. ConcreteElement는 방문자를 인수로 하는 Accept 메서드를 구현합니다. ObjectStructure는 Element를 열거할 수 있으며 Visitor가 Element를 방문할 수 있도록 높은 수준의 인터페이스를 제공합니다.예시맛집 레스토랑을 예시로 설명을 해보도록 하겠습니다. 직원들이 열심히 일을 해 손님들이 항상 꽉차고 매출도 많이 오른 레스토랑이 있습니다.그래서 사장은 보너스와 휴가를 줌으로써 직원들에게 보상하려고 합니다.하지만 이미 아래와 같이 직원의 클래스가 이미 만들어져 있습니다.classDiagram Employee &lt;|--GeneralManager Employee &lt;|--HeadChef Employee &lt;|--LineCook class Employee{ +string Name +double AnnualSalary +int PaidTimeOffDays } class GeneralManager{ } class HeadChef{ } class LineCook{ }우리는 여기서 직원들의 보너스와 추가 휴가에 대해 계산하여 출력하려 합니다.물론 List에 모든 직원들을 넣어 반복문을 돌면서 보너스를 계산하는 메서드, 추가 휴가를 계산하는 메서드를 만들 수 있습니다.하지만 Visitor 패턴을 사용하게 되면 좀 더 객체지향적으로 계산할 수 있으며, 추후 다른 필요한 계산에 대해 모듈을 만들어 추가 및 삭제가 용이하게 만들 수 있습니다.public interface IVisitor{ void Visit(IElement element);}public interface IElement{ void Accept(IVisitor visitor);}public class IncomeVisitor : IVisitor{ public void Visit(IElement element) { Employee employee = (Employee)element; employee.AnnualSalary *= 1.10; Console.WriteLine(\"{0} {1}' new income: {2:C}\", employee.GetType().Name, employee.Name, employee.AnnualSalary); }}public class PaidTimeOffVisitor : IVisitor{ public void Visit(IElement element) { Employee employee = (Employee)element; employee.PaidTimeOffDays += 3; Console.WriteLine(\"{0} {1}'s new vacation days: {2}\", employee.GetType().Name, employee.Name, employee.PaidTimeOffDays); }} IncomeVisitor : 보너스 계산에 쓰입니다. PaidTimeOffVisitor : 추가 휴가에 쓰입니다.위와 같이 Visitor를 따로따로 만들어 필요할때마다 가져다 사용하면 됩니다.기존의 Employee 클래스는 IElement를 상속 받아 구현합니다.public class Employee : IElement{ public string Name { get; set; } public double AnnualSalary { get; set; } public int PaidTimeOffDays { get; set; } public Employee(string name, double annualSalary, int paidTimeOffDays) { Name = name; AnnualSalary = annualSalary; PaidTimeOffDays = paidTimeOffDays; } public void Accept(IVisitor visitor) { visitor.Visit(this); }}그리고 직원들의 리스트를 가질 Employees 클래스를 생성합니다.public class Employees{ private List&lt;Employee&gt; _employees = new List&lt;Employee&gt;(); public void Attach(Employee employee) { _employees.Add(employee); } public void Detach(Employee employee) { _employees.Remove(employee); } public void Accept(IVisitor visitor) { foreach (Employee e in _employees) { e.Accept(visitor); } Console.WriteLine(); }}Program.cs 파일에서 아래와 같이 필요한 직원들을 추가하고 계산 할 Visitor를 넣어 실행 시킵니다.Employees e = new Employees();e.Attach(new LineCook());e.Attach(new HeadChef());e.Attach(new GeneralManager());e.Accept(new IncomeVisitor());e.Accept(new PaidTimeOffVisitor());Console.ReadKey();LineCook Dmitri' new income: \\35,200HeadChef Jackson' new income: \\75,916GeneralManager Amanda' new income: \\85,800LineCook Dmitri's new vacation days: 10HeadChef Jackson's new vacation days: 24GeneralManager Amanda's new vacation days: 27고려할 점들Visitor 패턴을 사용 할 때는 캡슐화에 대해 고려해 볼 점이 있다.장점 기존 클래스를 수정하지 않고 새로운 동작을 추가할 수 있습니다. 생각하지 못했던 연산을 쉽게 추가할 수 있다. 드믈게 사용되는 연산을 외부에 정의 할 수 있기 때문에 클래스가 작아진다. Visitor는 원소들을 방문하면서 상태를 축적할 수 있다. 모바일 에이전트는 리모트 객체(예를 들어 데이터베이스 서버)에 방문하여 분산 데이터베이스로부터 합성 결과를 축적할 수 있다. 단점합성 객체의 내부 구조가 Visitor에 열리게 되고, 이는 캡슐화를 위반하는 것이다.예를 들어 트리의 원소에 넘겨진 사악한 Visitor가 이들의 키 값을 바꾼다면 트리는 쓰레기가 되어 버린다. 또한 Visitor는 그들이 방문하는 객체와 강결합되어 있다.캡슐화 위반에 대한 반론어떤 프로그래머들은 이런저런 이유로 Visitor 패턴 사용을 반대하기도 한다. 예를 들어 어떤 프로그래머는 Visitor 패턴이 캡슐화 원칙에 위배되기 때문에 좋아하지 않는다고 말한적이 있다. 즉, Visitor 클래스가 대상 클래스의 어떤 메서드를 사용해야 하는데 그 메서드가 public 이 아니라면 그 메서드의 접근 제한을 풀어야 하고, 이것이 캡슐화 특성으 깨뜨린다는 주장이다.옳은 말이다. 하지만 Visitor 패턴을 구현할 때 대부분의 경우 그럴 필요가 없다. 설사 몇몇 메서드의 접근 제한을 풀어줘야 하는 경우라도, Visitor 패턴을 사용하지 않고 코드를 꾸려가는 것보다 대상 클래스의 캡슐화 특성을 양보하는 편이 처러야 하는 대가가 훨씬 적을 수 있다.참고 https://velog.io/@newtownboy/%EB%94%94%EC%9E%90%EC%9D%B8%ED%8C%A8%ED%84%B4-%EB%B0%A9%EB%AC%B8%EC%9E%90%ED%8C%A8%ED%84%B4Visitor-Pattern https://johngrib.github.io/wiki/pattern/visitor/ https://nipafx.dev/java-visitor-pattern-pointless/" }, { "title": "페이지 교체 기법", "url": "/posts/PageReplacement/", "categories": "OS, Cache", "tags": "OS, Memory, Cache", "date": "2022-08-01 14:30:00 +0900", "snippet": "소개메모리 관리 배경각각의 프로세스는 독립된 메모리 공간을 갖고, 운영체제 혹은 다른 프로세스의 메모리 공간에 접근할 수 없는 제한이 걸려있다. 단지, 운영체제만이 운영체제 메모리 영역과 사용자 메모리 영역에 접근을 제약을 받지 않는다.페이징하나의 프로세스가 사용하는 메모리 공간이 연속적이어야 한다는 제약을 업애는 메모리 관리 방법이다. 외부 단편화와 압축 작업을 해소하기 위해 생긴 방법론으로, 물리 메모리는 Frame이라는 고정 크기로 분리되어 있고, 논리 메모리(프로세스가 점유하는)는 페이지라 불리는 고정 크기의 블록으로 분리 된다.페이징 기법을 사용함으로써 논리 메모리를 물리 메모리에 저장될 때, 연속되어 저장될 필요가 없고 물리 메모리의 남는 프레임에 적절히 배치됨으로 외부 단편화를 해결할 수 있는 큰 장점이 있다.하나의 프로세스가 사용하는 공간을 여러개의 페이지로 나뉘어서 관리되고(논리 메모리에서), 개별 페이지는 순서에 상관없이 물리 메모리에 있는 프레임에 mapping되어 저장 된다고 볼 수 있다.요구 페이징(Demand Paging)프로그램 실행 시작 시에 프로그램 전체를 디스크에서 물리 메모리에 적재하는 대신, 초기에 필요한 것들만 적재하는 전략을 요구 페이징이라 하며, 가상 메모리 시스템에서 많이 사용된다.그리고 가상 메모리는 대게 페이지로 관리된다. 요구 페이징을 사용하는 가상 메모리에서는 실행과정에서 필요해질 때 페이지들이 적재된다. 한 번도 접근되지 않은 페이지는 물리 메모리에 적재되지 않는다.프로세스 내 개별 페이지들은 페이저(pager)에 의해 관리된다. 페이저는 프로세스 실행에 실제 필요한 페이지들만 메모리에 읽어 옴으로써, 사용되지 않을 페이지를 가져오는 시간 낭비와 메모리 낭비를 줄일 수 있다.페이지 교체요구 페이지에서 언급된대로 프로그램 실행시에 모든 항목이 물리 메모리에 올라오지 않기 때문에, 프로세스의 동작에 필요한 페이지를 요청하는 과정에서 page fault(페이지 부재)가 발생하게 되면, 원하는 페이지를 보조저장장치로 가져오게 된다. 하지만, 만약 물리 메모리가 모두 사용중인 상황이라면, 페이지 교체가 이뤄줘야 한다. (또는 운영체제가 프로세스를 강제 종료하는 방법이 있다.)페이지 교체 방법물리 메모리가 모두 사용중인 상황에서 메모리 교체 흐름이다. 디스크에서 필요한 페이지의 위치를 찾는다. 빈 페이지 프레임을 찾는다. 페이지 교체 알고리즘을 통해 희생될 페이지를 고른다. 희생될 페이지를 디스크에 기록하고, 관련된 테이블을 수정한다. 새롭게 비워진 페이지 테이블 내 프레임에 새 페이지를 읽어오고, 프레임 테이블을 수정한다. 사용자 프로세스 재시작페이지 교체 알고리즘 운영체제는 주기억장치보다 더 큰 용량의 프로그램을 실행하기 위해 프로그램의 일부만 주기억장치에 적재하여 사용한다. 이를 가상메모리 기법이라 한다. 페이징 기법으로 메모리를 간리하는 운영체제에서 필요한 페이지가 주기억장치에 적재되지 않았을 시 (페이지 부재) 어떤 페이지 프레임을 선택하여 교체할 것인지 결정하는 방법을 페이지 교체 알고리즘이라고 한다. 프레임 : 물리 메모리를 일정한 크기로 나눈 블록 페이지 : 가상 메모리를 일정한 크기로 나눈 블록 알고리즘 설명 OPT(Optimal) 앞으로 가장 오랫동안 사용되지 않을 페이지 교체 FIFO(First In First Out) 먼저 들어온 페이지가 먼저 나가게 된다. LRU(Least Recently Used) 가장 오랫동안 사용되지 않은 페이지 교체 LFU(Least Frequently Used) 참조 횟수가 가장 작은 페이지 교체 1. OPR(Optimal Page Replacement)Belady의 모순을 확인한 이후 최적 교체 알고리즘에 대한 탐구가 진행되었고, 모든 알고리즘 보다 낮은 부재율을 보이며 Belady의 모순이 발생하지 않는다.이 알고리즘의 핵심은 앞으로 가장 오랫동안 사용되지 않을 페이지를 찾아 교체하는 것이다. 주료 비교 연구 목적으로 사용 된다.장점 알고리즘 중 가장 낮은 페이지 부재율을 보장한다.단점 구현의 어려움이 있다. 모든 프로세스의 메모리 참조 계획을 미리 파악할 방법이 없다.2. FIFO(First In First Out)가장 간단한 페이지 교체 알고리즘으로 먼저 물리 메모리에 들어온 순서대로 페이지 교체 시점에 먼저 나가게 된다.장점 이해하기 쉽고, 프로그램하기도 쉽다.단점 오래된 페이지가 항상 불필요하지 않은 정보를 포함하지 않을 수 있다. ( 초기 변수 등) 처음부터 활발하게 사용되는 페이지를 교체해서 페이지 내 부재율을 높이는 부작용을 초래할 수 있다. Belady의 모순 : 페이지를 저장 할 수 있는 페이지 프레임의 갯수를 늘려도 되려 페이지 부재가 더 많이 발생하는 모순이 존재한다.3. LRU(Least Recently Used)가장 오랫동안 사용하지 않았던 데이터라면 앞으로도 사용할 확률이 적을 것이다. 라는 가정을 가지고 동작한다.특징 국부성(locality)에 기반 : 어느 한순간에 특정 부분을 집중적으로 참조 시간 국부성 : 현재 참조된 기억장소는 가까운 미래에도 계속 참조될 가능성이 높음 공간 국부성 : 하나의 기억장소가 참조되면 근처의 기억 장소가 계속 참조될 가능성이 높음장점 Belady의 모순이 발생하지 않음단점 경험적 판단이 맞지 않는 상환도 존재 막대한 오버헤드 발생4. LFU(Least Frequently Used)참조 횟수가 가장 적은 페이지를 교체하는 방법이다. 활발하게 사용되는 페이지는 참조 횟수가 많아질 것이라는 가정에서 만들어진 알고리즘이다.페이지가 참조 될 때마다 증가된 횟수를 기록하고 참조 횟수가 가장 적은 페이지를 교체 한다.단점 가장 최근에 메모리로 옮겨진 페이지가 교체될 가능성이 높다. 초기에 매우 많이 사용된 후 더 이상 사용되지 않는 페이지는 교체 가능성이 낮다." }, { "title": "상속에서 Dispose 패턴", "url": "/posts/Impl_Dispose_Pattern/", "categories": ".NET, Pattern", "tags": ".NET, Pattern, Dispose", "date": "2022-06-06 15:30:00 +0900", "snippet": "소개C#에서는 가비즈 컬렉터(GC)가 메모리를 자동으로 관리합니다. 필요없는 클래스의 인스턴스를 메모리에서 바로 지우는 것이나라, 조건을 만족할 때까지 기다렸다가 지우기 때문에 클래스를 지웠다고 해도 메모리가 바로 해제 되지 않는다.일반적인 메모리라면 GC에 맡겨도 상관 없지만, 관리되지 않는(Unmanaged, Native)리소스는 즉각 해제해야 하는 경우가 생기는데, 그럴때 필요한 것이 Dispose다.IDisposable 인터페이스C#에서는 개발자가 명시적으로 메모리를 해제하기 위해서는 IDisposable 인터페이스를 상속 받아 구현한다.IDisposable에서는 Dispose() 하나의 메서드만 제공한다.public interface IDisposable{ void Dispose();}IDisposable.Dispose()는 다음 4가지 작업을 수행한다. 모든 비관리 리소스를 정리한다. 모든 관리 리소스를 정리한다. 객체가 이미 정리되었음을 나타내기 위한 상태 플래그 설정. 앞서 이미 정리된 객체에 대하여 추가로 정리 작업이 요청될 경우 이 플래그를 확인하여 ObjectDisposed예외를 발생시킨다. finalizer 호출 회피. 이를 위해 GC.SupressFinalize(this)를 호출한다.IDisposable의 일반적인 사용법 MSDN 참고class DisposeExample { public class MyResource : IDisposable { private IntPtr Handle; // 외부 비관리 리소스 핸들 private Component component = new Component(); // 관리 리소스 private bool disposed = false; // Dispose가 호출되었는지 확인한다. public MyResource(IntPtr _Handle) { Handle = _Handle; } public void Dispose() { Dispose(disposing: true); // 사용자가 직접 Dispose()를 호출했기 때문에 // GC는 finalizer를 호출할 필요가 없다. // GC는 finalizer를 구현한 인스턴스에 대해 finalizer를 호출한다. GC.SuppressFinalize(this); } // disposing이 true인 경우 사용자가 직접 호출하여 // 해당 인스턴스의 관리/비관리 리소스를 해제하고 있는 것이다. // disposing이 false인 경우, finalizer에 의해 호출되어 // 다른 객체를 더 이상 참조하면 안되기 때문에 오직 비관리 리소스만 해제되어야한다. protected virtual void Dispose(bool disposing) { // 이미 리소스가 해제 되었는지 확인 if (disposed == true) { return; } // 실제로 사용자가 호출한 경우에만 // 관리 리소스를 호출한다. if(disposing) { component.Dispose(); } // 비관리 리소스를 해제하기 위해 // 올바른 함수를 호출한다. CloseHandle(Handle); Handle = IntPtr.Zero; // 이제 해당 인스턴스는 모두 해제되었다. disposed = true; } // C# finalizer는 비관리 리소스만 해제해야한다. ~MyResource() =&gt; Dispose(disposing: false); }}protected로 선언된 가상 헬퍼함수(virtual hepler function)을 제공하는데 파생 클래스에게도 리소스를 정리하도록 제공할 수 있습니다.protected virtual void Dispose(bool isDisposing); disposing이 true일 경우는 관리/비관리 리소스를 모두 해제 합니다. disposing이 false일 경우는 비관리 리소스만 정리합니다. 코드의 마지막 부분에서는 반드시 베이스 클래서에서 정의하는 Dispose를 호출해야만 합니다.자식 클래스에서 Dispose 사용법classDiagramIDisposable &lt;|--ParentClaseParentClase &lt;|--ChildClass이미 BaseClass에서 IDisposable를 구현했을 때 Child 클래스에서만 사용하는 리소스의 메모리 해제 방법에 대해 알아봅니다.class ParentClase : IDisposable{ private Component _parentComponent = new Component(); private bool _disposed = false; ~ParentClase() =&gt; Dispose(false); public void Dispose() { Dispose(true); GC.SuppressFinalize(this); } protected virtual void Dispose(bool disposing) { if (_disposed) { return; } if (disposing) { _parentComponent.Dispose(); } _disposed = true; }}class ChildClass : ParentClase{ bool _disposed = false; private Component _childComponent = new Component(); ~ChildClass() =&gt; Dispose(false); protected override void Dispose(bool disposing) { if (_disposed) { return; } if (disposing) { _childComponent.Dispose(); } _disposed = true; base.Dispose(disposing); }}위와 같이 ParentClass에서 ChildClass의 Dispose가 호출되는 것을 확인하지 않고 Dispose 해버리면 ChildClass의 메모리는 해제 되지 않습니다.Dispose Pattern 구현 시 주의 사항Dispose와 Finalizer는 방어적으로 작성되어야 합니다. Dispose 메서드는 한번 이상 호출 될 수 있으므로, 여러번 호출해도 문제가 없도록 구현해야 합니다.만약 이미 정리된 객체에 대해 호출한 경우 ObjectDisposedException예외를 발생시키는 것 또한 Dispose 패턴의 규칙이다.Dispose 메서드에서는 리소스 정리 작업만 수행해야 한다. Dispose나 Finalizer에서 다른 작업을 수행하게 되면 객체의 생명주기와 관련된 심각한 문제를 일으킬 수 잇따. 만약 Finalizer에서 객체에 접근하여 다른 작업을 수행하면 객체는 Reachable 상태로 되어 객체가 죽지 않고 다시 살아 날수 있다." }, { "title": "27장. '크고 작은 모든' 서비스들", "url": "/posts/PPPCleanArchitecture_ch27/", "categories": "DDD, 클린 아키텍처 소프트웨어 구조와 설계의 원칙, 5부 아키텍처", "tags": "DDD, CleanArchitecture", "date": "2022-05-19 22:00:00 +0900", "snippet": "소개클린아키텍처: 소프트웨어 구조와 설계의 원칙 책을 읽고 정리하며 소감을 적는 포스트입니다.‘크고 작은 모든’ 서비스들서비스 지향 아키텍처와 마이크로서비스 아키텍처가 최근 큰 인기를 끌고 있는 이유는 다음과 같다. 서비스를 사용하면 상호 결합이 철저하게 분리되는 것처럼 보인다. 나중에 보겠지만, 일부만 맞는 말이다. 서비스를 사용하면 개발과 배포 독립성을 지원하는 것처럼 보인다. 나중에 보겠지만, 일부만 맞는 말이다.서비스 아키텍처?서비스를 사용한다는 것인 본질적으로 아키텍처에 해당하는가? 개념적으로는 아니다. 시스템의 아키텍처는 의존성 규칙을 준수하며 고수준의 정책을 저수준의 세부사항으로부터 분리하는 경계에 의해 정의 된다.단순히 애플리케이션의 행위를 분리할 뿐인 서비스라면 값비싼 함수 호출에 불과하다.결국 서비스는 프로세스나 플랫폼 경계를 가로지르는 함수 호출에 불과 하다. 아키텍처적으로 중요한 서비스도 있지만, 중요하지 않는 서비스도 존재한다.서비스의 이점?결합 분리의 오류시스템을 서비스들로 분리함으로써 얻는 이점은 서비스 사이의 결합이 확실히 분리된다는 점이다. 물론 서비스는 개별 변수 수준에서는 각각 결합이 분리된다. 하지만 프로세서 내의 또는 네트워크 상의 공유 자원 때문에 결합 될 가능성이 여전히 존재한다. 더욱이 서로 공유하는 데이터에 의해 이들 서비스는 강력하게 결합되어 버린다.개발 및 배포 독립성의 오류서비스를 사용함에 따라 예측되는 또 다른 이점은 전담팀이 서비스를 소유하고 운영한다는 점이다. 그래서 데브옵스(dev-ops) 전략의 일환으로 전담팀에서 각 서비스를 작성하고, 유지보수하며, 운영하는 책임을 질 수 있다. 이러한 개발 및 배포 독립성은 확장 가능한(scalable)것으로 간주 된다.대규모 엔터프라이즈 시스템을 독립적으로 개발하고 배포 가능한 수십, 수백, 수천 개의 서비스들을 이용하여 만들 수 있다고 믿는다. 시스템의 개발, 유지보수, 운영 또한 비슷한 수의 독립적인 팀 단위로 분할할 수 있다고 여긴다.하지만 이는 일부일 뿐이다. 첫째로 대규모 인터프라이즈 시스템은 서비스 기반 시스템 이외에도 모노리틱, 컴포넌트 기반 등 다른 방식으로 구축할 수 있다.둘째, 결합 분리의 오류에 따르면 서비스라고 해서 항상 독립적으로 개발하고, 배포 운영 할 수 있는 것이 아니다. 데이터나 행위에서 어느정도 결합되어 있다면 결합된 정도에 맞게 개발, 배포, 운영을 조정해야만 한다.야옹이 문제앞의 두 가지 오류에 대한 예로 9장에 예를 들었던 택시 통합 시스템을 다시 살펴보자. 고객은 승차 요청을 할 수 있다. 고객은 승차 시간, 비용, 고급 택시 여부, 운전자 경력 등 다양한 기준에 따라 택시를 선택 할 수 있다.확장 가능한 시스템을 구축하고 싶었기에, 수많은 작은 마이크로서비스를 기반으로 구축하였다. 아래의 다이어그램은 TaxiUI 서비스는 고객을 담당하며, 고객은 모바일 기기로 호출한다. Taxi Finder가 여러 Taxi Supplier를 찾아 적합한 택시 후보를 고객에게 보여준다.TaxiSelector서비스는 사용자가 지정한 비용, 시간, 고급 여부 등의 조건으로 적합한 택시를 선택한다. TaxiSelector가 해당 택시를 TaxiDispatcher 서비스로 전달하면, TaxiDispatcher 서비스는 해당 택시에 배차를 지시한다. 택시 통합 서비스를 구현하기 위해 배치된 서비스들이 시스템을 일년 이상 운영해왔다고 가정한다. 그런데 마케팅 부서와 미팅에서 마케터들은 도시에 야옹이를 배달하는 서비스를 제공한다고 발표한다.택시 업체 한곳이 한다고 하였고 참여를 거부하는 업체도 있었다. 당연하지만 고양이 알러지가 있다면 해당 차량은 3일 동안 배차되지 않아야 한다.여기서 우리는 어떤 서비스를 고쳐야하는가?? 전부다. 의심의 여지없이 야용이 배달 기능을 추가하려면 개발과 배포 전략을 매우 신중하게 조정해야 한다.다시 말해 이 서비스들은 모두 결합되어 있어서 독립적으로 개발하고, 배포하거나, 유지될 수 없다.이게 바로 횡단 관심사(cross-cutting concern)가 지닌 문제다. 모든 소프트웨어 시스템은 서비스 지향이든 아니든 이 문제에 직면하게 마련이다.위 서비스 다이어그램에서 묘사된 것과 같은 종류의 기능적 분해는 새로운 기능이 기능적 행위를 횡단하는 상황에 매우 취약하다.객체가 구출한다.컴포넌트 기반 아키텍처에서는 이 문제를 어떻게 해결했을까? SOLID 설계 원칙을 잘 들여다보면, 다형적으로 확장할 수 있는 클래스 집합을 생성해 새로운 기능을 처리하도록 함을 알 수 있다.아래의 다이어그램은 이 전략을 보여준다. 배차에 특화된 로직 부분은 Rides 컴포넌트로 추출되고, 야용이에 대한 신규 기능은 Kittens 컴포넌트에 들어간다. 두 컴포넌트는 기존 컴포넌트들에 있는 추상 기반 클래스를 템플릿 메서드(Template Method)나 전략(Strategy) 패턴 등을 이용해서 오버라이드한다. 객체 지향 방식으로 횡단 관심사를 처리하기또한 이 기능들을 구현하는 클래스들은 UI의 제어하에 팩토리(Factories)가 생성한다. 이 전략을 따르더라도 야용이 기능을 구현하려면 TaxiUI는 어쩔 수 없이 변경해야 한다. 하지만 그 외의 것들은 변경할 필요가 없다. 추가만 하면된다.따라서 야용이 기능은 결합이 분리되며, 독립적으로 개발하여 배포할 수 있다.컴포넌트 기반 서비스이제 당연한 질문은 \"서비스에도 이렇게 할 수 있을까?\"다. 물론 \"예\"이다.서비스는 SOLID 원칙대로 설계할 수 있으며 컴포넌트 구조를 갖출 수도 있다. 이를 통해 서비스 내의 기존 컴포넌트들을 변경하지 않고도 새로운 컴포넌트를 추가할 수 있다.자바의 경우, 서비스를 하나 이상의 jar 파일에 포함되는 추상 클래스들의 집합이라고 생각하라. 새로운 기능 추가 혹은 기능 확장은 새로운 jar 파일로 만든다.그러면 새로운 기능은 재배포하는 문제가 아니라 jar 파일을 추가하는 문제가 된다. 다시 말해 새로운 기능을 추가하는 행위가 개방 패쇄 원칙을 준수하게 된다.아래의 서비스 다이어그램은 이 구조를 보여 준다. 서비스들은 이전과 달라진게 없지만 서비스의 내부는 자신만의 컴포넌트 설계로 되어 있어서 파생 클래스를 만드는 방식으로 신규 기능을 추가할 수 잇다. 파생 클래서들은 각자의 컴포넌트 내부에 놓인다. 각 서비스의 내부는 각자의 방식대로 컴포넌트를 설계할 수 있으며, 파생 클래스를 만들어서 신규 기능을 추가할 수 있다.횡단 관심사지금까지 배운 것은 아키텍처 경계가 서비스 사이에 있지 않다는 사실이다.오히려 서비스를 관통하며, 서비스를 컴포넌트 단위로 분할한다.모든 주요 시스템이 직면하는 횡단 관심사를 처리하려면, 아래의 다이어그램처럼 서비스 내부는 의존성 규칙도 준수하는 컴포넌트 아키텍처로 설계해야 한다. 이 서비스들은 시스템의 아키텍처 경계를 정의하지 않는다. 아키텍처 경계를 정의하는 것은 서비스 내에 위치한 컴포넌트다. 서비스 내부는 의존성 규칙도 준수하는 컴포넌트 아키텍처로 설계해야 한다.결론서비스는 시스템의 확장성과 개발 가능성 측면에서 유용하지만, 그 자체로는 아키텍처적으로 그리 중요한 요소는 아니다. 시스템의 아키텍처는 시스템 내부에 그어진 경계와 경계를 넘나드는 의존성에 의해 정의 된다. 시스템의 구성 요수고 통신하고 실행되는 물리적인 메커니즘에 의해 아키텍처가 정의되는 것은 아니다.서비스는 단 하나의 아키텍처 경계로 둘러싸인 단일 컴포넌트로 만들 수 있다. 혹은 여러 아키텍처 경계로 분리된 다수의 컴포넌트로 구성할 수도 있다." }, { "title": "26장. 메인(Main) 컴포넌트", "url": "/posts/PPPCleanArchitecture_ch26/", "categories": "DDD, 클린 아키텍처 소프트웨어 구조와 설계의 원칙, 5부 아키텍처", "tags": "DDD, CleanArchitecture", "date": "2022-05-19 21:30:00 +0900", "snippet": "소개클린아키텍처: 소프트웨어 구조와 설계의 원칙 책을 읽고 정리하며 소감을 적는 포스트입니다.메인(Main) 컴포넌트모든 시스템에는 최소한 하나의 컴포넌트가 존재하고, 이 컴포넌트가 나머지 컴포넌트를 생성하고, 조정하며 관리한다. 나는 이 컴포넌트를 메인(Main)이라고 부른다.궁극적인 세부사항메인 컴포넌트는 궁극적인 세부사항으로, 가장 낮은 수준의 정책이다. 메인은 시스템의 초기 진입점이다. 운영체제를 제외하면 어떤 것도 메인에 의존하지 않는다.의존성을 주입하는 일은 바로 메인 컴포넌트에서 이뤄져야 한다. 메인에 의존성이 일단 주입되고 나면, 메인은 의존성 주입 프레임워크를 사용하지 않고도 일반적인 방식으로 의존성을 분배할 수 있다.메인을 가장 지저분한 컴포넌트라고 생각하면 된다.아래는 최신 버전의 움퍼스 사냥(Hunt the Wumpus) 게임의 메인 컴포넌트이다. 주목할 부분은 문자열을 로드하는 방법으로, 코드의 나머지 핵심 영역에서 구체적인 문자열을 알지 못하게 하였다.public class Main implements HtwMessageReceiver { private static HuntTheWumpus game; private static int hitPoints = 10; private static final List&lt;String&gt; caverns = new ArrayList&lt;&gt;(); private static final String[] environments = new String[] { \"bright\", \"humid\", \"dry\", \"creepy\", \"ugly\", \"foggy\", \"hot\", \"cold\", \"drafty\", \"dreadful\" }; private static final String[] shapes = new String[] { \"round\", \"square\", \"oval\", \"irregular\", \"long\", \"craggy\", \"rough\", \"tail\", \"narrow\" }; private static final String[] cavernTypes = new String[] { \"cavern\", \"room\", \"chamber\", \"catacomb\", \"crevasse\", \"cell\", \"tunnel\", \"passageway\", \"hall\", \"expanse\", }; private static final String[] adornments = new String[] { \"smelling of sulfur\", \"with engravings on the walls\", \"with a bumpy floor\", \"\", \"littered with garbage\", \"spttered with guano\", \"with piles of Wumpus droppings\", \"with bones scattered around\", \"with a corpse on the floor\", \"that seems to vibrate\", \"that feels stuffy\", \"that fills you with dread\", };이제 main 함수를 보면 HtwFactory를 사용하여 게임을 생성하는 방식을 주목하자. 게임을 생성할 때 htw.game.HunTheWumpusFacase라는 클래스 이름을 전달하는데, 이 클래스는 메인보다도 더 지저분하기 때문이다. 재컴파일/재배포가 되지 않게하기 위함이다.public static void main(String[] args) throws IOException { game = HtwFactory.makeGame(\"htw.game.HuntTheWumpusFacade\", new Main()); createMap(); BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); game.makeRestCommand().execute(); while (true) { System.out.println(game.getPlayerCavern()); System.out.println(\"Health: \" + hitPoints + \" arrows: \" + game.getQuiver()); HuntTheWumpus.Command c = game.makeRestCommand(); System.out.println(\"&gt;\"); String command = br.readLine(); if(command.equalsIgnoreCase(\"e\")) c = game.makeMoveCommand(EAST); else if (command.equalsIgnoreCase(\"w\")) c = game.makeMoveCommand(WEST); else if (command.equalsIgnoreCase(\"n\")) c = game.makeMoveCommand(NORTH); else if (command.equalsIgnoreCase(\"s\")) c = game.makeMoveCommand(SOUTH); else if (command.equalsIgnoreCase(\"r\")) c = game.makeRestCommand(); else if (command.equalsIgnoreCase(\"sw\")) c = game.makeShootCommand(WEST); else if (command.equalsIgnoreCase(\"se\")) c = game.makeShootCommand(EAST); else if (command.equalsIgnoreCase(\"sn\")) c = game.makeShootCommand(NORTH); else if (command.equalsIgnoreCase(\"ss\")) c = game.makeShootCommand(SOUTH); else if (command.equalsIgnoreCase(\"q\")) return; c.execute(); }}main 함수에서 주목할 점이 더 있다. 바로 입력 스트림 생성 부분, 게임의 메인 루프 처리, 간단한 입력 명령어 해석 등은 main 함수에서 모두 처리하지만, 명령어를 실제로 처리하는 일은 다른 고수준 컴포넌트로 위임한다는 사실이다.마지막으로 지도 생성 역시 main에서 처리한다.private static void createMap(){ int nCaverns = (int) (Math,random() * 30.0 + 10.0); while (nCaverns-- &gt; 0) caverns.add(makeName()); for(String cavern : caverns) { maybeConnectCavern(cavern, NORTH); maybeConnectCavern(cavern, SOUTH); maybeConnectCavern(cavern, EAST); maybeConnectCavern(cavern, WEST); } String playerCavern = anyCavern(); game.setPlayerCavern(playerCavern); game.setWumpusCavern(anyOther(playerCavern)); game.addBatCavern(anyOther(playerCavern)); game.addBatCavern(anyOther(playerCavern)); game.addBatCavern(anyOther(playerCavern)); game.addPitCavern(anyOther(playerCavern)); game.addPitCavern(anyOther(playerCavern)); game.addPitCavern(anyOther(playerCavern)); game.setQuiver(5); // 이하 코드 생략}요지는 메인은 클린 아키텍처에서 가장 바깥 원에 위치하는, 지저분한 저수준 모듈이다.메인은 고수준의 시스템을 위한 모든 것을 로드한 후, 제어권을 고수준의 시스템에게 넘긴다.결론메인은 초기 조건과 설정을 구성하고, 외부 자원을 모두 수집한 후, 제어권을 애플리케이션의 고수준 정책으로 넘기는 플러그인이다. 메인은 플러그인이므로 메인 컴포넌트를 애플리케이션의 설정별로 하나씩 두도록 하여 둘 이상의 메인 컴포넌트를 만들 수도 있다.메인은 플러그인 컴포넌트로 여기고, 그래서 아키텍처 경계 바깥에 위치한다고 보면 설정 관련 문제를 훨씬 쉽게 해결할 수 있다." }, { "title": "25장. 계층과 경계", "url": "/posts/PPPCleanArchitecture_ch25/", "categories": "DDD, 클린 아키텍처 소프트웨어 구조와 설계의 원칙, 5부 아키텍처", "tags": "DDD, CleanArchitecture", "date": "2022-05-17 22:50:00 +0900", "snippet": "소개클린아키텍처: 소프트웨어 구조와 설계의 원칙 책을 읽고 정리하며 소감을 적는 포스트입니다.계층과 경계시스템이 세 가지 컴포넌트(UI, 업무 규칙, 데이터베이스)로만 구성된다고 생각하기 쉽다. 하지만 대다수의 시스템에서 컴포넌트 개수는 이보다 훨씬 많다.움퍼스 사냥 게임1972년에 발매된 인기있는 모험게임인 움퍼스 사냥(Hunt thw Wumpus)는 텍스트를 기반으로 하는 GO EAST와 SHOOT WEST와 같은 매우 단순한 명령어를 사용한다.여기서 텍스트 기반 UI는 그대로 유지하되, 게임 규칙과 UI를 분리해서 우리 제품을 여러 시장에서 다양한 언어로 발매할 수 있게 만든다고 가정해 보자. 게임 규칙은 언어 독립적인 API를 사용해서 UI 컴포넌트와 통신할 것이고, UI는 API를 사람이 이해할 수 있는 언어로 변환할 것이다.아래의 그림과 같이 의존성을 적절히 관리하면 UI 컴포넌트가 어떤 언어를 사용해도 게임 규칙을 재사용 할 수 있다. UI 컴포넌트가 어떤 언어를 사용하더라도 게임 규칙을 재사용할 수 있다.아래의 그림과 같이 의존성 규칙을 준수하여 게임 규칙이 데이터 저장소 컴포넌트와 통신 할 때 우리는 게임 규칙이 다양한 종류의 데이터 저장소에 대해 알지 않기를 원한다. 의존성 규칙 준수하기클린 아키텍처?위 예제와 같은 단순한 시스템은 클린 아키텍처 접근법을 적용해서 유스케이스, 경계, 엔티티 그리고 관련된 데이터 구조를 모두 만드는 일도 쉬운 일이다. 그런데 정말 아키텍처 경계를 모두 발견한 것인가??예를 들어 UI에서 언어가 유일한 변경점은 아니다. 텍스트를 주고 받는 메커니즘을 다양하게 만들고 싶을 수도 있다. 예를 들어 셸(shell)창을 사용하거나 채팅 프로그램으로 할 수도 있다.다양한 가능성이 존재하므로 변경의 축에 의해 정의되는 아키텍처 경계가 잠재되어 있을 수 있다. 개선된 다이어그램점선으로 된 테두리는 API를 정의하는 추상 컴포넌트를 가리키며, 해당 API는 추상 컴포넌트 위나 아래의 컴포넌트가 구현된다. TextDelivery : SMS, Console Language : English, Spanish Data Storage : Cloud Data, Flash Data위 경우에 해당하는 Boundary 인터페이스가 정의하는 API는 의존성 흐름의 상위에 위치한 컴포넌트에 속한다.이러한 변형들을 모두 제거하고 순전히 API 컴포넌트만 집중하면 다이어그램을 단순화 할 수 있다. 단순화된 다이어그램위 다이어그램은 모든 화살표가 위를 향하도록 맞춰졌다는 점에 주목해야 한다.모든 입력은 사용자로부터 전달 받아 TextDelivery를 통해 Language를 거쳐 GameRules에 적합한 명령어로 변역된다.GrameRules는 사용자 입력을 처리하고, 우측 하단의 DataStorage로 데이터를 내려 보낸다.이 구성은 데이터 흐름을 두 개의 흐름을 효과적으로 분리한다.흐름 횡단하기위 예제처럼 데이터 흐름이 항상 두 가지 일까? 절대아니다. 움퍼스 사냥 게임을 네트워크상에서 여러 사람이 함께 플레이할 수 있게 만든다고 해보자아래와 같이 네트워크(NETWORK) 컴포넌트를 추가해야 한다. Network 컴포넌트 추가하기위 흐름은 GameRules가 모두 제어한다. 따라서 시스템이 복잡해질수록 컴포넌트 구조는 더 많은 흐름으로 분리될 것이다.흐름 분리하기이쯤 되면 모든 흐름이 결국에는 상단의 단일 컴포넌트에서 서로 만난다고 생각할 수 있다. 하지만 현실을 훨씬 복잡하다.움퍼스 사냥 게임의 GameRules 컴포넌트를 보면 게임 규칙 중일부는 지도와 관련된 메커니즘을 처리한다. 동굴의 연결, 물체의 위치 등을 알고 있다.하지만 이보다 더 높은 수준에서 또 다른 정책 집합이 존재한다. 즉, 플레이어 생명령, 사건 해결 비용, 소등 등 이다.저수준의 정책은 고수준 정책에게 FellInFit(구덩이에빠짐)과 같은 사건이 발생했음을 알린다. 고수준의 정책은 플레이어를 관리한다.이것이 아키텍처 경계일까? MoveManagement와 PalyerManagement를 분리해야할까? 이 예제를 더 흥미롭게하는 마이크로서비스까지 추가해 보자.대규모 플레이어가 동시에 플레이 할 수 있는 버전은 움퍼스 사냥 게임이 있다고 가정해보자. MoveManagement는 플레이어의 컴퓨터에서 처리되지만 PlayerManagement는 서버에서 처리된다.PlayerManagement는 접속된 모든 MoveManagement 컴포넌트에 마이크로서비스 API를 제공한다. 마이크로서비스 API 추가하기MoveManagement와 PlayerManagement 사이에는 완벽한 형테의 아키텍처 경계가 존재한다.결론아키텍트로서 우리는 아키텍처 경계가 언제 필요한지를 신중하게 파악해내야 한다. 또한 우리는 이러한 경계를 제대로 구현하려면 비용이 많이 든다는 사실도 인지하고 있어야 한다.그러면 우리는 어떻게 해야하나? 매우 똑똑한 사람들이 수년간 말해왔듯이, 우상화가 필요하리라고 미리 예측해서느 안 된다. 이것이 바로 YAGNU(You Aren’t Going to Need It)이 말하는 철학이다. 오버 엔지니어링(over engineering)이 언더 엔지니어링(under engineering)보다 나쁠 때가 훨씬 많기 때문이다.우리는 비용을 산정하고 어디에 아키텍처 경계를 둬야 할지, 그리고 완벽하게 구현할 경계는 무엇인지와 부분적으로 구현할 경계와 무시할 경계는 무엇인지를 결정해야 한다.하지만 이는 일회성 결정이 아니다. 프로젝트 초반에는 구현할 경계가 무엇인지와 무시할 경계가 무엇인지를 쉽게 결정할 수 없다. 대신 경계가 필요할 수도 있는 부분에 주목하고, 경계가 존재하지 않아 생기는 마찰의 어렴풋한 첫 조짐을 신중하게 관차랳야 한다." }, { "title": "24장. 부분적 경계", "url": "/posts/PPPCleanArchitecture_ch24/", "categories": "DDD, 클린 아키텍처 소프트웨어 구조와 설계의 원칙, 5부 아키텍처", "tags": "DDD, CleanArchitecture", "date": "2022-05-14 18:18:00 +0900", "snippet": "소개클린아키텍처: 소프트웨어 구조와 설계의 원칙 책을 읽고 정리하며 소감을 적는 포스트입니다.부분적 경계아키텍처 경계를 완벽하게 만드는 데는 비용이 많이 든다. 엄청난 노력을 기울여야 하고, 유지하는 데도 또 엄청난 노력이 든다.많은 경우에, 뛰어난 아키텍트라면 이러한 경계를 만드는게 비용이 너무 많이 든다고 판단하면서도, 나중에 필요할 수도 있으니 경계에 필요한 공간을 확보하기 원할 수 있다.애자일 커뮤니티에 속한 사람 중 많은 이가 이러한 종류의 선행적인 설계를 탐탁지 않게 여기는데, YAGNI(You Aren’t Going to Need It) 원칙을 위반하기 때문이다.하지만 아키텍트라면 이 문제를 검토하면서 “그래, 하지만 어쩌면 필요할지도.”라는 생각이 든다면 부분적 경계(partial boundary)를 구현해 볼 수 있다.마지막 단계를 건너뛰기부분적 경계를 생성하는 방법 하나는 독립적으로 컴파일하고 배포할 수 있는 컴포넌트를 만들기 위한 작업은 모두 수행한 후, 단일 컴포넌트에 그대로 모아만 두는 것이다.아무리 보아도 이처럼 부분적 경계를 만들려면 완벽한 경계를 만들 때만큼 코드량과 사전 설계가 필요하다. 하지만 다수의 컴포넌트 관리하는 작업은 하지 않아도 된다.하지만 시간이 흐르면서, 별도로 분리한 컴포넌트가 재사용 될 가능성이 낮아지고 의존성이 잘못된 방향으로 선을 넘기 시작하면 다시 분리하는 작업은 따문한 일이 될 것이다.일차원 경계완벽한 형태의 아키텍처 경계는 양방향으로 격리된 상태를 유지해야 하므로 쌍방향 Boundary 인터페이스를 사용한다. 양방향으로 격리된 상태를 유지하려면 초기 설정할 때나 지속적으로 유지할 때도 비용이 많이 든다.아래의 그림은 전통적인 전략(Strategy)패턴을 사용하여 추후 완벽한 형태로 경계를 확장하기 위해 공간을 확보할 때 사용 된다. 전략(Strategy) 패턴Client를 ServiceImpl로 부터 격리시키는 데 필요한 의존성 역전을 적용하여 미래에 필요한 아키텍처 경계를 만든다.하지만 점선 화살표에서 보듯이 이러한 분리는 빠르게 붕괴 될 수 있는데, 쌍방향 인터페이스가 없고 개발자와 아키텍트가 근면 성실하고 제대로 훈련되어 있지 않다면, 이 점선과 같은 비밀 통로가 생기는 일을 막을 수 없다.퍼사드훨씬 더 단순한 경계는 퍼사드(Facade) 패턴이다. 아래의 그림과 같으며 의존성 역전까지도 희생한다. 퍼사드(Facade) 패턴Facade 클래스에는 모든 서비스 클래스를 메서드 형태로 정의하고, 서비스 호출이 발생하면 해당 서비스 클래스로 호출을 전달한다. 클라이언트는 이들 서비스 클래스에 직접 접근 할 수 없다.하지만 Client가 이 모든 서비스 클래스에 대해 추이 종속성을 가지게 된다. 정적 언어였다면 서비스 클래스 중 하나에서 소스 코드가 변경되면 Client도 무조건 재컴파일 해야 한다.결론아키텍처 경계를 부분적으로 구현하는 간단한 방법 세 가지를 살펴봤다.접근법 각각은 나름의 비용과 장점을 지닌다. 각 접근법은 완벽한 형태의 경계를 담기 위한 공간으로써, 적절하게 사용할 수 있는 상황이 서로 다르다. 또한 각 접근법은 해당 경계가 실제로 구체화되지 않으면 가치가 떨어질 수 있다.아키텍처 경계가 언제, 어디에 존재해야 할지, 그리고 그 경계를 완벽하게 구현할지 아니면 부분저그올 구현할지를 결정하는 일 또한 아키텍트의 역할이다." }, { "title": "23장. 프레젠터와 험블 객체", "url": "/posts/PPPCleanArchitecture_ch23/", "categories": "DDD, 클린 아키텍처 소프트웨어 구조와 설계의 원칙, 5부 아키텍처", "tags": "DDD, CleanArchitecture", "date": "2022-05-14 15:30:00 +0900", "snippet": "소개클린아키텍처: 소프트웨어 구조와 설계의 원칙 책을 읽고 정리하며 소감을 적는 포스트입니다.프레젠터와 험블 객체프레젠터는 험블 객체(Humble Object) 패턴을 따른 형태로, 아키텍처 경계를 식별하고 보호하는 데 도움이 된다. 실제로 이전 장 \"클린 아키텍처\"는 험블 객체 구현체들로 가득 차 있다.험블 객체 패턴험블 객체 패턴은 디자인 패턴으로 테스트하기 어려운 행위와 테스트하기 쉬운 행위를 단위 테스트 작성자가 분리하기 쉽게 하는 방법으로 고안되었다.아이디어는 매우 단순하다. 행위들을 두 개의 모듈 또는 클래스로 나눈다. 이들 모듈 중 하나가 험블(Humble)이다. 가장 기본적인 본질은 남고, 테스트 하기 어려운 행위를 모두 험블 객체로 옮긴다. 나머지 모듈에는 험블 객체에 속하지 않은 테스트 하기 쉬운 행위를 모두 옮긴다.예를 들어 GUI는 테스트하기 어렵다. 하지만 GUI에서 수행하는 행위의 대다수는 쉽게 테스트 할수 있다.험블 객체 패턴을 사용하면 두 부류의 행위를 분리하여 프레젠터와 뷰라는 서로 다른 클래스로 만들 수 있다.프레젠터와 뷰뷰는 험블 객체이고 테스트하기 어렵다. 뷰는 데이터를 GUI로 이동시키지만, 데이터를 직접 처리하지는 않는다.프레젠터는 테스트하기 쉬운 객체다. 프레젠터의 역할은 애플리케이션으로 부터 데이터를 받아 화면에 표현할 수 있는 포맷으로 만드는 것이다.애플리케이션에서 어떤 필드에 날짜를 표시하고자 한다면 프레제터에 Date 객체를 전달하고 프레젠터는 데이터를 적절한 포맷의 문자열로 만든다. 이 문자열은 뷰 모델(view model)이라고 부르는 간단한 데이터 구조를 담는다. 그러면 뷰는 뷰 모델에서 이 데이터를 찾는다.뷰는 뷰 모델의 데이터를 화면으로 로드할 뿐이며, 이 외에 뷰가 맡은 역할은 전혀 없다. 따라서 뷰는 보잘것 없다.(humble)테스트와 아키텍처테스트 용이성은 좋은 아키텍처가 지녀야 할 속성으로 오랫동안 알려져 왔다. 험블 객체 패턴이 좋은 예인데, 행위를 테스트하기 쉬운 부분과 테스트하기 어려운 부분으로 분리하면 아키텍처 경계가 정의되기 때문이다. 프레젠터와 뷰 사이의 경계는 이러한 경계 중 하나이다.데이터베이스 게이트웨이유스케이스 인터렉터와 데이터베이스 사이에는 데이터베이스 게이트웨이(Database Gateway)가 위치한다. 이 게이트웨이는 다형적 인테페이스로, 애플리케이션의 데이터베이스에 수행하는 생성, 조회, 갱신, 삭제 작업과 관련된 모든 메서드를 포함한다.유스케이스 계층은 필요한 메서드를 제공하는 게이트웨이 인터페이스를 호출한다. 그리고 인터페이스의 구현체는 데이터베이스 계층에 위치한다. 이 구현체는 험블 객체다.이와 달리 인터렉터는 애플리케이션에 특화된 업무 규칙을 캡슐화하기 때문에 험블 객체가 아니다. 따라서 테스트하기 쉬운데, 게이트웨이는 스텁(stub)이나 테스트 더블(test-double)로 적당히 교체할 수 있기 때문이다.데이터 매퍼객체 관계 매퍼(Object Relational Mapper, ORM)은 어느 계층인가? 사실 ORM은 존재하지 않는데, 객체는 데이터 구조가 아니기 때문이다.데이터는 모두 private으로 선언되므로 객체의 사용자는 데이터를 볼 수 없다.객체와 달리 데이터 구조는 함축된 행위를 가지지 않는 public 데이터 변수의 집합이다. ORM 보다는 차라리 데이터 매퍼(Data Mapper)라고 부르는 편이 나아 보인다.이러한 ORM은 시스템에서 데이터베이스 계층에 속한다. 실제로 ORM은 게이트웨이 인터페이스와 데이터베이스 사이에서 일종의 또 다른 험블 객체 경계를 형성하기 때문이다.서비스 리스너애플리케이션이 다른 서비스와 반드시 통신해야 한다면, 또는 애플리케이션에서 일련의 서비스를 제공해야 한다면, 서비스 경계를 생성하는 험블 객체 패턴을 발견 할 수 있다.애플리케이션이 데이터를 데이터 구조로 로드하고, 경계를 가로질러 특정 모듈로 전달한다. 해당 모듈은 적절한 포맷으로 변경하여 외부 서비스로 전성한다.외부 서비스는 서비스 리스너(service listencer)가 서비스 인터페이스로 부터 데이터를 수신하고, 데이터를 애플리케이션에 사용 할 수 있도록 데이터 구조로 포맷을 변경한다.결론각 아키텍처 경계마다 경계 가까이 숨어 있는 험블 객체 패턴을 발견할 수 있다. 경계를 넘나드는 통신은 거의 모두 간단한 데이터 구조를 수반할 때가 많고, 대개 그 경계는 테스트하기 어려운 무언가와 테스트하기 쉬운 무언가로 분리될 것이다.그리고 이러한 아키텍처 경계에서 험블 객체 패턴을 사용하면 전체 시스템의 테스트 용이성을 크게 높일 수 있다." }, { "title": "22장. 클린 아키텍처", "url": "/posts/PPPCleanArchitecture_ch22/", "categories": "DDD, 클린 아키텍처 소프트웨어 구조와 설계의 원칙, 5부 아키텍처", "tags": "DDD, CleanArchitecture", "date": "2022-05-14 15:00:00 +0900", "snippet": "소개클린아키텍처: 소프트웨어 구조와 설계의 원칙 책을 읽고 정리하며 소감을 적는 포스트입니다.클린 아키텍처지난 수십 년간 시스템 아키텍처들이다. 육각형 아키텍처(Hexagonal Architecture) 포트와 어댑터(Ports and Adapters)라고도 알려졌으며, 앨리스터 코오빈(Alistair Cockburn)이 개발했다. 그리고 스티브 프리먼(Steve Freeman)과 냇 프라이스(Nat Pryce)가 그들의 훌륭한 저서인 테스트 주도 개발로 배우는 객체지향 설계와 실천에서 차용했다. DCI(Data, Context and Interaction) 제임스 코플리언(James Coplien)과 트리그베 린스쿠주(Trygve Reenskaug)가 만들었다. BCE(Boundary-Control-Entity) 이바 야콥슨이 자신의 저서인 Object Oriented Software Engineering에서 소개했다. 이들의 목표는 모두 같은데, 바로 관심사의 분리(separation of converns)다. 이들은 모두 소프트웨어를 계층으로 분리함으로써 관심사의 분리라는 목표를 달성할 수 있었다. 각 아키텍처는 최소한 업무 규칙을 위한 계층하나와, 사용자와 시스템 인터페이스를 위한 또 다른 계층 하나를 반드시 포함한다.이들 아키텍처는 시스템에 아래와 같은 특징이 나타나도록 만든다. 프레임워크 독립성 아키텍처는 프레임워크에 존재 여부에 의존하지 않는다. 이를 통해 프레임워크를 도구로 사용하며 프레임워크의 제약사항안으로 시스템을 욱여 넣도록 강제하지 않는다. 테스트 용이성 업무 규칙은 UI, 데이터베이스, 웹 서버, 또는 여타 외부 요소가 없어도 테스트 할 수 있다. UI 독립성 시스템의 나머지 부분을 변경하지 않고도 UI를 쉽게 변경할 수 있다. 데이터베이스 독립성 오라클이나 MS SQL서버를 몽고 DB 등으로 교체할 수 있다. 업무 규칙은 데이터베이스에 결합되지 않는다. 모든 외부 에이전시에 대한 독립성 실제로 업무 규칙은 외부 세계와의 인터페이스에 대해 전혀 알지 못한다. 클린 아키텍처의존성 규칙클린 아키텍처에서 각각의 동심원은 소프트웨어에서 서로 다른 영역을 표현한다. 보통 안으로 들어갈수록 고수준의 소프트웨어가 된다. 바깥쪽 원은 메커니즘이고, 안쪽 원은 정책이다.이러한 아키텍처가 동작하도록 하는 가장 중요한 규칙은 의존성 규칙(Dependency Rule)이다.소스 코드 의존성은 반드시 안쪽으로, 고수준의 정책을 향해야 한다.내부의 원에 속한 요소는 외부의 원에 속한 어떤 것도 아지 못한다. 특히 내부의 원에 속한 코드는 외부의 원에 선언된 어떤 것에 대해서도 그 이름을 언급해서는 절대 안된다.같은 이유로, 외부의 원에 선언된 데이터 형식도 내부의 원에서 절대로 사용해서는 안 된다. 특히 그 데이터 형식이 외부의 원에 있는 프레임워크가 생성한 것이라면 더더욱 사용해서는 안된다. 우리는 외부 원에 위치한 어떤 것도 내부의 원에 영향을 주지 않기를 바란다.엔티티엔티티는 전사적인 핵심 업무 규칙을 캡슐화 한다. 엔티티는 메서드를 가지는 객체이거나 일련의 데이터 구조와 함수의 집합일 수도 있다.다양한 애플리케이션에서 엔티티를 재사용할 수만 있다면, 그 형태는 그다지 중요하지 않다.전사적이지 않은 단순한 단일 애플리케이션을 작성하고 있다면 엔티티는 해당 애플리케이션의 업무 객체가 된다. 특정 어플리케이션에 만 국한되어 있는 엔티티라면 코어가 따로 존재한다는 뜻이 된다. 전체적으로 관리하는 Core와 각 애플리케이션에서 관리하는 CoreCore├─────── Application├─────── DomainService└─────── Core ├──── Application ├──── Domain운영 관점에서 특정 애플리케이션에 무언가 변경이 필요하더라도 엔티티 계층에는 절대로 영향을 주어서는 안 된다.유스케이스유스케이스 계층의 소프트웨어는ㄴ 애플리케이션에 특화된 업무 규칙을 포함한다. 또한 유스케이스 계층의 소프트웨어는 시스템의 모든 유스케이스를 캡슐화하고 구현한다.유스케이스는 엔티티로 들어오고 나가는 데이터 흐름을 조정하며, 엔티티가 자신의 핵심 업무 규칙을 사용해서 유스케이의 목적을 달성하도록 이끈다.이 계층에서 발생한 변경이 엔티티에 영향을 줘서는 안 된다. 유스케이스 계층은 관심사(DB,UI 등)로부터 격리되어야 한다.하지만 운영 관점에서 애플리케이션이 변경된다면 유스케이스가 영향을 받으며, 따라서 이 계층의 소프트웨어에도 영향을 줄 것이다. 유스케이스의 세부사항이 변하면 이 계층의 코드 일부는 분명 영향을 받을 것이다.인터페이스 어댑터인터페이스 어댑터(Interface Adapter) 계층은 일련의 어댑터들로 구성된다. 어댑터는 데이터를 유스케이스와 엔티티에게 가장 편리한 형식으로 데이터베이스나 웹 같은 외부 에이전시에게 가장 편리한 형식으로 변환한다.프레진터(Presenter), 뷰(View), 컨트롤러(Controller)는 모두 인터페이스 어댑터 계층에 속한다.모델은 그저 데이터 구조 정도에 지나지 않으며, 컨트롤러에서 유스케이스로 전달되고, 다시 유스케이스에서 프레젠터와 뷰로 되돌아 간다.마찬가지로 이 계층은 데이터를 엔티티와 유스케이스에게 가장 편리한 형식에서 영속성용으로 사용 중인 임의으이 프레임워크(즉, 데이터베이스)가 이용하기에 가장 편리한 형식으로 변환한다. 이 원 안에 속한 어떤 코드도 데이터베이스에 대해 알아서는 안된다.이 계층에는 데이터를 외부 서비스와 같은 외부적인 형식에서 유스케이스나 엔티티에서 사용되는 내부적인 형식으로 변환하는 또 다른 어댑터가 필요하다. 인터페이스 어댑터 계층은 Usecase만 사용하지 DB가 어떤 건지는 관련하지 않는다. 인터페이스만 사용한다는 것이고 구현체가 무엇인지는 중요하지 않다. 데이터만 잘 가져오면 된다.프레임워크 드라이버아키텍처에서 가장 바깥쪽 계층은 일반적으로 데이터베이스나 웹 프레임워크 같은 프레임워크나 도구들로 구성된다. 일반적으로 이 계층에서는 안쪽원과 통신하기 위한 접합 코드 외에는 특별히 더 작성해야 할 코드가 그다지 많지 않다.프레임워크와 드라이버 계층은 모든 세부사항이 위치하는 곳이다. 웹은 세부사항이다. 데이터베이스는 세부사항이다.우리는 이러한 것들을 모두 외부에 위치시켜서 피해를 최소화해야한다.원은 네 개여야만 하나?네 개보다 더 많은 원이 필요할 수도 있다. 항상 네개만 사용해야 한다는 규칙은 없다. 하지만 어떤 경우에도 의존성 규칙은 적용된다.소스코드 의존성은 항상 안쪽으로 향한다. 안쪽으로 이동할수도록 추상화와 정책의 수준은 높아진다. 가장 바깥쪽 원은 저수준의 구체적인 세부사항으로 구성된다.경계 횡단하기 경계 횡단하기아키텍처의 우측하단 다이어그램에 원의 경계를 횡단하는 방법을 보여주는 예시가 있다. 이 예시에서 컨트롤러와 프레젠터가 다음 계층에 속한 유스케이스와 통신하는 모습을 확인할 수 있다.제어흐름은 컨트롤러로 시작해서, 유스케이스를 지난 후, 프레젠터에서 실행되면서 마무리된다. 각 의존성은 유스케이스를 향해 안쪽을 가리킨다이처럼 제어흐름과 의존성의 방향이 명백히 반대여야 하는 경우, 대체로 의존성 역전 원칙을 사용해 해결한다.우리는 동적 다형성을 이용하여 소스 코드 의존성을 제어흐름과는 반대로 만들수 있고, 이를 통해 제어흐름이 어느 방향으로 흐르더라도 의존성 규칙을 준수할 수 있다.경계를 횡단하는 데이터는 어떤 모습인가??경계를 가로지르는 데이터는 흥히 간단한 데이터 구조로 이루어져 있다. 기본적인 구조체나 간단한 데이터 전송 객체(data transfer object) 등 원하는 대로 고를 수 있다. 또는 함수를 호출할 때 간단한 인자를 사용해서 데이터로 전달할 수도 있다.중요한 점은 격리되어 있는 간단한 데이터 구조가 경계를 가로질러 전달된다는 사실이다. 꾀를 부려서 엔티티 객체나 데이터베이스의 행(row)을 전달하는 일은 원치 않는다. 우리는 데이터 구조가 어떤 의존성을 가져 의존성 규칙을 위배하게 되는 일은 바라지 않는다.전형적인 시나리오아래의 다이어 그램은 데이터베이스를 사용하는 웹 기반 자바 시스템의 전형적인 시나리오이다. 데이터베이스를 사용하는, 웹 기반 자바 시스템의 전형적인 시나리오웹 서버가 사용자로부터 입력 데이터를 모아 좌측 상단의 Controller로 전달한다. Controller는 데이터를 자바 객체(POJO)로 묶은 후, InputBoundary 인터페이스를 통해 UseCaseInteractor로 전달하고 UseCaseInteractor는 데이터를 해석하여 Entities를 어떻게 사용할지 제어하는 데 사용한다.Presentoer는 OutputData를 ViewModel과 같이 화면에 출력 할 수 있느 형식으로 재구성하는 일이다. View는 이 데이터를 화면에 출력한다.의존성의 방향에 주목해야 한다. 모든 의존성은 경계선을 안쪽으로 가로지르며, 따라서 의존성 규칙을 준수한다.결론이상의 간단한 규칙들을 준수하는 일은 어렵지 않으며, 향후에 겪을 수많은 고통거리를 덜어줄 것이다. 소프트웨어를 계층으로 분리하고 의존성 규칙을 준수한다면 본질적으로 테스트하기 쉬운 시스템을 만들게 될 것이며, 그에 따른 이점을 누릴 수 있다." }, { "title": "21장. 소리치는 아키텍처", "url": "/posts/PPPCleanArchitecture_ch21/", "categories": "DDD, 클린 아키텍처 소프트웨어 구조와 설계의 원칙, 5부 아키텍처", "tags": "DDD, CleanArchitecture", "date": "2022-05-13 23:30:00 +0900", "snippet": "소개클린아키텍처: 소프트웨어 구조와 설계의 원칙 책을 읽고 정리하며 소감을 적는 포스트입니다.소리치는 아키텍처건물의 청사진을 살펴보고 있다고 상상해보자. 아키텍트가 작성한 건물에 대한 일련의 계획을 보여주고 있다.계획서가 사람이 거주 할 주택이라면 정문, 거실로 연결되는 현관, 그리고 부엌 가족방 등이 있을 가능성이 높다. 이러한 계획서를 보면 이건 한 가족이 사는 주택이라는 느낌을 받을 것이다. 다시 말해, 아키텍처가 난 집이야!!라고 소리칠 것이다.자, 여러분의 애플리케이션 아키텍처는 뭐라고 소리치는가? 상위 수준의 디렉터리 구조, 최상위 패키지에 담긴 소스 파일을 볼 때, 이 아키텍처는 \"헬스케어 시스템이야!\", \"재고 관리 시스템이야!\"라고 소리치는가??아니면 \"스프링이야!\", \"ASP야!!\"라고 소리치는가??아키텍처의 테마이바 야콥슨(Ivar Jacobson)이 쓴 Object Oriented Software Engineering이라는 책의 부제가 유스케이스 주도 접근법(Use Case Driven Approach)이다.야콥슨은 소프트웨어 아키텍처는 시스템의 유스케이스를 지원하는 구조라고 지적했다. 주택이나 도서관의 계획서가 해당 건축물의 유스케이스에 대해 소리치는 것처럼, 소프트웨어 애플리케이션의 아키텍처도 애플리케이션의 유스케이스에 대해 소리쳐야 한다.아키텍처는 프레임워크에 대한 것이 아니다. 아키텍처를 프레임워크로부터 제공받아서는 절대 안 된다.아키텍처를 프레임워크 중심으로 만들어버리면 유스케이스가 중심이 되는 아키텍처는 절대 나올 수 없다.아키텍처의 목적좋은 아키텍처는 유스케이스를 그 중심에 두기 때문에, 프레임워크나 도구, 환경에 전혀 구애받지 않고 유스케이스를 지원하는 구조를 아무런 문제 없이 기술할 수 있다.좋은 소프트웨어 아키텍처는 프레임워크, 데이터베이스, 웹 서버, 그리고 여타 개발 환경 문제나 도구에 대해서는 결정을 미룰 수 있도록 만든다.좋은 아키텍처는 유스케이스에 중점을 두며, 지엽적인 관심사에 대한 결합은 분리시킨다.하지만 웹은??웹은 아키텍처일까?? 시스템이 웹을 통해 전달된다는 사실이 시스템의 아키텍처에 영향을 주는가? 당연히 아니다! 웹은 전달 메커니즘(입출력 장치)이며, 애플리케이션 아키텍처에서도 그와 같이 다뤄야 한다.실제 애플리케이션을 웹으로 전달할지 여부는 미루어야 할 결정사항 중 하나다. 시스템 아키텍처는 시스템이 어떻게 전다로딜지에 대해 가능하다면 아무것도 몰라야 한다.시스템을 콘솔 앱, 웹 앱, 리크 클라이언트 앱, 심지어 웹서비스 앱으로도 전달할 수 있어야 한다.프레임워크는 도구일 뿐, 삶의 방식은 아니다.프레임워크는 매우 강력하고 상당히 유용할 수 있다. 프레임워크 제작자는 자신이 만든 프레임워크를 매우 깊이 신뢰하곤 한다. 프레임워크를 사용하는 방식을 보여주면서, 흔히 모든 것을 아우르는, 어디에나 스며드는, “프레임워크가 모든 것을 하게하자”라는 태도를 취한다.이는 우리가 취하고 싶은 태도가 아니다어떻게 하면 아키텍처를 유스케이스에 중점을 둔 채 그대로 보전할 수 있을지를 생각하라. 프레임워크는 아키텍처의 중심을 차지하는 일을 막을 수 있는 전략을 개발하라.테스트하기 쉬운 아키텍처아키텍처가 유스케이스를 최우선으로 한다면, 그리고 프레임워크와는 적당한 거리를 둔다면, 프레임워크를 전혀 준비하지 않더라도 필요한 유스케이스 전부에 대해 단위 테스트를 할 수 있어야 한다.테스트를 돌리는 데 웹 서버가 반드시 필요한 상황이 되어서는 안 된다. 데이터베이스가 반드시 연결되어 있어야만 테스트를 돌리 수 잇어서도 안 된다.엔티티 객체는 반드시 오래 된 방식의 간단한 객체(plain old object)여야 하며, 프레임워크나 데이터베이스, 또는 여타 복잡한 것들에 의존해서는 안 된다.최종적으로, 프레임워크로 인한 어려움을 겪지 않고도 반드시 이 모두를 있는 그대로 테스트 할 수 있어야 한다.결론아키텍처는 시스템을 이야기해야 하며, 시스템에 적용한 프레임워크에 대해 이야기해서는 안 된다.새로 합류한 프로그래머는 시스템이 어떻게 전달될지 알지 못한 상태에서도 시스템의 모든 유스케이스를 이해할 수 있어야 한다.언젠가 이들은 당신을 찾아와서 이렇게 말할 것이다.“모델처럼 보이는 것들을 확인했습니다. 그런데 뷰와 컨트롤러는 어디에 있죠?”그러면 당신은 이와 같이 답해야 한다.“아, 그것은 세부사항이므로 당장슨 고려할 필요가 없습니다. 나중에 결정 할 겁니다.”" }, { "title": "20장. 업무 규칙", "url": "/posts/PPPCleanArchitecture_ch20/", "categories": "DDD, 클린 아키텍처 소프트웨어 구조와 설계의 원칙, 5부 아키텍처", "tags": "DDD, CleanArchitecture", "date": "2022-05-13 22:50:00 +0900", "snippet": "소개클린아키텍처: 소프트웨어 구조와 설계의 원칙 책을 읽고 정리하며 소감을 적는 포스트입니다.업무 규칙애플리케이션을 업무 규칙과 플러그인으로 구분하려면 업무 규칙이 실제로 무엇인지를 잘 이해해야만 한다.엄밀하게 말하면 업무 규칙은 사업적으로 수익을 얻거나 비용을 줄일 수 있는 규칙 또는 절차다. 더 엄밀하게 말하면 컴퓨터상으로 구현했는지와 상관없이, 업무 규칙은 사업적으로 수익을 얻거나 비용을 줄일 수 있어야 한다.대출에 N% 이자를 부과한다는 사실은 은행이 돈을 버는 업무 규칙이다. 이건 사람이든 컴퓨터 프로그램이는 하등 관계가 없다.이러한 규칙을 핵심 업무 규칙(Critical Business Rule)이라고 부를 것이다. 이들 규칙은 사업 자체의 핵심적이며, 규칙을 자동화하는 시스템이 없더라도 업무 규칙은 그대로 존재하기 때문이다.핵심 규칙과 핵심 데이터는 본질적으로 결합되어 있기 때문에 객체로 만들 좋은 후보가 된다. 우리는 이러한 유형의 객체를 엔티티(Entity)라고 하겠다.엔티티엔티티는 컴퓨터 시스템 내부의 객체로서, 핵심 업무 데이터를 기반으로 동작하는 일련의 조그만 핵심 업무 규칙을 구체화한다. 엔티티 객체는 핵심 업무 데이터를 직접 포함하거나 핵심 업무 데이터에 매우 쉽게 접근할 수 있다.인티티의 인터페이스는 핵심 업무 데이터를 기반으로 동작하는 핵심 업무 규칙을 구현한 함수들로 구성된다.아래의 그림은 대출을 뜻하는 Loan 엔티티가 UML 클래스로 어떻게 표현되는지 보여준다. 세 가지 핵심 업무 데이터를 포함하며, 데이터와 관련된 세 가지 핵심 업무 규칙을 인터페이스로 제공한다.classDiagram class Loan{ - principle - rate - period + makePayment() + applyInterest() + chargeLateFee() } UML 클래스로 표현한 Loan 엔티티이 클래스는 업무의 대표자로서 독립적으로 존재한다. 이 클래스는 데이터베이스, 사용자 인터페이스, 서드파티 프레임워크에 대한 고려사항들로 인해 오염되어서는 절대 안 된다.엔티티는 순전히 업무에 대한 것이며, 이외의 것은 없다.유스케이스모든 업무 규칙이 엔티티처럼 순수한 것은 아니다. 자동화된 시스템이 동작하는 방법을 정의하고 제약함으로써 수익을 얻거나 비용을 줄이는 업무 규칙도 존재한다.유스케이스는 자동화된 시스템이 사용되는 방법을 설명한다. 유스케이스는 사용자가 제공하는 입력, 사용자에게 보여줄 출력, 그리고 해당 출력을 생성하기 위한 처리 단계를 기술한다.엔티티 내의 핵심 업무 규칙과는 반대로, 유스케이스는 애플리케이션에 특화된(application-specific) 업무 규칙을 설명한다.유스케이스는 엔티티 내부의 핵심 업무 규칙을 어떻게 그리고 언제 호출할지를 명시하는 규칙을 담는다.주목할 또 다른 사실은 인터페이스로 들어오는 데이터와 인터페이스에서 되돌려주는 데이터를 형식 없이 명시한다는 점만 빼면, 유스케이스는 사용자 인터페이스를 기술하지 않는다는 점이다. 유스케이스만 봐서는 애플리케이션이 웹을 통해 전달되는지, 리치 클라이언트인지, 콘솔인지 구분하기란 불가능하다. 유스케이스 예제유스케이스는 시스템이 사용자에게 어떻게 보이는지를 설명하지 않는다. 이보다는 애플리케이션에 특화된 규칙을 설명하며, 이를 통해 사용자와 엔티티 사이의 상호작용을 규정한다. 시스템에서 데이터가 들어오고 나가는 방식은 유스케이스와는 무관하다.유스케이스는 객체다. 유스케이스는 애플리케이션에 특화된 업무 규칙을 구현하는 하나 이상의 함수를 제공한다. 또한 유스케이스는 입력 데이터, 출력 데이터, 유스케이스가 상호작용하는 엔티티에 대한 참조 데이터 등의 데이터 요소를 포함한다.왜 엔티티는 고수준이며, 유스케이스는 저수준일까? 왜냐하면 유스케이스는 단일 애플리케이션에 특화되어 있으며, 따라서 해당 시스템의 입력과 출력에 보다 가깝게 위치하기 때문이다.요청 및 응답 모델유스케이스는 입력 데이터를 받아서 출력 데이터를 생성한다. 제대로 구성된 유스케이스 객체라면 데이터를 사용자나 또 다른 컴포넌트와 주고 받는 방식에 대해서는 전혀 눈치챌 수 없어야 한다.데이터 구조는 HttpRequest나 HttpResponse 같은 표준 프레임 워크 인터페이스로부터 파생되지 않는다. 웹뿐만 아니라 그 어떤 사용자 인터페이스에도 종속되는 게 아무것도 없다.이 처럼 의존성을 제거하는 일은 매우 중요하다. 요청 및 응답 모델이 독립적이지 않다면, 그 모델에 의존하는 유스케이스도 결국 해당 모델이 수반하는 의존성에 간접적으로 결합되어 버린다.엔티티와 요청/응답 모델은 상당히 많은 데이터를 공유하므로 엔티티를 요청/응답 모델에 참조를 걸고 싶은 유혹을 받을 수 있다.하지만 두 객체의 목적은 완전히 다르며 시간이 지나면 두 객체는 완전히 다른 이유로 변경될 것이고, 따라서 두 객체를 어떻 식으로든 함께 묶는 행위는 공통 폐쇄 원칙과 단일 책임 원칙을 위배하게 된다.결론업무 규칙은 소프트웨어 시스템이 존재하는 이유다. 업무 규칙은 핵심적인 기능이다.업무 규칙은 사용자 인터페이스나 데이터베이스와 같은 저수준의 관심사로 인해 오염되어서는 안 되며, 원래 그대로의 모습으로 남아 있어야 한다.업무 규칙은 시스템에서 가장 독립적이며 가장 많이 재사용할 수 있는 코드여야 한다." }, { "title": "19장. 정책과 수준", "url": "/posts/PPPCleanArchitecture_ch19/", "categories": "DDD, 클린 아키텍처 소프트웨어 구조와 설계의 원칙, 5부 아키텍처", "tags": "DDD, CleanArchitecture", "date": "2022-05-13 22:00:00 +0900", "snippet": "소개클린아키텍처: 소프트웨어 구조와 설계의 원칙 책을 읽고 정리하며 소감을 적는 포스트입니다.정책과 수준소프트웨어 시스템이란 정책을 기술한 것이다. 컴퓨터 프로그램은 각 입력을 출력으로 변환하는 정책을 상세하게 기술한 설명서다.대다수의 주요 시스템에서 하나의 정책은 이 정책을 서술하는 여러 개의 조그만 정책들로 쪼갤 수 있다.소프트웨어 아키텍처를 개발하는 기술에는 이러한 정책을 신중하게 분리하고, 정책이 변경되는 양상에 따라 정책을 재편성하는 일도 포함된다. 동일한 이유로 동일한 시점에 변경되는 정책은 동일한 수준에 위치하며, 동일한 컴포넌트에 속해야 한다. 서로 다른 이유로, 혹은 다른 시점에 변겨오디는 정책은 다른 수준에 위치하며, 반드시 다른 컴포넌트로 분리해야 한다.흔히 아키텍처 개발은 재편성된 컴포넌트들을 비순환 방향 그래프(directed acyclic graph)로 구성하는 기술을 포함한다. 그래프에서 정점(node)은 동일한 수준의 정책을 포함하는 컴포넌트에 해당한다. 방향이 있는 간선(edge)은 컴포넌트 사이의 의존성을 나타낸다. 간선은 다른 수준에 위치한 컴포넌트를 서로 연결한다.이러한 의존성은 소스 코드, 컴파일타임의 의존성이다. 자바의 import, C#의 using 구문이다. 이러한 의존성은 컴파일러가 제대로 동작하기 위해서 필요하다.좋은 아키텍처라면 각 컴포넌트를 연결할 때 의존성의 방향이 컴포넌트의 수준을 기반으로 연결되도록 만들어야 한다. 즉, 저수준 컴포넌트가 고수준 컴포넌트에 의존하도록 설계되어야 한다.수준수준(level)을 엄밀하게 정의하자면 입력과 출력까지의 거리다. 시스템의 입력과 출력 모두로부터 멀리 위치할수록 정책의 수준은 높아진다. 입력과 출력을 다루는 정책이라면 시스템에서 최하위 수준에 위치한다.아래의 데이터흐름도는 간단한 암호화 프로그램이다. 데이터의 흐름은 굽은 실선 화살표, 소스 코드 의존성은 곧은 점선으로 표시되어야 한다. 간단한 암호화 프로그램번역 컴포넌트는 최고 수준의 컴포넌트인데, 입력과 출력에서부터 가장 멀리 떨어져 있기 때문이다.주목할 점은 데이터 흐름과 소스 코드 의존성이 항상 같은 방향을 가리키지 않는다는 사실이다. 다시 한번 말하지만 이것이 바로 소프트웨어 아키텍처가 가진 예술 중하나다. 소스 코드 의존성은 그 수준에 따라 결합되어야 하며, 데이터 흐름을 기준으로 결합되어서는 안 된다.자칫하면 잘못된 아키텍처가 만들어지는데, 예를 들어 암호화 프로그램을 다음처럼 작성한다면 그렇게 된다.fuction encrypt(){ while(true) writeChar(translate(readChar()));}고수준인 encrypt 함수가 저수준인 readChar와 writeChar 함수에 의존하기 때문이다.아래의 클래스 다이어그램은 개선해본 모습니다. Encrypt 클래스, CharWriter와 CharReader 인터페이스를 둘러싸고 있는 점선으로 된 경계다. 이 경계를 횡단하는 의존성은 모두 경계 안쪽으로 향한다. 이 경계로 묶인 영역이 이 시스템에서 최고 수준의 구성요소다. 시스템의 더 나은 아키텍처를 보여주는 클래스 다이어그램정책을 컴포넌트로 묶는 기준은 정책이 변경되는 방식에 달려있다는 사실을 상기하자. 단일 책임 원칙(SRP)과 공통 폐쇄 원칙(CCP)에 따르면 동일한 이유로 동일한 시점에 변경되는 정책은 함께 묶인다.고수준 정책, 즉 입력과 출력에서부터 멀리 떨어진 정책은 저수준 정책에 비해 덜 빈번하게 변경되고, 보다 중요한 이유로 변경되는 경향이 있다. 저수준 정책, 즉 입력과 출력에 가까이 위치한 정책은 더 빈번하게 변경되며, 보다 긴급성을 요하며, 덜 중요한 이유로 변경되는 경향이 있다.모든 소스코드 의존성의 방향이 고수준 정책을 향할 수 있도록 정책을 분리했다면 변경의 영향도 줄일 수 있다. 시스템의 최저 수준에서 중요하지 않지만 긴급한 변경이 발생하더라도, 보다 높은 위치의 중요한 수준에 미치는 영향은 거의 없게 된다.이 논의는 저수준 컴포넌트가 고수준 컴포넌트에 플러그인되어야 한다는 관점에서 바라볼 수도 있다. Encryption 컴포넌트는 IO Devices 컴포넌트를 전혀 알지 못한다. 저수준 컴포넌트는 고수준 컴포넌트에 플러그인되어야 한다.결론정책에 대한 논의는 단일 책임 원칙, 개발 폐쇄 원칙, 공통 폐쇄 원칙, 의존성 역전 원칙, 안정된 의존성 원칙, 안정된 추상화 원칙을 모두 포함한다.이 원칙들의 설명을 다시 읽어 보며 각 원칙이 어디에서 무슨 이유로 사용되었는지를 찾아보자." }, { "title": "18장. 경계 해부학", "url": "/posts/PPPCleanArchitecture_ch18/", "categories": "DDD, 클린 아키텍처 소프트웨어 구조와 설계의 원칙, 5부 아키텍처", "tags": "DDD, CleanArchitecture", "date": "2022-05-13 21:00:00 +0900", "snippet": "소개클린아키텍처: 소프트웨어 구조와 설계의 원칙 책을 읽고 정리하며 소감을 적는 포스트입니다.경계 해부학시스템 아키텍처는 일련의 소프트웨어 컴포넌트와 그 컴포넌트들을 분리하는 경계에 의해 정의 된다.이번 장에서는 경계의 다양한 형태를 알아본다.경계 횡단하기런타임에 경계를 횡단한다함은 그저 경계 한쪽에 있는 기능에서 반대편 기능을 호출하여 데이터를 전달하는 일에 불과하다.적절한 위치에서 경계를 횡당하게 하는 비결은 소스 코드 의존성 관리에 있다.소스 코드 모듈이 변경되면 의존되는 다른 소스 코드도 다시 컴파일하고 배포해야 한다.경계는 이러한 변경이 전파 되는 것을 막는 방화벽을 구축하고 관리하는 수단으로써 존재한다.두려운 단일체아키텍처 경계 중에서 가장 단순하며 가장 흔한 형태는 물리적으로 엄격하게 구분되지 않는 형태다.이 형태에서는 함수와 데이터가 단일 프로세서에서 같은 주소 공간을 공유하며 그저 나름의 규칙에 따라 분리되어 있을 뿐이다. 이전 장에서는 나는 이를 소스 수준 분리 모드라고 불렀다.배포 관점에서는 소위 단일체(monolith)라고 불리는 단일 실행 파일에 지나지 않는다. 배포 관점에서 볼 때 단일체는 경계가 드러나지 않는다.가장 단순한 형태의 경계 횡단은 저수준 클라이언트에서 고수준 서비스로 향하는 함수 호출이다. 이 경우 런타임 의존성과 컴파일타임 의존성은 모두 같은 방향, 즉, 저수준 컴포넌트에서 고수준 컴포넌트로 향한다. 제어흐름은 경계를 횡단할 때 저수준에서 고수준으로 향한다.고수준 클라이언트가 저수준 서비스를 호출해야 한다면 동적 다형성을 사용하여 제어흐름과는 반대 방향으로 의존성을 역전시킬 수 있다. 이렇게 하면 런타임 의존성은 컴파일타임 의존성과는 반대가 된다. 제어흐름은 반대로 경계를 횡단한다.정적 링크된 모노리틱 구조의 실행 파일이라도 이처럼 규칙적인 방식으로 구조를 분리하면 프로젝트를 개발, 테스트, 배포하는 작업에 큰 도움이 된다.팀들은 서로의 영역에 침범하지 않은 채 자신만의 컴포넌트를 독립적으로 작업할 수 있다. 고수준 컴포넌트는 저수준 세부사항으로부터 독립적으로 유지된다.배포형 컴포넌트아키텍처의 경계가 물리적으로 드러날 수도 있는데 그중 가장 단순한 형태는 동적 링크 라이브러리다. .NET DLL, 자바 jar파일 등이 그예이다.단일체와 마찬가지로 배포형 컴포넌트의 경계를 가로지르는 통신은 순전히 함수 호출에 지나지 않으므로 매우 값싸다. 동적 링크와 런타임 로디으로 인해 최초의 함수 호출은 오래 걸릴 수도 있지만, 이들 경계를 가로지르는 통신은 매우 빈번할 것이다.스레드단일체와 배포형 컴포넌트는 모두 스레드를 활용할 수 있다. 스레드는 아키텍처 경계도 아니며 배포 단위도 아니다. 이보다 스레드는 실행 계획과 순서를 체계화하는 방법에 가깝다. 모든 스레드가 단 하나의 컴포넌트에 포함될 수도 있고, 많은 컴포넌트에 걸쳐 분산될 수도 있다.로컬 프로세스훨씬 강한 물리적 형태를 띠는 아키텍처 경계로는 로컬 프로세스가 있다. 로컬 프로세스는 주로 명령행이나 그와 유사한 시스템 호출을 통해 생성 된다.각 로컬 프로세스는 정적으로 링크된 단일체이거나 동적으로 링크된 여러개의 컴포넌트로 구성될 수 있다. 전자의 경우, 여러 모노리틱 프로세스가 같은 컴포넌트들을 가지고 있을 수 있다.(컴파일하고 정적 링크하는 과정에서 각 컴포넌트의 바이너리가 단일체에 물리적으로 복사되어 들어가기 때문이다.). 반면 후자의 경우, 동적 링크된 배포형 컴포넌트들을 서로 공유할 수 있다.로컬 프로세스를 일정의 최상위 컴포넌트라고 생각하자. 즉, 로컬 프로세스는 컴포넌트 간 의존성을 동적 다형성을 통해 관리하는 저수준 컴포넌트로 구성된다.로컬 프로세스 간 분리 전략은 단일체나 바이너리 컴포넌트의 경우와 동일하다. 소스 코드 의존성의 화살표는 단일체나 바이너리 컴포넌트와 동일한 방향으로 경계를 횡단한다. 즉, 항상 고수준 컴포넌트를 향한다.서비스물리적인 형태를 띠는 가장 강력한 경계는 바로 서비스다. 서비스는 프로세스로, 일반적으로 명령행 또는 그와 동등한 시스템 호출을 통해 구동된다.서비스 경계를 지나는 통신은 함수 호출에 비해 매우 느리다. 가능하다면 빈번하게 통신하는 일을 피해야 한다. 이 수준의 통신에서는 지연(latency)에 따른 문제를 고수준에서 처리할 수 있어야 한다.저수준 서비스는 반드시 고수준 서비스에 플러그인되어야 한다. 고수준 서비스의 소스 코드에는 저수준 서비스를 특정 짓는 어떤 물리적인 정보(예를 들면 URI)도 포함해서느 ㄴ안된다.결론단일체를 제외한 대다수의 시스템은 한 가지 이상의 경계 전략을 사용한다. 서비스 경계를 활용하는 시스템이라면 로컬 프로세스 경계도 일부 포함하고 있을 수 있다. 실제로 서비스는 상호작용하는 일련의 로컬 프로세스 퍼사드(Facade)에 불과할 때가 많다. 또한 개별 서비스 또는 로컬 프로세스는 거의 언제나 소스 코드 컴포넌트로 구성된 단일체이거나, 혹은 동적으로 링크된 배포형 컴포넌트의 집합니다.즉, 대체로 한 시스템 안에서도 통신이 빈번한 로컬 경계와 지연을 중요하게 고려해야 하는 경계가 혼합되어 있음을 의미한다." }, { "title": "17장. 경계,선긋기", "url": "/posts/PPPCleanArchitecture_ch17/", "categories": "DDD, 클린 아키텍처 소프트웨어 구조와 설계의 원칙, 5부 아키텍처", "tags": "DDD, CleanArchitecture", "date": "2022-05-10 22:00:00 +0900", "snippet": "소개클린아키텍처: 소프트웨어 구조와 설계의 원칙 책을 읽고 정리하며 소감을 적는 포스트입니다.경계: 선 긋기소프트웨어 아키텍처는 선을 긎는 기술이며, 나는 이러한 선을 경계(boundary)라고 부른다.경계는 소프트웨어 요소를 서로 분리하고, 경계 한편에 있는 요소가 반대편에 있는 요소를 알지 못하도록 막는다.프로젝트 초기에 그어진 선은 가능한 오랫동아 결정을 연기시키기 위해, 그래서 이들 결정이 핵심적인 업무 로직을 오염시키지 못하도록 만들려는 목적으로 쓰인다.아키텍트의 목표는 인적 자원을 최소화하는 것이다. 인적 자원의 효율을 떨어뜨리는 요인은 바로 결합(coupling)이다. 특히 너무 일찍 내려진 결정에 따른 결합이다.이러한 결정은 시스템의 업무 요구사항, 즉 유스케이스와 아무런 관련이 없는 결정이다. 프레임워크, 데이터베이스, 웹 서버, 유틸리티 라이브러리, 의존성 주입에 대한 결정들이 포함된다.좋은 시스템 아키텍처는 이러한 결정을 가능한 한 최후의 순간에 내릴 수 있게 해주며, 결정에 따른 영향이 크지 않게 만든다.두 가지 슬픈 이야기P사의 슬플 이야기먼저 P 회사의 슬픈 이야기는 1990년대 데스크톱 GUI 애플리케이션으로 성장했다. 하지만 웹이 대세가 되면서 자바 프로그래머를 다수 고용 했고, 자사 제품을 웹 버전으로 변환하는 프로젝트에 착수 했다.자바 진영 사람은 머릿속에 서버 팜(server farm)이 춤추는 이상을 꿈꾸었기에, 3-티어로 구성된 리치(rish) 아키텍처를 채택했고, 서버 팜을 통해 분산하고자 했다.서버 팜에는 GUI를 위한 서버, 미들웨어 서버, 데이터베이스 서버가 있었다. 이들 프로그래머는 모든 도메인 객체가 세 가지 인스턴스를 가져야 한다고 너무 이른 결정을 내렸다.하나는 GUI 티어를 위해, 또 하나는 미들웨어 티어를 위해, 나머지 하나는 데이터베이스 티어를 위해서이다.이들 인스턴스는 서로 다른 머신에 상주했기 때문에 티어 간 메서드 호출은 객체로 변환하여, 직렬화 한 후, 회선을 통해 마샬링(marshalling) 되었다.역설적이게도 P사는 서버 팜을 필요로 하는 시스템을 한번도 판매하지 못했다. 배포했던 시스템은 모두 단일 서버였다. 그리고 단일 서버에서 세 실행 파일은 객체 초기화, 직렬화, 마샬링과 언마샬링, 메시지 구성과 파싱, 소켓 통신들과 추가 작업들을 지속했다.P사의 실수는 아키텍트가 너무 이르게 결정을 내림으로써 개발 비용을 엄청나게 가중시킨 사례다.W사의 슬픈 이야기일련의 회사 차량을 관리하는 지역 기업인 W사를 살펴보자. 이들은 최근 아키텍트를 고용하였고, 그는 모든 특성이 구성된 엔터프라이즈급의 서비스 지향 아키텍처가 필요하다는 것을 파악했다.업무와 관련된 서로 다른 모든 객체들로 구성된 거대한 도메인 모델을 생성했고, 이들 도메인 객체를 관리하기 위해 서비스들의 묶음을 설계했으며, 모든 개발자를 지옥의 길로 밀어 넣었다.당연하겠지만 무언가를 테스트하려면 필요한 서비스들을 하나씩 구동시키고 메시지 버스와 BPel(Business Process Execution Language)서버 등을 작동시켜야 했다.이들 모든 서비스 사이의 결합으로 인해 엄청난 양의 WSDL(Web Services Description Language)를 변경해야하며, 변경에 영향받는 모든 것을 다시 배포해야 할 것이다.W사의 실수는 SOA를 약속하는 일련의 도구들을 너무 일찍 채택하여 적용했다는 사실이다.FitNesse나는 2001년에 FitNesse를 만들기로 하였다. 이때는 메이븐이 등장하여 jar 파일 문제를 해결하기 전이였다.우리가 초기에 내린 결정 중 하나는 FitNesse의 요구에 특화된 우리만의 웹서버를 직접 작성하자는 것이였다. 기본 뼈대만 갖춘 웹 서버는 단일 소프트웨어이기에 구현이 간단하고 어떤 웹 프로그램워크를 사용할지에 대한 결정을 훨씬 나중으로 연기할 수 있었다.초기에 내린 또 다른 결정은 데이터베이스에 대해 고민하지 말자는 것이였다. 어떤 데이터베이스를 사용하더라도 상관 없도록 설계하여 의도적으로 데이터베이스에 대한 결정을 미뤘다. 우리는 모든 데이터 접근 영역과 데이터 저장소 영역 사이에 인터페이스를 추가하는 간단한 설계 방식을 사용했다.자그마치 18개월 동안 데이터베이스가 없다는 사실은 스키마와 관련된 문제들, 쿼리 문제들, 데이터베이스 서버 문제들, 패스워드 문제들 그리고 데이터베이스를 작동시킬 때 추하게 고개를 드는 여타 모든 고약한 문제가 없었다는 사실을 뜻한다.테스트를 느리게 만드는 데이터베이스가 없으니 테스트 또한 빠르게 돌릴 수 있었다.간단히 말해서 경계선을 긋는 행위는 결정을 늦추고 연기하는 데 도움이 되었고, 궁극적으로는 시간을 엄청나게 절약해주었으며, 골치를 썩지 않게해주었다.어떻게 선을 그을까? 그리고 언제 그을까?관련이 있는 것과 없는 것 사이에 선을 긋는다. GUI는 업무 규칙과는 관련 없기 때문에, 이 둘 사이에는 반드시 선이 있어야 한다.데이터베이스는 GUI와는 관련이 없으므로, 이 둘 사이에도 반드시 선이 있어야 한다.데이터 베이스는 업무 규칙과 관련 없으므로, 이 둘 사이에도 선이 있어야 한다.데이터베이스는 업무 규칙이 간접적으로 사용할 수 있는 도구다. 업무 규칙은 스키마, 쿼리 언어, 또는 데이터베이스와 관련된 나머지 세부사항에 대해 어떤 것도 알아서는 안된다.아래의 그림에서 보면 BusinessRules는 Database Interface를 사용하여 데이터를 로드하고 저장한다. DatabaseAccess는 DatabaseInterface를 구현하며, Database를 실제로 자작하는 일을 맡는다. 인터페이스 뒤로 숨은 데이터베이스경계선은 어디에 있는가? 경계선은 상속 관계를 횡단하면서 Database Interface 바로 아래에 그어진다. 경계선이제 조금 물러 나서 많은 업무 규칙이 포함된 컴포넌트, 데이터베이스와 데이터베이스 접근 클래스를 포함하는 컴포넌트를 살펴본다 업무 규칙과 데이터베이스 컴포넌트Database는 BusinessRules에 대해 알고 있다. BusinessRules는 Database에 관해 알지 못한다. 이는 DatabaseInterface 클래스는 BusinessRules 컴포넌트에 속하며, DatabaseAccess 클래스는 Database 컴포넌트에 속한다는 사실을 의미한다.Database 컴포넌트는 다양한 구현체로 교체될 수 있으며, BusinessRules는 조금도 개의치 않는다.이 같은 사실은 데이터베이스에 대한 결정은 연기할 수 있으며, 데이터베이스를 결정하기에 앞서 업무 규칙을 먼저 작성하고 테스트하는 데 집중 할 수 있음을 의미한다.입력과 출력은?개발자와 고객은 종종 시스템이 무엇인지에 대해 혼란스러워한다. GUI를 보고선 GUI가 시스템이라고 생각하곤한다.우리는 시스템의 행위를 입출력이 지닌 행위적 측면에서 생각하는 경향이 있다. 예를 들어 비디오게임에서 사용자 경험은 인터페이스에 의해 좌우된다. 화면, 마우스, 버튼, 음향이 바로 그 인터페이스다.이러한 인터페이스 뒤에는 인터페이스를 조작하는 모델(데이터 구조와 함수로 구성된 정교한 집합)이 존재한다는 사실을 잊어버린다.더 중요한 사실은 모델은 인터페이스가 필요하지 않다. 화면에 출력되지 않아도 돌아가는데 문제가 없다.중요한 것은 업무 규칙이다. GUI와 BusinessRules 컴포넌트 사이의 경계GUI와 BusinessRules 컴포넌트가 경계선에 의해 분할된다는 사실을 알 수 있다. GUI는 다른 종류의 인터페이스로 얼마든지 교체할 수 있다.플러그인 아키텍처데이터베이스와 GUI에 대해 내린 두 가지 결정을 하나로 합쳐서 보면 컴포넌트 추가와 관련한 일종의 패턴이 만들어진다. 이 패턴은 시스템에서 서드 파티 플러그인을 사용할 수 있게 한 바로 그 패턴과 동일하다.사실 소프트웨어 개발 기술의 역사는 플러그인을 손쉽게 생성하여, 확장 가능하며 유지보수가 쉬운 시스템 아키텍처를 확립할 수 있게 만드는 방법에 대한 이야기다.선택적이거나 또는 수많은 다양한 형태로 구현될 수 있는 나머지 컴포넌트로부터 핵심적인 업무 규칙은 불리되어 있고, 또한 독립적이다. 업무 규칙에 플러그인 형태로 연결하기이 설계에서 사용자 인터페이스는 플러그인 형태로 고려되었기에, 수많은 종류의 사용자 인터페이스를 플러그인 형태로 연결할 수 있게 된다.교체 작업은 사소한 것이 아닐 것이다. 시스템의 초기 배포본이 웹 기반이었다면 클라이언트-서버 UI용 플러그인을 작성하는 것은 쉽지 않은 일이 될 수 있다.그러다 하더라도 플러그인 구조를 가정할 채 시작함으로써, 최소한 우리는 이러한 변경 작업을 현실성 있도록 만들었다.플러그인에 대한 논의ReSharper와 비주얼 스튜디오(Visual Studio)의 관계를 보자. 어느 팀이 다른 팀을 위험하게 만들 수 있을까? 의존성 구조가 답해준다. ReSharper는 비주얼 스튜디오에 의존한다.ReSharper는 비주얼 스튜디오의 소스 코드에 의존하기 때문에 비주얼 스튜디오 팀은 원한다면 언제든지 ReSharper팀을 완전히 무력화할 수 있다.우리는 시스템에서 한 부분이 변경되더라도 관련 없는 나머지 부분이 망가지길 원치 않는다.경계는 변경의 축(axis of change)이 있는 지점에 그어진다. 경계의 한쪽에 위치한 컴포넌트는 경계 반대편의 컴포넌트와는 다른 속도로, 그리고 다른 이유로 변경된다.업무 규칙은 의존성 주입 프레임워크와는 다른 시점에 그리고 다른 이유로 변경되므로, 둘 사이에도 반드시 경계가 필요하다.이 역시도 순전히 단일 책임 원칙에 해당한다. 단일 책임 원칙은 어디에 경계를 그어야 할지를 알려준다.결론소프트웨어 아키텍처에서 경계선을 그리려면 먼저 시스템을 컴포넌트 단위로 분할해야 한다. 일부 컴포넌트는 핵심 업무 규칙에 해당한다.이는 의존성 역전 원칙과 안정된 추상화 원칙을 응용한 것임을 눈치챌 수 있어야 한다. 의존성 화살표는 저수준 세부사항에서 고수준의 추상화를 향하도록 배칳야 한다." }, { "title": "16장. 독립성", "url": "/posts/PPPCleanArchitecture_ch16/", "categories": "DDD, 클린 아키텍처 소프트웨어 구조와 설계의 원칙, 5부 아키텍처", "tags": "DDD, CleanArchitecture", "date": "2022-05-08 21:00:00 +0900", "snippet": "소개클린아키텍처: 소프트웨어 구조와 설계의 원칙 책을 읽고 정리하며 소감을 적는 포스트입니다.독립성좋은 아키텍처는 다음을 지원해야 한다. 시스템의 유스케이스 시스템의 운영 시스템의 개발 시스템의 배포유스케이스첫 번째 주요 항목인 유스케이스의 경우, 시스템의 아키텍처는 시스템의 의도를 지원해야 한다는 뜻이다.아키텍트의 최우선 관심사는 유스케이스이며, 아키텍처에서도 유스케이스가 최우선이다. 아키텍처는 반드시 유스케이스를 지원해야 한다.좋은 아키텍처가 행위를 지원하기 위해 할 수 있는 중에서 가장 중요한 사항은 행위를 명확히 하고 외부로 드러내며, 이를 통해 시스템이 지닌 의도를 아키텍처 수준에서 알아볼 수 있게 만드는 것이다.장바구니 애플리케이션이 좋은 아키텍처를 갖춘다면 이 애플리케이션은 장바구니 애플리케이션처럼 보일 것이다. 해당 시스템의 유스케이스는 시스템 구조 자체에서 한눈 에 들어날 것이다.이들 행위는 일급 요소(first-class)이며 시스템의 최상위 수준에서 알아볼 수 있으므로, 개발자가 일일이 찾아 헤매지 않아도 된다.운영시스템의 운영 지원 관점에서 볼 때 아키텍처는 더 실질적이며 덜 피상적인 역할을 맡는다. 아키텍처는 요구와 관련 된 각 유스케이스에 걸맞은 처리량와 응답시간을 보장해야 한다.이러한 형태를 지원한다는 말은 시스템에 따라 다양한 의미를 지닌다. 어떤 시스템에서는 시스템의 처리 요소를 일련의 작은 서비스들로 배열하여 서로 다른 많은 서버에서 병렬로 실행할 수 있게 만들어야 함을 의미한다.만약 시스템이 단일체(monolith)로 작성되어 모노리틱 구조를 갖는다면, 다중 프로세스, 다중 스레드, 또는 마이크로서비스 형태가 필요해질 때 개선하기 어렵다.그에 비해 아키텍처에서 각 컴포넌트를 적걸히 격리하고 유지하고 컴포넌트 간 통신 방싱을 특정 형태로 제한하지 않는다면, 시간이 지나 운영에 필요한 요구사항이 바뀌더라도 스레드, 프로세스, 서비스로 구성된 기술 스펙트럼 사이를 전환하는 일이 훨씬 쉬워질 것이다.개발아키텍처는 개발환경을 지원하는 데 있어 핵심적인 역할을 수행한다.콘웨이(Conway)의 법칙이 작용하는 지점이 바로 여기이다. 코누에이의 법칙은 다음과 같다.시스템을 설계하는 조직이라면 어디든지 그 조직의 의사소통 구조와 동일한 구조의 설계를 만들어 낼 것이다.많은 팀으로 구성되며 관심사가 다양한 조직에서 어떤 시스템을 개발해야 한다면, 각 팀이 독립적으로 행동하기 편한 아키텍처를 반드시 확보하여 개발하는 동안 팀들이 서로를 방해하지 않도록 해야한다.이러한 아키텍처를 만들려면 잘 격리되어 독립적으로 개발 가능한 컴포넌트 단위로 시스템을 분할 할 수 있어야 한다.그래야만 이들 컴포넌트를 독립적으로 작업할 수 있는 팀에 할당할 수 있다.배포아키텍처는 배포 용이성을 결정하는 데 중요한 역할을 한다. 이때 목표는 즉각적인 배포(immediate deployment)다.좋은 아키텍처는 수십 개의 작은 설정 스크립트나 속성 파일을 약간씩 수정하는 방식을 사용하지 않는다.좋은 아키텍처라면 시스템이 빌드된 후 즉각 배포할 수 있도록 지원해야 한다.‘다시 말하지만, 이러한 아키텍처를 만들려면 시스템을 컴포넌트 단위로 적절하게 분할하고 격리시켜야 한다.선태사항 열어놓기좋은 아키텍처는 컴포넌트 구조와 관련된 이 관심사들 사이에서 균형을 맞추고, 각 관심사 모두를 만족시킨다.말은 쉽지만 현실에서는 이러한 균형을 잡기가 매우 러렵다. 대부분의 경우 우리는 모든 유스케이스를 알 수는 없으며, 운영하는 데 따르는 제약사항, 팀 구조, 배포 요구사항도 알지 못하기 때문이다.더 심각한 문제는 이러한 사항들을 알고 있더라도, 시스템이 생명주기의 단계를 하나씩 거쳐감에 따라 이 사항들도 반드시 변해간다는 사실이다.하지만 몇몇 아키텍처 원칙을 구현하는 비용은 비교적 싸지 않으며, 관심사들 사이에서 균형을 잡는데 도움이 된다. 이들 원칙은 시스템을 제대로 격리된 컴포넌트 단위로 분할 할 때 도움이 되며, 이를 통해 선택사항을 가능한 한 많이, 그리고 가능한한 오랫동안 열어 둘 수 있게 해준다.좋은 아키텍처는 선택사항을 열어 둠으로써, 향후 시스템에 변경이 필요할 때 어떤 방향으로든 쉽게 변경할 수 있도록 한다.계층 결합 분리아키텍트는 필요한 모든 유스케이스를 지원할 수 있는 시스템 구조를 원하지만, 유스케이스 전부를 알지는 못한다.하지만 아키텍트는 시스템의 기본적인 의도는 분명히 알고 있다. 그 시스템이 장바구니 시스템인지, 자재 명세서 시스템인지 안다는 뜻이다.따라서 아키텍트는 단일 책임 원칙과 공통 폐쇄 원칙을 적용하여, 그 의도의 맥락에 따라서 다른 이유로 변경되는 것들은 분리하고, 동일한 이유로 변경되는 것들은 묶는다.사용자 인터페이스가 변경되는 이유는 업무 규칙과는 아무런 관련이 없다. 만약 유스케이스가 두 가지 요소를 모두 포함한다면, 유스케이스에서 UI 부분와 업무 규칙 부분을 서로 분리하고자 할 것이다.업무 규칙은 그 자체가 애플리케이션과 밀접한 관련이 있거나, 혹은 더 범용적일 수 있다. 예를 들어 입력 필드 유효성 검사는 애플리케이션 자체와 연관 된 업무 규칙이다.반대로 계좌의 이자 계산 같은 경우는 업무 도메인에 더 밀접하게 연관된 엄무 규칙이다.이들 규칙은 서로 분리하고, 독립적으로 변경할 수 있도록 만들어야만 한다.데이터베이스, 쿼리 언어, 스키마 조차도 업무 규칙이나 UI와는 아무런 관련이 없다. 결론적으로 아키텍트는 이들을 시스템의 나머지 부분으로부터 분리하여 독립적으로 변경할 수 있도록 해야만 한다.이제 우리는 서로 결합되지 않은 수평적인 계층으로 분리하는 방법을 알게 되었다.이러한 계층의 예로는 UI, 애플리케이션에 특화된 업무 규칙, 애플리케이션과는 독립적인 업무 규칙, 데이터베이스 등을 들 수 있다.유스케이스 결합 분리서로 다른 이유로 변경되는 것에는 또 무엇이 있을까? 바로 유스케이스 그 자체가 있다!주문 입력시스템에서 주문을 추가하는 유스케이스는 주문을 삭제하는 유스케이스와는 틀림없이 다른 속도로, 그리고 다른 이유로 변경된다. 유스케이스는 시스템을 분할하는 매우 자연스러운 방법이다.이와 같이 결합을 분리하려면 주문 추가 유스케이스의 UI와 주문 삭제 유스케이스의 UI를 분리해야 한다. 이런식으로 시스템의 맨 아래 계층까지 수직으로 내려가며 유스케이스들이 각 계층에서 서로 겹치지 않게 한다.여기에서 패턴을 볼 수 있다. 시스템에서 서로 다른 이유로 변경되는 요소들의 결합을 분리하면 기존 요소에 지장을 주지 않고도 새로운 유스케이스를 계속해서 추가할 수 있다.유스케이스가 UI와 데이터베이스의 서로 다른 관점(aspect)를 사용하게 되면, 새로운 유스케이스를 추가하더라도 기존 유스케이스에 영향을 주는 일은 거의 없을 것이다.결합 분리 모드이렇게 결합을 분리하면 두 번째 항목인 운영 관점에서 어떤 의미가 있는지 살펴본다. 수직, 수평 계층 분할 예시UI와 데이터베이스가 업무 규칙과 분리되어 있다면, UI와 데이터베이스는 업무 규칙과는 다른 서버에서 실행될 수 있다. 높은 대역폭을 요구사흔ㄴ 유스케이스는 여러 서버로 복제하여 실행할 수 있따.분리된 컴포넌트를 서로 다른 서버에서 실행해야 하는 상황이라면, 이들 컴포넌트가 단일 프로세서의 동일한 주소 공간에 함께 상주하는 형태가 만들어져서는 안 된다.분리된 컴포넌트는 반드시 독립된 서비스가 되어야 하고, 일정의 네트워크를 통해 서로 통신해야 한다.많은 아키텍트가 이러한 컴포넌트를 서비스(service) 또는 마이크로서비스(micro-service)라고 하는데, 실제로 서비스에 기반한 아키텍처를 흔히들 서비스 지향 아키텍처(service-oriented architecture)라고 부른다.여기서 이야기 하고자 하는 핵심은 우리는 때때로 컴포넌트를 서비스 수준까지도 분리해야 한다는 것이다.개발 독립성컴포넌트가 완전히 분리되면 팀 사이의 간섭은 줄어든다. 업무 규칙이 UI를 알지 못하면 UI에 중점을 둔 팀은 업무 규칙에 중점을 둔 팀에 그다지 영향을 줄 수 없다.기능팀, 컴포넌트 팀, 계층 팀, 혹은 또 다른 형태의 팀이라도, 계층과 유스케이스의 결합이 분리되는 한 시스템의 아키텍처는 그 팀 구조를 뒷받침해 줄 것이다.배포 독립성유스케이스와 계층의 결합이 분리되면 배포 측면에서도 고도의 유연성이 생긴다. 실제로 결합을 제대로 분리했다면 운영 중인 시스템에서도 계층과 유스케이스를 교체(hot-swap) 할 수 있다.중복소프트웨엉에서 중복은 일반적으로 나쁜 것이다. 우리는 중복된 코드를 좋아하지 않는다. 코드가 진짜로 중복되었다면, 우리는 전문가로서의 명예를 걸고 중복을 줄이거나 제거해야 한다.하지만 중복에도 종류가 있다. 그 중하나는 진짜 중복이다. 이 경우는 인스턴스가 변경되면, 동일한 변경을 그 인스턴스의 모든 복사본에 반드시 적용해야 한다.또 다른 중복은 거짓된 또는 우발적 중복이다. 중복으로 보이지만 두 코드 영역이 각자의 경로로 발전한다면, 즉 서로 다른 속도와 다른 이유로 변경된다면 이 두 코드는 진짜 중복이 아니다.유스케이스를 수직으로 분리할 때 이러한 문제와 마주칠 테고, 이들 유스케이를 통합하고 싶다는 유혹을 받게 될 것이다. 하지만 조심해야 한다. 중복이 진짜 중복인지 확인해야 한다.결합 분리 모드(다시)다시 결합 분리 모드로 돌아간다. 계층과 유스케이스의 결합을 분리하는 방법은 다양하다.소스 수준 분리 모드소스 코드 모듈 사이의 의존성을 제어할 수 있다. 이를 통해 하나의 모듈이 변하더라도 다른 모듈을 변경하거나 재컴파일하지 않도록 만들 수 있다(예, 루비 Gem).이 모드에서는 모든 컴포넌트가 같은 주소 공간에서 실행되고 서로 통신할 때는 간단한 함수 호출을 사용한다.이러한 구조를 모노리틱 구조라고 부른다.배포 수준 분리 모드jar 파일, DLL, 공유 라이브러리와 같은 배포 가능한 단위들 사이의 의존성을 제어할 수 있다. 이를 통해 한 모듈의 소스 코드가 변하더라도 다른 모듈을 재빌드하거나 재배포하지 않도록 만들 수 있다.이 모드의 중요한 특징은 결합이 분리된 컴포넌트가 jar 파일, Gem 파일, DLL과 같이 독립적으로 배포할 수 있는 단위로 분할되어 있다는 점이다.서비스 수준 분리 모드의존하는 수준을 데이터 구조 단위 까지 낮출 수 있고, 순전히 네트워크 패킷을 통해서만 통신하도록 만들 수 있다.이를 통해 모든 실행 가능한 단위는 소스와 바이너리 변경에 대해 서로 완전히 독립적이게 된다.시간이 흐르면 시스템에서 운영 요구사항은 감소할 수 있다. 한때는 결합을 서비스 수준까지 분리해야 했던 것들이 이제 배포 수준, 심지어 소스 수준의 결합 분리만으로 충분할 수도 있다.좋은 아키텍처는 시스템이 모노리틱 구조로 태어나서 단일 파일로 배포되더라도, 이후에는 독립적으로 배포 가능한 단위들의 집합으로 성정하고, 또 독립적인 서비스나 마이크로서비스 수준까지 성정할 수 있도록 만들어져야한다.또한 좋은 아키텍처라면 나중에 상황이 바뀌었을 때 이 진행 방향을 거꾸로 돌려 원래 형태인 모노리틱 구조로 되돌리 수도 있어야 한다.좋은 아키텍처는 이러한 변경으로부터 소스 코드 대부분을 보호한다. 좋은 아키텍처는 결합 분리 모드를 선택사항으로 남겨두어서 배포 규모에 따라 가장 적합한 모드를 선택해 사용할 수 있게 만들어 준다.결론물론 이렇게 하기느 ㄴ까다롭다. 그리고 결합 분리 모드를 변경하기가 설정 값하나 바꾸듯 쉬워야 한다는 뜻이 아니다.시스템의 결합 분리 모드는 시간이 지나면서 바뀌기 쉬우며, 뛰어나 아키텍트라면 이러한 변경을 예층하여 큰 무리 없이 반영할 수 있도록 만들어야 한다는 점이다." }, { "title": "15장. 아키텍처란?", "url": "/posts/PPPCleanArchitecture_ch15/", "categories": "DDD, 클린 아키텍처 소프트웨어 구조와 설계의 원칙, 5부 아키텍처", "tags": "DDD, CleanArchitecture", "date": "2022-05-08 18:00:00 +0900", "snippet": "소개클린아키텍처: 소프트웨어 구조와 설계의 원칙 책을 읽고 정리하며 소감을 적는 포스트입니다.아키텍처란?아키텍처(architecture)라는 단어는 권력과 신비로움을 연상케 한다. 소프트웨어아키텍처는 기술적 성취의 정점에 서 있다. 소프트웨어 아키텍트를 생각할 때면, 권한을 가지며 존경심을 불러일으키는 사람을 떠올린다.그러면 소프트웨어 아키텍처란 무엇인가? 소프트웨어 아키텍트는 무슨 일을 하며, 언제 그 일을 하는가?무엇보다도 소프트웨어 아키텍트는 프로그래머이며, 앞으로도 계속 프로그래머로 남는다. 소프트웨어 아키텍트라면 코드에서 탈피하고 고수준의 문제에 집중해야 한다는 거짓말에 절대로 속아서는 안된다.소프트웨어 아키텍트는 최고의 프로그래머이며, 앞으로도 계속 프로그래밍 작업을 맡을 뿐만 아니라 동시에 나머지 팀원들이 생산성을 극대화할 수 있는 설계를 하도록 방향을 이끌어 준다.소프트웨어 시스템의 아키텍처란 시스템을 구축했던 사람들이 만들어낸 시스템의 형태이다. 그 모양은 시스템을 컴포넌트로 분할하는 방법, 분할된 컴포넌트를 배치하는 방법, 컴포넌트가 서로 의사소통하는 방식에 따라 정해진다.그리고 그 형태는 아키텍처 안에 담긴 소프트웨어 시스템이 쉽게 개발, 배포, 운영, 유지보수 되도록 만들어진다.이러한 일을 용이하게 만들기 위해서는 가능한 한 많은 선택지를, 가능한 한 오래 남겨두는 전략을 따라야 한다.아키텍처의 주된 목적은 시스템의 생명주기를 지원하는 것이다. 좋은 아키텍처는 시스템을 쉽게 이해하고, 쉽게 개발하며, 쉽게 유지보수하고, 또 쉽게 배포하게 해준다.아키텍처의 궁극적인 목표는 시스템의 수명과 관련된 비용은 최소화하고, 프로그래머의 생산성은 최대화하는 데 있다.개발개발하기 힘든 시스템이라면 수명이 길지도 않고 건강하지도 않을 것이다.시스템 아키텍처는 개발팀(들)이 시스템을 쉽게 개발할 수 있도록 뒷바침해야한다.팀 구조가 다르다면 아키텍처 관련 결정에도 차이가 난다. 개발자가 다섯명이라면 서로 효율적으로 협력하며 모노리틱(monilithic)시스템을 개발 할 수 있다.다른 한편으로 일곱 명씩 구성된 총 다섯팀이 시스템을 개발하고 있다면 시스템을 신뢰할 수 있고 안정된 인터페이스를 갖춘, 잘 설계된 컴포넌트 단위로 분리하지 않으면 개발이 진척되지 않는다. 다른 요소를 고려하지 않는다면 이 시스템의 아키텍처는 다섯 개의 컴포넌트로(즉, 각 팀마다 하나씩) 발전될 가능성이 높다.이러한 팀별 단일 컴포넌트 아키텍처가 시스템을 배포, 운영, 유지보수 하는데 최적일 가능성은 거의 없다. 그럼에도 여러 팀이 순전히 일정에만 쫒겨서 일한다면, 결국 이 아키텍처로 귀착될 것이다.배포배포 비용이 높을 수록 시스템의 유용성은 떨어진다. 따라서 소프트웨어 아키텍처는 시스템을 단 한 번에 쉽게 배포할 수 있도록 만드는 데 그 목표를 두어야 한다.안타깝지만 초기 개발 단계에서는 배포 전략을 거의 고려하지 않는다.예를 들어 개발 초기에 마이크로서비스 아키텍처를 사용하자고 결정한다면 컴포넌트 경계가 뚜렿해지고 인터페이스가 대체로 안정화되므로 시스템을 매우 쉽게 개발 할 수 있다고 판단했을지도 모른다.하지만 배포할 시기가 되면 위협적일 만큼 늘어난 수많은 마이크로서비스를 발견하게 될지도 모른다.만약 아키텍트가 배포 문제를 초기에 고려했다면 이와는 다른 결정을 내렸을 것이다.더 적은 서비스를 사용하고, 서비스 컴포넌트와 프로세스 수준의 컴포넌트를 하이브리드 형태로 융합하며, 좀 더 통합 된 도구를 사용하여 상호 연결을 관리했을 것이다.운영아키텍처가 시스템 운영에 미치는 영향은 개발, 배포, 유지보수에 미치는 영향보다는 덜 극적이다. 운영에서 겪는 대다수의 어려움은 소프트웨어 아키텍처에는 극적인 영향을 주지 않고도 단순히 하드웨어를 더 투입해서 해결할 수 있다.하드웨어는 값 싸고 인력은 비싸다는 말이 뜻하는 바는 운영을 방해하는 아키텍처가 개발, 배포, 유지보수를 방해하는 아키텍처보다는 비용이 덜 든다는 뜻이다.시스템을 쉽게 운영하게 해주는 아키텍처가 바람직하지 않다는 말이 아니다. 다만 비용 공식 관점에서 운영보다는 개발, 배포, 유지보수 쪽으로 더 기운다는 말이다.그렇다라도 시스템을 운영할 때 아키텍처가 맡은 또 다른 역할이 있다. 좋은 소프트웨어 아키텍처는 시스템을 운영하는 데 필요한 요구도 알려준다.아키텍처의 이 역할을 달리 표현하면, 시스템 아키텍처가 개발자에게 시스템의 운영 방식을 잘 드러내 준다고 할 수 있다.시스템 아키텍처는 유스케이스, 기능, 시스템의 필수 행위를 일급(first-class) 엔티티로 격상시키고, 이들 요소가 개발자에게 주요 목표로 인식되도록해야 한다.유지보수유지보수는 모든 측면에서 봤을 때 소프트웨어 시스템에서 비용이 가장 많이 든다.유지보수의 가장 큰 비용은 탐사(spelunking)와 이로 인한 위험부담에 있다.탐사란 기존 소프트웨어에 새로운 기능을 추가하거나 결함을 수정할 때, 소프트웨어를 파헤쳐서 어디를 고치는 게 최선인지, 그리고 어떤 전략을 쓰는게 최적일지 결정할 때 드는 비용이다.주의를 기울여 신중하게 아키텍처를 만들면 이 비용을 크게 줄일 수 있다. 시스템을 컴포넌트로 분리하고, 안정된 인터페이스를 두어 서로 격리한다.이를 통해 미래에 추가 될 기능에 대한 길을 밝혀 둘 수 있을 뿐만 아니라 의도치 않은 장애가 발생할 위험을 크게 줄일 수 있다.선택사항 열어두기소프트웨어는 두 종류의 가치, 즉 행위적 가치와 구조적 가치를 지닌다. 이 중에서 구조적 가치가 더 중요한데, 소프트웨어를 부드럽게(soft) 만들기 때문이다.소프트웨어를 부드럽게 유지하는 방법은 선택사항을 가능한 한 많이, 그리고 가능한 한 오랫동안 열어 두는 것이다. 그렇다면 열어둬야 할 선택사항은 무엇인가?? 바로 중요치 않은 세부사항(detail)이다.모든 소프트웨어 시스템은 주요한 두 가지 구성요소로 분해 할 수 있다.바로 정책(policy)과 세부사항이다. 정책 요소는 모든 업무 규칙과 업무 절차를 구체화 한다. 정책이란 시스템의 진정한 가치가 살아 있는 곳이다.세부사항은 사람, 외부 시스템, 프로그래머가 정책과 소통할 때 필요한 요소지만, 정책이 가진 행위에는 조금도 영향을 미치지 않는다.예를 들어 세부사항에는 입출력 장치, 데이터베이스, 웹 시스템, 서버, 프레임워크, 통신 프로토콜 등이 있다.아키텍트의 목표는 시스템에서 정책을 가장 핵심적인 요소로 식별하고, 동시에 세부사항은 정책에 무관하게 만들 수 있는 형태의 시스템을 구축하는데 있다. 이를 통해 세부사항을 결정하는 일을 미루거나 연기할 수 있게 된다.좋은 아키텍트는 결정되지 않은 사항의 수를 최대화 한다.장치 동립성이전 프로그래머의 대표적인 실수 중 하나는 코드를 입출력 장치와 직접 결합해버린 일이었다. 프린터로 인쇄할 일이 있다면, 해당 프린터를 제어하는 입출력 명령어를 직접 사용해서 코드로 작성했다. 이러한 코드는 장치 종속적(device dependent)이 었다.1960년 후반에 어르러서야 장치 독립성(device independence)를 생각해 냈다. 오늘날의 운영체제는 입출력 장치를 소프트웨어 함수로 추상화했고, 해당 함수는 천공카드와 같은 단위 레코드를 처리한다.동일한 프로그램을 아무런 변경 없이도 카드에서 읽고 쓰거나 테이브에서 읽고 쓸 수 있게 되었다.개발 폐쇄 원칙이 탄생한 순간이다.광고 우편1960년 대 후반에 나는 광고 우편을 인쇄하는 회사에서 일했다. 의뢰인은 고객의 이름과 주소가 포함한느 단위 레코드가 기록 된 자기 테이프를 우리에게 보내주고 우리는 개인화된 광고를 멋지게 프린트하는 프로그램을 작성하였다.그러나 안타깝게도 IBM 360과 라인 프린트 하나만 이용해서 인쇄했고 매우 느렸다. 그래서 우리는 자기 테이프를 사용하도록 운영체제에게 지시하여 IBM 360가 10여분 만에 자기 테이프를 가득 채워서 쏟아냈다. 우리는 그 것을 가지고 오프라인 프린트로 수십만 장의 광고 우편을 인쇄하였다.장치 동립성이 지닌 가치는 굉징했다. 어떤 장치를 사용할지 전혀 모른채, 그리고 고려하지 않고도 프로그램을 작성할 수 있었다.이 경우 정책은 이름과 주소 레코드에 대한 서식이었다. 세부사항은 장치였다. 우리는 어떤 장치를 사용할지에 대한 결정을 연기시켰다.물리적 주소할당1970년대 초에 나는 회계 시스템을 만들고 있었다. 25MB의 크기의 디스크 드라이브에 여러 Agent, Employer, Member의 레코드를 저장했다.그렇게 우리는 소프트웨어가 디스크의 상세 구조를 알도록 만들 었다. 즉 소프트웨어는 디스크가 200개의 실린더와 10개의 헤드로 구성되며, 각 실린더는 헤드별 수십 개의 섹터로 구성된다는 사실을 알게 되었다. 이러한 정보가 모드 하드 코딩이었다.그런데 만약 헤더가 더 많거나 실린더가 더 많은, 또는 실린더당 섹터가 더 많은 새로운 디스크 드라이브로 업그레이드해야 한다면 무슨 일이 벌어질까? 하드 코딩된 코드를 전부 수정해야 한다.어느날 노련한 프로그래머가 우리 조직에 합류하였고 그는 친절하게 주소 할당 체계를 변경하여 상대 주소를 사용하라고 충고해 주었다.다행이도 우리는 그의 조언을 받아들여, 시스템에서 고수준의 정책이 디스크의 물리적 구조로부터 독립되도록 수정했다. 그 덕분에 우리는 디스크 드라이브 구조에 대한 결정사항을 애플리케이션으로부터 분리할 수 있게 되었다.결론좋은 아키텍트는 세부사항을 정책으로 부터 신중하게 가려내고, 정책이 세부사항과 결합되지 않도록 엄격하게 분리한다.이를 통해 정책은 세부사항에 관한 어떤 지식도 갖지 못하게 되며, 어떤 경우에도 세부사항에 의존하지 않게 된다.좋은 아키텍트는 세부사항에 대한 결정을 가능한 한 오랫동안 미룰 수 있는 방향으로 정책을 설계한다." }, { "title": "14장. 컴포넌트 결합", "url": "/posts/PPPCleanArchitecture_ch14/", "categories": "DDD, 클린 아키텍처 소프트웨어 구조와 설계의 원칙, 4부 컴포넌트 원칙", "tags": "DDD, CleanArchitecture", "date": "2022-05-08 16:00:00 +0900", "snippet": "소개클린아키텍처: 소프트웨어 구조와 설계의 원칙 책을 읽고 정리하며 소감을 적는 포스트입니다.컴포넌트 결합지금 부터 다룰 세 가지 원칙은 컴포넌트 사이의 관계를 설명한다. 개발 가능성과 논리적 설계 사이의 균형을 다룬다.컴포넌트 구조와 관련된 아키텍처를 침번하는 힘은 기술적이며, 정치적이고, 가변적이다.ADP: 의존성 비순환 원칙컴포넌트 의존성 그래프에 순환(cycle)이 있어서는 안 된다.하루 종일 일해서 무언가를 작동하게 만들고 퇴근 했는데, 이튿날 전혀 돌아가지 않는 경험을 해본적 있는가? 누군가 당신보다 더 늦게까지 일하며 의존하고 있던 무언가를 수정했기 때문이다.나는 이러한 현상을 숙취 증후군(the morning after syndrome)이라고 부른다.프로젝트의 규모가 커지면 커질 수록 이러한 숙취는 지독한 악몽이 될 수 있다. 누군가가 마지막에 수정한 코드 때문에 망가진 부분이 동작하도록 만들기 위해 코드를 수정하고 또 수정하는 작업만이 계속 된다.해결책으로는 첫 번째 주 단위 빌드(weekly build)이며 두 번째는 의존성 비순황 원칙(Acyclic Dependencies Principle, ADP)이다.주 단위 빌드(Weekly Build)주 단위 빌드는 중간 규모의 프로젝트에서는 흔하게 사용된다. 모든 개발자가 일주일의 첫 4일 동안은 서로를 신경쓰지 않고 개발하며 금요일이 되면 변경된 코드를 모두 통합하여 시스템을 빌드한다.이 접근법은 5일 중 4일 동안 개발자를 고립된 세계에서 살 수 있게 해주지만 금요일에 통합과 관련된 막대한 업보를 치러야 한다.하지만 안타깝게도 프로젝트가 커지면 통합이 금요일 하루 만에 끝나지 않는다.개발보다 통합에 드는 시간이 늘어나면서 팀의 효율서도 서서히 나빠진다.순환 의존성 제거하기이 해결책은 개발 환경을 릴리스 가능한 컴포넌트 단위로 분리하는 것이다. 이를 통해 컴포넌트는 개별 개발자 또는 단일 개발팀이 책임질 수 있는 작업 단위가 된다.개발자가 해당 컴포넌트를 동작하도록 만든 후, 해당 컴포넌트를 릴리스하여 다른 개발자가 사용할 수 있도록 만든다.컴포넌트가 새로 릴리스되어 사용할 수 있게 되면, 다른 팀에서는 새 릴리스를 당장 적용할지를 결졍해야 한다. 새 릴리스를 적용할 준비가 되었다는 판단이 들면 새 릴리스를 사용하기 시작하면 된다.이 같은 작업 절차는 단순하며 합리적이지만 이 절차가 성공적으로 동작하려면 컴포넌트 사잉의 의존성 구조를 반드시 관리해야 한다. 의존성 구조에 순화이 있어서는 안된다. 전형적인 컴포넌트 다이어그램위 그림의 중요한 점은 컴포넌트 간의 의존성 구조다. 이 구조가 방향 그래프(directed graph)엠에 주의하자. 컴포넌트는 정점(vertex)에 해당하고, 의존성 관계는 방향이 있는 간선(directed edge)에 해당한다.또한 위 그림의 의존성 구조는 비순환 방향 그래프(Directed Acyclic Graph, DAG)이다.Presenters 컴포넌트를 만드는 개바랒가 이 컴포넌트를 테스트하고자 한다면, 단순히 현재 사용 중인 버전의 Interactors와 Entities를 이용해서 Presenters 자체 버전을 빌드하면 그만이다. 이 빌드 과정에서 시스템의 나머지 컴포넌트는 전혀 관련이 없다.시스템 전체를 릴리스 해야 할때가 온다면 릴릴스 절차는 상향식으로 진행하면 된다. Entities 컴포넌트를 컴파일하고, 테스트하고, 리리리스 한다. 그러고 나서 database와 Interactors에 대해서도 동일한 과정을 거친다.이 처럼 구성요소 간 의존성을 파일하고 있으면 시스템을 빌드하는 방법을 알 수 있다.순환이 컴포넌트 의존성 그래프에 미치는 영향새로운 요구사항이 발생해서 Entities에 포함된 클래스 하나가 Authorizer에 포함된 클래스 하나를 사용하도록 변경할 수밖에 없다고 가정해 보다. 순환 의존성위와 같이 순환 의존성(dependency cycle)이 발생하며 이 순환은 즉각적인 문제를 일으킨다.예를 들어 Database 컴포넌트를 만드는 개발자가 릴리스하려면 Entities 컴포넌트와 반드시 호환되너야 한다느 사실을 알고 있다. 하지만 Entitites 컴포넌트에는 순환이 있으므로, Database 컴포넌트는 또한 Authorizer와도 호환되어야 한다.이 말은 결국 개발자들은 모두, 이들 컴포넌트 중 어느 것을 개발하더라도 숙취 증후군에 떠는 경험을 하게 될 것이다.의존성 그래프에 순환이 생기면 컴포넌트를 어떤 순서로 빌드해야하 하는지 파악하기 힘들어진다.순환 끊기컴포넌트 사이의 순환을 끊고 의존성을 다시 DAG로 원상복구 하는 일은 언제라도 가능하다. 아래의 두 가지 메커니즘을 살펴 보자. 의존성 역전 원칙(DIP)를 적용한다. User가 필요한 메서드를 제공하는 인터페이스를 생성한다. 그리고 이 인터페이스는 Entities에 위치시키고, Authorizer에서는 이 인터페이스를 상속받는다. 이렇게 하면 Entities와 Authorizer 사이의 의존성을 역전시킬 수 있고, 이를 통해 순환을 끊을 수 있다. Entities와 Authorizer 사이의 의존성을 역전 시킨다. Entities와 Authorizer가 모두 의존하는 새로운 컴포넌트를 만든다. 그리고 두 컴포넌트가 모두 의존하는 클래스드릉르 새로운 컴포넌트로 이동 시킨다. Entities와 Authorizer 모두가 의존하는 새로운 컴포넌트흐트러짐(Jitters)두 번째 해결책에서 시사하는 바는 요구사항이 변경되면 컴포넌트 구조도 변경 될 수 있다는 사실이다. 실제로 애플리케이션이 성장함에 따라 컴포넌트 의존성 구조는 서서히 흐트러지며 또 성장한다.따라서 의존성 구조에 순환이 발생하는지를 항상 관찰해야 한다. 순환이 발생하면 어떤 식으로든 끊어야 한다.이 말은 때로 새로운 컴포넌트를 생성하거나 의존성 구조가 더 커질 수 있음을 의미한다.하향식(top-down) 설계지금까지 논의로 우리는 피할 수 없는 결론에 다다른다. 즉, 컴포넌트 구조는 하향식으로 설계 될 수 없다. 컴포넌트는 시스템에서 가장 먼저 설계할 수 있는 대상이 아니며, 오히려 시스템이 성장하고 변경 될 때 까지 함께 진화한다.사실 컴포넌트 의존성 다이어그램은 애플리케이션의 기능을 기술하는 일과는 거의 관련이 없다. 그렇게 때문에 컴포넌트 구조는 프로젝트 초기에 설계할 수 없다. 빌드하거나 유지보수할 소프트웨어가 없다면 빌드와 유지보수에 관한 지도 또한 필요없기 때문이다.하지만 프로젝트를 개발하기 위해서 의존성 관리에 대한 요구가 점처 늘어나게 되며 변경되는 범위가 시스템의 가능한 한 작은 일부로 한정되기를 원한다.결국 단일 책임 원칙(SRP)과 공통 폐쇄 원칙(CCP)에 관심을 갖기 시작하고, 이를 적용해 함께 변경되는 클래스는 같은 위치에 배치되도록 만든다.의존성 구조와 관련된 최우선 관심사는 변동성을 격리하는 일이다. 컴포넌트 의존성 그래프는 자주 변겨오디는 컴포넌트로부터 안정적으며 가치가 높은 컴포넌트를 보호하려는 아키텍트가 만들고 가다듬게 된다.아직 아무런 클래스도 설계하지 않은 상태에서 컴포넌트 의존성 구조를 설계하려고 시도한다면 상단히 큰 실패를 맛볼 수 있다.SDP : 안정된 의존성 원칙안정성의 방향으로 (더 안정된 쪽에) 의존하라설계는 결코 정적일 수 없다. 설계를 유지하다 보면 변경이 불가피하다. 공통 폐쇄 원칙을 준수함으로써, 컴포넌트가 다른 유형의 변경에는 영향을 받지 않으면서도 특정 유형의 변경에만 민감하게 만들 수 있다.우리는 변동성을 지니도록 설계한 컴포넌트는 언젠가 변경되리라고 예상한다.즉, 당신이 모듈을 만들때는 변경하기 쉽도록 설계했지만, 이 모듈에 누군가가 의존성을 매달아 버리면 당신의 모듈도 변경하기 어려워진다.안정된 의존성 원칙(Stable Dependencies Principle, SDP)을 준수하면 변경하기 어려운 모듈이 변경하기 쉽게 만들어진 모듈에 의존하지 않도록 만들 수 있다.안정성안정성(stability)는 무슨 뜻인가? 안정성은 변화가 발생하는 빈도와는 직접적인 관련이 없다.소프트웨어 컴포넌트를 변경하기 어렵게 만드는 데는 많은 요인이 존재하며, 그 예로는 컴포넌트의 크기, 복잡도, 간결함 등을 들 수 있다.소프트웨어 컴포넌트를 변경하기 어렵게 만드는 확실한 방법 하나는 수많은 다른 컴포넌트가 해당 컴포넌트에 의존하게 만드는 것이다.아래의 그램에서 X 컴포넌트는 안정된 컴포넌트다. 세 컴포넌트가 X에 의존하며, 따라서 X 컴포넌트는 변경하지 말아야 할 이유가 세 가지나 된다. X는 안정된 컴포넌트다.아래의 그림의 Y는 상당히 불안정한 컴포넌트다. 어떤 컴포넌트도 Y에 의존하지 않으므로 Y는 책임성이 없다고 말할 수 있다. 또한 Y는 세 개의 컴포넌트에 의존하므로 변경이 발생할 수 있는 외부 요인이 세 가지다 Y는 상당히 불안정한 컴포넌트다.안정성 지표컴포넌트의 안정성을 측정하는 방법은 의존성의 개수를 세어 보는 방법이 있다. 이 숫자를 통해 컴포넌트가 위치상(positional) 어느 정도의 안정성을 가지는지 계산할 수 있다. Fan-in : 안으로 들어오는 의존성 의존하는 외부 컴포넌트의 클래스 갯수 Fan-out : 바깥으로 나가는 의존성 외부 클래스에 의존하는 컴포넌틑 내부의 클래스 개수 I(불안정성) : I = Fan-out % (Fan-in + Fan-out). I = 0이면 최고로 안정된 컴포넌트 I = 1이면 최고로 불안정한 컴포넌트 SDP에서 컴포넌트의 I 지표는 그 컴포넌트가 의존하는 다른 컴포넌트들의 I보다 커야 한다고 말한다.즉, 의존성 방향이 갈수록 I 지표 값이 감소해야 한다.모든 컴포넌트가 안정적이여야 하는 것은 아니다.모든 컴포넌트가 최고로 안정적인 시스템은 변경이 불가능하다. 사실 우리가 컴포넌트 구조를 설계할 때 기대하는 것은 불안정한 컴포넌트도 있고 안정된 컴포넌트도 존재하는 상태다. 세 컴포넌트로 구성된 시스템이 이상적인 구조다이어그램에서 불안정한 컴포넌트를 관례적으로 위쪽에 두는데, 이 관례를 따르면 상당히 유용하다. 위로 향하는 화살표가 있으면 SDP를 위배하는 상태가 되기 때문이다. SDP 위배Flexible은 변경하기 쉽도록 설계한 컴포넌트다. 하지만 Stable 컴포넌트에서 작업하던 개발자가 Flexible에 의존성을 걸게 되면 이로 인해 SDP를 위배하는데, 결국 Flexible은 변경하기 어렵게 된다. 수정 된 그림위 그림과 같이 불안정한 컴포넌트를 위에 배치하면 한눈에 알아보기 쉽다.위와 같은 문제를 해결하려면 Stable의 Flexible에 대한 의존성은 어떤 식으로든 끊어야한다. 이 의존성은 무슨 이유로 존재하는가? Stable 내부의 클래스 U가 Flexible 내부의 클래스 C를 사용한다고 가정해보자. Stable 내부의 클래스 U가 Flexible 내부의 클래스 C를 사용한다.DIP를 도입하면 이 문제를 해결할 수 있다. C는 US 인터페이스를 구현한다.추상 컴포넌트오로지 인터페이스만을 포함하는 컴포넌트(위 예제의 UServer)를 생성하는 방식이 이상하게 보일 수도 있다.하지만 C#이나 Java 같은 정적 타입 언어를 사용할 때 이 방식은 상당히 흔할 뿐만 아니라, 꼭 필요한 전략이다.이러한 추상 컴포넌트는 상당히 안정적이며, 따라서 덜 안정적인 컴포넌트가 의존할 수 있는 이상적인 대상이다.SAP: 안정된 추상화 원칙컴포넌트는 안정된 정도만큼만 추상화되어야 한다.고수준 정책을 어디에 위치시켜야 하는가?시스템에서 자주 변경시켜서는 안되는 소프트웨어도 있다. 고수준 아키텍처나 정책결정과 관련된 소프트웨어가 그 예다.이처럼 업무 로직이나 아키텍처와 관련된 결정에는 변동성이 없기를 기대한다.하지만 고수준 정책을 안정된 컴포넌트에 위치시키면, 그 정책을 포함하는 소스 코드는 수정하기 어려워진다. 이로 인해 시스템 전체 아키텍처가 유연성을 잃는다.해답은 개방 폐쇄 원칙(OCP)에서 착을 수 있다. OCP는 클래스를 수정하지 않고도 확장이 충분히 가능할 정도로 클래스를 유연하게 만들 수 있다.어떤 클래스가 이 원칙을 준수하는가? 바로 추상(abstract) 클래스다.안정된 추상화 원칙안정된 추상화 원칙(Stable Abstractions Principle, SAP)는 안정성과 추상화 정도 사이의 관계를 정의한다.이 원칙은 한편으로는 안정된 컴포넌트는 추상 컴포넌트여야 하며, 이를 통해 안정성이 컴포넌트를 확장하는 일을 방해해서는 안 된다고 말한다. 다른 한편으로는 불안정한 컴포넌트는 반드시 구체 컴포넌트여야 한다고 말하는데, 컴포넌트가 불안정하므로 컴포넌트 내부의 구체적인 코드를 쉽게 변경할 수 있어야 하기 때문이다.따라서 안정적인 컴포넌트라면 반드시 인터페이스와 추상 클래스로 구성되어 쉽게 확장할 수 있어야 한다.SAP와 SDP를 결합하면 컴포넌트에 대한 DIP나 마찬가지가 된다. 실제로 SDP에서는 의존성이 반드시 안정성의 방향으로 향해야 한다고 말하며, SAP에서는 안정성이 결국 추상화를 의미한다고 말하기 때문이다. 따라서 의존성은 추상화의 방향으로 향하게 된다.하지만 DIP는 클래스에 대한 원칙이며, 클래스의 경우 중간은 존재하지 않는다.즉, 클래스는 추상적이거나 아니거나 둘 중 하나다. SDP와 SAP의 조합은 컴포넌트에 대한 원칙이며, 컴포넌트는 어떤 부분은 추상적이면서 다른 부분은 안정적일 수 있다.추상화 정도 측정하기A 지표는 컴포넌트의 추상화 정도를 측정한 값이다. 이 값은 컴포넌트의 클래스 총 수 대비 인터페이스와 추상 클래스의 개수를 단순히 계산한 값이다. Nc: 컴포넌트의 클래스 개수 Na: 컴포넌트의 추상 클래스와 인터페이스의 개수 A: 추상화 정도. A = Na % NcA 지표는 0과 1 사이의 값을 갖는다. A가 0이면 컴포넌트에는 추상 클래스가 하나도 없다는 뜻이다. A가 1이면 컴포넌트는 오로지 추상 클래스만을 포함한다는 뜻이다.주계열아래의 그래프는 안정성(I)과 추상화 정도(A)사이의 관계를 정의한다. A/I 그래프최고로 안정적이며 추상화된 컴포넌트는 좌측 상단이 (0,1)에 위치하고 최고로 불안정하고 구체화된 컴포넌트는 우측하단(1,0)에 위치한다.모든 컴포넌트가 좌측 상단, 우측 하단에 위치 할 수 없음으로 합리적인 지점을 정의하는 점의 궤적이 있으리라고 가정해 볼 수 있다.이 궤적은 컴포넌트가 절대로 위치해서는 안 되는 영역, 다시 말해 배제할 구역(Zone of Exclusion)을 찾는 방식으로 추론할 수 있다. 배제 구역(Zone of Exclusion)고통의 구역(0,0) 주변의 컴포넌트는 매우 안정적이며 구체적이다. 이는 바람직한 상태가 아닌데, 뻣뻣한 상태이기 때문이다.추상적이지 않아 확장할 수 없고, 안정적이므로 변경하기 상당히 어렵다.사실 일부 소프트웨어 엔티티는 고통의 구역에 위치하곤 한다. 데이터베이스 스키마가 한 예이다. 스키마는 변동성이 높기로 악명이 높다.또 다른 예는 구체적인 유틸리티 라이브러리를 들 수 있다. 하지만 이러한 라이브러리는 I 지표가 1일지라도, 실제로 변동성이 거의 없다. 예를 들어 String 컴포넌트이다.변동성이 거의 없는 컴포넌트는 (0,0) 구역에 위치했더라도 해롭지 않다. 변동 될 가능성이 거의 없기 때문이다.쓸모없는 구역(1,1) 주변의 컴포넌트는 추상적이지만, 누구도 그 컴포넌트에 의존하지 않는다. 이는 쓸모가 없는 컴포넌트다.이 영역에 존재하는 엔티티는 폐기물과도 같다. 엔티티는 누구도 구현하지 않은 채 남겨친 추상 클래스인 경우가 많다.배제 구역 벗어나기변동성이 큰 컴포넌트 대부분은 두 배제 구역으로부터 가능한 한 멀리 떨어뜨려야 한다.이 선분이 주계열(Main Sequence)라고 부르며, 주계열에 위치한 컴포넌트는 자신의 안정성에 비해 너무 추상적이지도 않고, 추상화 정도에 비해 너무 불안정하지도 않다.컴포넌트가 위칳라 수 있는 가장 바람직한 지점은 주계열의 두 종점이다.주계열과의 거리컴포넌트가 주계열 바로 위에, 또는 가까이 있는 것이 바람직하다면, 이 같은 이상적인 상태로부터 컴포넌트가 얼마나 멀리 떨어져 있는지 측정하는 지표를 말들어 볼 수 있다. D: 거리. D = A + I - 1 유효범위는 [0,1] D가 0이면 컴포넌트가 주계열 바로 위에 위치하고, 1이면 주계열로부터 가장 멀리 위치한다.지표를 사용하면 컴포넌트를 재검토 후 재구성 할 수 있고 통계적으로 분석하는 일 또한 가능해진다.모든 컴포넌트에 대해 D 지표의 평균과 분산을 구한다. 분산은 관리 한계(Control limit)를 결정하기 위한 목적으로 사용할 수 있고, 분산을 통해 다른 컴포넌트에 비해 극히 예외적인 컴포넌트를 식별 할 수 있다.아래의 그림에서 보듯이 일부 컴포넌트의 표준편차가 1(Z=1)인 영역을 벗어나 있다.이처럼 이상한 컴포넌트는 좀 더 면밀히 검토해 볼 가치가 있다. 이들 컴포넌트는 자신에게 의존하는 컴포넌트가 거의 없는데도 너무 추상적이거나, 자신에게 의존하는 컴포넌트가 많은데도 너무 구체적일 것이다. 컴포넌트 산점도결론의존성 관리 지표는 설계의 의존성과 추상화 정도가 내가 훌륭한 패턴이라고 생각하는 수준에 얼마나 잘 부합하는지를 측정한다.하지만 지표는 그저 임의로 결정된 표준을 기초로 한 측정값에 지나지 않는다. 이러한 지표는 아무리 해도 불완전하다. 하지만 이들 지표로부터 무언가 유용한 것을 찾을 수 있기를 바란다." }, { "title": "13장. 컴포넌트 응집도", "url": "/posts/PPPCleanArchitecture_ch13/", "categories": "DDD, 클린 아키텍처 소프트웨어 구조와 설계의 원칙, 4부 컴포넌트 원칙", "tags": "DDD, CleanArchitecture", "date": "2022-05-08 14:10:00 +0900", "snippet": "소개클린아키텍처: 소프트웨어 구조와 설계의 원칙 책을 읽고 정리하며 소감을 적는 포스트입니다.컴포넌트 응집도어떤 클래스를 어느 컴포넌트에 포함시켜야 할까? 이 장에서는 컴포넌트 응집도와 관련된 세 가지 원칙을 논의한다. REF : 재사용/릴리스 등가원칙(Reuse/Release Equivalence Principle) CCP : 공통 폐쇄 원칙(Commom Closure Principle) CRP : 공통 재사용 원칙(Common Reuse Principle)REP: 재사용/릴리스 등가 원칙재사용 단위는 릴리스 단위와 같다.우리는 이제 소프트웨어 재사용의 시대에 살고 있다. 객체 지향 모델의 오랜 약속 중 하나가 실현되었다.돌이켜 보면 재사용/릴리스 등가 원칙(REP)는 너무 당연하다. 릴리스 번호가 없다면 재사용 컴포넌트들이 서로 호환되는지 보증할 방법이 전혀 없다.이 원칙을 소프트웨어 설계와 아키텍처 관점에서 보면 단일 컴포넌트는 응집성 높은 클래스와 모듈들로 구성되어야 함을 뜻한다. 컴포넌트를 구성하는 모든 모듈은 서로 공유하는 중요한 테마나 목적이 있어야 한다.하나의 컴포넌트로 묶인 클래스와 모듈은 반드시 함께 릴리스 할 수 있어야 하며 버전 번호가 같아야 하며, 동일한 릴리스로 추적 관리되고, 동일한 릴리스 문서에 포함되어 한다.하지만 이것으로 클래스와 모듈을 단일 컴포넌트로 묶는 방법을 제대로 설명 할 수 없다.이 원칙의 약점은 다음에 다룰 두 원칙이 지닌 강점을 통해 충분히 보완할 수 있다.실제로 CCP와 CRP는 REP를 엄격하게, 하지만 제약을 가하는 측면에서 정의한다.CPP : 공통 폐쇄 원칙동일한 이유로 동일한 시점에 변경되는 클래스를 같은 컴포넌트로 묶어라서로 다른 시점에 다른 이유로 변경되는 클래스는 다른 컴포넌트로 분리하라 이 원칙은 단일 책임 원칙(SRP)을 컴포넌트 관점에서 다시 쓴 것이다.대다수의 애플리케이션에서 유지보수성(maintainability)은 재사용성보다 훨씬 중요하다. 애플리케이션에서 코드가 반드시 변겨오디어야 한다면, 이러한 변경이 여러 컴포넌트 도처에 분산되어 발생하기보다는, 차라리 변경 모두가 단일 컴포넌트에서 발생하는 편이 낫다.CCP는 같은 이유로 변경될 가능성이 있는 클래스는 모두 한곳으로 묶을 것을 권한다. 이를 통해 소프트웨어를 릴리스, 재검증, 배포하는 일과 관련된 작업량을 최소화 할 수 있다.이 원칙은 개발 폐쇄 원칙(OCP)와 밀접하게 관련되어 있는데, CCP에서 말하는 폐쇄(closure)는 OCP에서 말하는 폐쇄(closure)와 그 뜻이 같다.100% 폐쇄란 불가능하므로 전략적으로 폐쇄해야 한다. 우리는 발생할 가능성이 있거나 과거에 발생했던 대대수의 공통적인 변경에 대해서 클래스가 닫혀 있도록 설계한다.CCP는 동일한 유형의 변경에 대해 닫혀 있는 클래스들을 하나의 컴포넌트로 묶음으로써 OCP에서 얻은 교훈을 확대 적용 한다.SRP와의 유사성CCP는 컴포넌트 수준의 SRP다. SRP에서는 서로 다른 이유로 변경되는 메서드를 서로 다른 클래스로 분리하라고 말한다.동일한 시점에 동일한 이유로 변경되는 것을들 한데 묶어라. 서로 다른 시점에 다른 이유로 변경되는 것들은 서로 분리하라.CRP: 공통 재사용 원칙컴포넌트 사용자들을 필요하지 않은 것에 의존하게 강요하지 말라.공통 재사용 원칙(CRP)도 클래스와 모듈을 어느 컴포넌트에 위치시킬지 결정할 때 도움되는 원칙이다. CRP에서는 같은 재사용되는 경향이 있는 클래스와 모듈들은 같은 컴포넌트에 포함해야 한다고 말한다.예를 들어 컨테이너(container) 클래스와 해당 클래스의 이터레이터(iterator) 클래스를 들 수 있다. 이들 클래스는 서로 강하게 결합되어 있기 때문에 함께 재사용된다. 따라서 이들 클래스는 반드시 동일한 컴포넌트에 위치해야 한다.컴포넌트가 다른 컴포넌트를 사용하면 의존성이 생긴다. 사용되는 컴포넌트가 변경되면 사용하는 컴포넌트 또한 변경 될 가능성이 높다.따라서 의존하는 컴포넌트가 있다면 해당 컴포넌트의 모든 클래스에 대해 의존함을 확실히 인지해야 한다. 바꿔 말하면, 한 컴포넌트에 속한 클래스들은 더 작게 그룹지을 수 없다. 즉, 일부 클래스에만 의존하고 다른 클래스와는 독립적일 수 없음을 확실히 인지해야 한다.ISP와의 관계CRP는 인터페이스 분리 원칙(ISP)의 포괄적인 버전이다.필요하지 않은 것에 의존하지 말라컴포넌트 응집도에 대한 균형 다이어그램아마도 응집도에 관한 세 원칙이 서로 상충된다는 사실을 눈치챘을 거라고 본다.REP와 CCP는 포함(include)원칙이다. 즉, 두 원칙은 컴포넌트를 더욱 크게 만든다.CRP는 배제(exclusive)원칙이며, 컴포넌트를 더욱 작게 만든다.아래의 그림은 균형(tension) 다이어그램으로, 응집도에 관한 세 원칙이 서로 어떻게 상호작용하는지 보여준다. REP와 CRP에만 중점을 두면, 사소한 변경에 너무 많은 컴포넌트에 영향을 미친다. CCP와 REP에만 과도하게 집중하면 불필요한 릴리스가 너무 빈번해진다. CRP와 CCP에만 집중하게 되면 재사용성이 떨어지게 된다.일반적으로 프로젝트는 삼각형의 오른쪽에서 시작하는 편이며, 이때는 오직 재사용성만 희생하면 된다.프로젝트가 성숙하고, 그 프로젝트로부터 파생된 또 다른 프로젝트가 시작되면, 프로젝트는 삼각형에서 점차 왼쪽으로 이동해 간다.결론과거의 결합도에 대한 우리의 인식 수준이 REP, CCP, CRP가 의미하는 것보다는 훨씬 단순했다.응집도를 모듈은 단 하나의 기능만 수행해야 한다는 속성 정도로 단순하게 이해한적도 있다.어느 클래스들을 묶어서 컴포넌트로 만들지를 결정할 때, 재사용성과 개발 가능성이라는 상충하는 힘을 반드시 고려해야 한다. 심지어 이 균형점은 거의 항상 유동적이다." }, { "title": "12장. 컴포넌트 원칙", "url": "/posts/PPPCleanArchitecture_ch12/", "categories": "DDD, 클린 아키텍처 소프트웨어 구조와 설계의 원칙, 4부 컴포넌트 원칙", "tags": "DDD, CleanArchitecture", "date": "2022-05-08 14:00:00 +0900", "snippet": "소개클린아키텍처: 소프트웨어 구조와 설계의 원칙 책을 읽고 정리하며 소감을 적는 포스트입니다.컴포넌트 원칙컴포넌트는 배포 단위다. 컴포넌트는 시스템의 구성 요소로 배포할 수 있는 가장 작은 단위다.자바에서는 jar 파일이 컴포넌트이고, 닷넷에서는 DLL이다.컴포넌트가 가장 마지막에 어떤 형태로 배포되든, 잘 설계된 컴포넌트라면 반드시 독립적으로 배포 가능한, 따라서 독립적으로 개발 가능한 능력을 갖춰야 한다.컴포넌트의 간략한 역사소프트웨어 개발 초창기에는 메모리에서의 프로그램 위치와 레이아웃을 프로그래머가 직접 제어했다. 프로그램의 시작부에는 프로그램이 로드 될 주소를 선언하는 오리진(origin) 구문이 나와야 했다. *200 TLSSTART, CLA TAD BUFR JMS GETSTR CLA TAD BUFR JMS PUTSTR JMP START프로그램 시작부에 있는 *200은 메모리 주소 2008에 로드할 코드를 생성하라고 컴파일러에 알려준다.이 시대에는 장치는 느리고 메모리는 너무 비싸 메모리가 소스 코드 전체를 메모리에 상주시킬 수가 없었다.결국 컴파일러는 느린 장치를 이용해서 소스 코드를 여러차례 읽어야만 했다.컴파일 시간을 단축시키기 위해 프로그래머는 함수 라이브러리와 소스 코드를 애플리케이션 코드로부터 분리했다.하지만 애플리케이션 마져 점점 커져서 두 개의 주소 세그먼트로 분리하여 함수 라이브러리 공간을 사이에 두고 오가며 동작하게 배치해야 했다. 애플리케이션을 두 개의 주소 세그먼트로 분리그러나 이러한 배치에서 함수 라이브러리 마저 커지게 된다면 할당된 메모리 주소를 넘어서게 되고 결국 추가 공간을 할당해야 한다.재배치성위의 문제를 해결하기 위해서는 재배치가 가능한 바이너리(relocatable binary)였다.재배치 로더가 여러 개의 바이너리의 위치 정보를 전달받아 새롭게 재배치 하였다. 이를 통해 프로그래머는 피룡한 함수만 로드 할 수 있게 되었다.또한 컴파일러는 재배치 가능한 바이너리 안의 함수 이름을 메타데이터 형태로 생성하도록 수정하였다. 만약 프로그램이 라이브러리 함수를 호출한다면 컴파일러는 라이브러리 함수 이름을 외부 참조(external reference)로 생성했다. 반면 라이브러리 함수를 정의하는 프로그램이라면 외부 정의(external definition)을 생성했다.이렇게 링킹 로더(linking loader)가 탄생했다.링커링킹 로더의 등장으로 프로그래머는 프로그램을 개별적으로 컴파일하고 로드할 수 있는 단위로 분할 할 수 있게 되었다.하지만 링킹 로더는 너무 느려서 로드와 링크가 두 단계로 분리 되었다.프로그래머가 느린 부분, 링크 과정을 맡았는데, 링커(linker)라는 벼롣의 애플리케이션으로 이 작업을 처리하도록 만들었다.하지만 1980년대가 되어 C나, 다른 고수준 언어를 사용하게 되며 또 다시 전체 모듈을 컴파일 하는 시간이 오래 걸리게 되었고 링커에서는 더 많은 시간이 소요 되었다.로드 시간은 여진히 빨랐지만 컴파일-링크 시간이 병목 구간이었다.컴파일하고 링크하는 데 사용 가능한 시간을 모두 소모할 때까지 프로그램은 커진다.하지만 무어의 법칙이 생겨나면서 메모리는 저렴해지고 RAM에 모두 캐싱 할 수 있을 정도로 커졌다.이렇게 액티브 X와 공유 라이버러리 시대가 열렸고, .jar 파일도 등장하기 시작했다. 컴퓨터와 장치가 빨라져서 또다시 로드와 링크를 동시에 할 수 있게 되었다. 다수의 .jar 파일 또는 다수의 공유라이브러리를 순식간에 서로 링크한 후, 링크가 끝난 프로그램을 실행할 수 있게 되었다.이렇게 컴포넌트 플러그인 아키텍처(component plugin architecture)가 탄생했다.결론런타임에 플러그인 형태로 결합할 수 있는 동적 링크 파일이 이 책에서 말하는 소프트웨어 컴포넌트에 해당한다." }, { "title": "11장. DIP, 의존성 역전 원칙", "url": "/posts/PPPCleanArchitecture_ch11/", "categories": "DDD, 클린 아키텍처 소프트웨어 구조와 설계의 원칙, 3부 설계 원칙", "tags": "DDD, CleanArchitecture", "date": "2022-05-08 13:30:00 +0900", "snippet": "소개클린아키텍처: 소프트웨어 구조와 설계의 원칙 책을 읽고 정리하며 소감을 적는 포스트입니다.DIP: 의존성 역전 원칙의존성 역전 원칙에서 말하는 '유연성이 극대화된 시스템'이란 소스 코드 의존성이 추상(abstraction)에 의존하며 구체(concretion)에는 의존하지 않는 시스템이다.자바 같은 정적 타입 언어에서는 이 말은 use, import, include 구분이 오직 인터페이스나 추상 클래스 같은 추상적인 선언만을 참조해야 한다는 뜻이다. 구체적인 대상에는 절대로 의존해서는 안된다.루비나 파이썬 같은 동적 타입에도 소스 코드 의존 관계에서 구체 모듈은 참조해서는 안된다.하지만 String 같은 클래스는 구체 클래스이며, 이를 의존하지 않기는 어렵다.반면 String 클래스는 변경되는 일은 거의 없으며, 있어도 엄격하게 통제된다.이러한 이유로 DIP를 논할 때 운영체제나 플랫폼 같이 안정성이 보장된 환경에 대해서는 무시하는 편이다.우리가 의존하지 않도록 피하고자 하는 것은 바로 변동성이 큰(volatile) 구체적인 요소이다.안정된 추상화추상 인터페이스에 변경이 생기면 이를 구체화환 구현체들도 따라서 수정해야 한다. 반대로 구체적인 구현체에 변경이 생기더라도 그 구현체가 구현하는 인터페이스는 대다수의 경우 변경될 필요가 없다. 따라서 인터페이스는 구현체보다 변동성이 낮다.즉, 안정된 소프트웨어 아키텍처란 변동성이 큰 구현체에 의존하는 일은 지양하고, 안정된 추상 인터페이스를 선호하는 안키텍처라는 뜻이다.변동성이 큰 구체 클래스를 참조하지 말라.대신 추상 인터페이스를 참조하라. 이 규칙은 객체 생성 방식을 강하게 제약하며, 일반적으로 추상 팩토리(Abstract Factory)를 사용하도록 강제한다.변동성이 큰 구체 클래스로부터 파생하지 말라.정적 타입 언어에서는 상속은 소스 코드에 존재하는 모든 관계 중에서 가장 강력한 동시에 뻣뻣해서 변경하기 어렵다. 따라서 상속은 아주 신중하게 사용해야 한다.구체 함수를 오버라이드 하지 말라.대체로 구체 함수는 소스 코드 의존성을 필요로 한다. 따라서 구체 함수를 오버라이드 하면 이러한 의존성을 제거할 수 없게 되며, 실제로는 그 의존성을 상속하게 된다.이러한 의존성을 제거하려면, 차라리 추상 함수로 선언하고 구현체들에서 각자의 용도에 맞게 구현해야 한다.구체적인 변동성이 크다면 절대로 그 이름을 언급하지 말라.사실 이 실천법은 DIP 원칙을 다른 방식으로 풀어쓴 것이다.팩토리객체 지향 언어에서 바람직하지 못한 의존성을 처리할 때 추상 패토리를 사용하곤 한다. 의존성을 관리하기 위해 추상 팩토리(Abstract Factory) 패턴을 사용한다.위 그림에서 곡선은 아키텍처 경계를 뜻한다. 이 곡선은 구체적인 것들로부터 추상적인 것들을 분리한다. 소스 코드 의존성은 해당 곡선과 교차할 때 모두 한 방향, 즉 추상적인 쪽으로 향한다.곡선은 시스템을 두 가지 컴포넌트로 분리한다. 하나는 추상 컴포넌트이며, 다른 하나는 구체 컴포넌트다. 추상 컴포넌트는 애플리케이션의 모든 고수준 업무 규칙을 포함한다.제어흐름은 소스코드 의존성과는 정반대 방향으로 곡선을 가로지른다는 점에 주목한다. 다시 말해 소스 코드 의존성은 제어흐름과는 반대 방향으로 역전된다.이러한 이유로 이 원칙을 의존성 역전(Dependency Inversion)이라고 부른다.구체 컴포넌트이전 그림에서 구체 컴포넌트에는 구체적인 의존성(Service Factory Impl - ConcreteImpl)이 하나 있고, 따라서 DIP에 위반 된다.이는 일반적이며 DIP 위배를 모두 없앨 수는 없다.대다수의 시스템은 이러한 구체 컴포넌트를 최소한 하나는 포함할 것이다. 흔히 이 컴포넌트를 메인(Main)이라고 부르는데, main 함수를 포함하기 때문이다.main 함수는 ServiceFactoryImpl의 인스턴스를 생성한 후, 이 인스턴스를 ServiceFactory 타입으로 전역 변수에 저장할 것이다. 그런 다음 Application은 이 전역 변수를 이용해서 ServiceFactoryImpl의 인스턴스에 접근할 것이다.결론그림에서 곡선은 이후의 장에서는 아키텍처 경계가 될 것이다. 그리고 의존성은 이 곡선을 경계로, 더 추상적인 엔티티가 있는 쪽으로만 향한다. 추후 이 규칙은 의존성 규칙(Dependency Rule)이라 부를 것이다." }, { "title": "10장. ISP, 인터페이스 분리 원칙", "url": "/posts/PPPCleanArchitecture_ch10/", "categories": "DDD, 클린 아키텍처 소프트웨어 구조와 설계의 원칙, 3부 설계 원칙", "tags": "DDD, CleanArchitecture", "date": "2022-05-05 23:50:00 +0900", "snippet": "소개클린아키텍처: 소프트웨어 구조와 설계의 원칙 책을 읽고 정리하며 소감을 적는 포스트입니다.ISP: 인터페이스 분리 원칙인터페이스 분리 원칙은 아래의 다이어그램에서 그 이름이 유래했다. 인터페이스 분리 원칙User1은 오직 op1을 User2는 op2만을, User3는 op3만을 사용한다고 가정한다.이 경우 User1은 op2와 op3를 전혀 사용하지 않음에도 User1의 소스코드는 이 두 메서드에 의존하게 된다.이러한 의존성으로 인해 op2가 수정되면 User1도 다시 컴파일 후 새로 배포해야 한다.그래서 아래와 같인 인터페이스를 분리해여 관리 하여야 한다. 분리된 오퍼레이션ISP와 언어앞에서 본 사례는 언터 타입에 의존한다. 정적 타입 언어는 사용자가 import, use 또는 include와 같은 타입 선언문을 사용하도록 강제 한다.이처럼 소스 코드에 포함된included 선언문으로 인해 소스 코드 의존성이 발생하고, 이로 인해 재컴파일 또는 재배포가 강제되는 상황이 무조건 초래한다.루비나 파이썬 같은 동적 타입 언어를 사용하면 정적 타입 언어를 사용할 때보다 유연하며 결합도가 낮은 시스템을 만들 수 있다.이러한 사실로 인해 ISP를 아키텍처가 아니라, 언어와 관련된 문제라고 결론 내릴 여지가 있다.ISP와 아키텍처일반적으로 필요 이상으로 많은 걸 포함하는 모듈에 의존하는 것은 해로운 일이다. 소스코드 의존성의 경우 이는 분명한 사실인데, 불필요한 재컴파일과 재배포를 강제하기 때문이다. 하지만 더 고수준인 아키텍처 수준에서도 마찬가지 상황이 발생한다. 문제가 있는 아키텍처위 그림은 S 시스템 구축에 참여하는 아키텍트가 F라는 프레임워크를 시스템에 도입하기를 원한다. 그리고 F 프레임워크 개발자는 특정한 D 데이터베이스를 반드시 사용하도록 만들었다고 가정한다.따라서 S는 F에 의존하며, F는 다시 D에 의존하게 된다.결론불필요한 짐을 실은 무언가에 의존하면 예상치 못한 문제에 빠진다." }, { "title": "9장. LSP, 리스코프 치환 원칙", "url": "/posts/PPPCleanArchitecture_ch9/", "categories": "DDD, 클린 아키텍처 소프트웨어 구조와 설계의 원칙, 3부 설계 원칙", "tags": "DDD, CleanArchitecture", "date": "2022-05-05 23:30:00 +0900", "snippet": "소개클린아키텍처: 소프트웨어 구조와 설계의 원칙 책을 읽고 정리하며 소감을 적는 포스트입니다.LSP : 리스코프 치환 원칙1988년 바바라 리스코프(Barbara Liskov)는 하위 타입(subtype)을 아래와 같이 정의 했다.S 타입의 객체 o1에 각각에 대응하는 T 타입 객체 o2가 있고, T 타입을 이용해서 정의한 모든 프로그램 P에서 o2의 자리에 o1을 치환하더라도 P의 행위가 변하지 않는다면, S는 T의 하위 타입이다.상송을 사용하도록 가이드하기아래의 그림과 같이 License라는 클래스가 있다고 했을 때, License는 PersonalLicense와 BusinessLicense라는 두 가지 ‘하위 타입’이 존재한다. License와 파생 클래스는 LSP를 준수한다.이 설계는 LSP를 준수하는데 Bulling 애플리케이션의 행위가 License 하위 타입 중 무엇을 사용하는지에 전혀 의존하지 않기 때문이다. 이들 하위 타입은 모두 License 타입을 치환할 수 있다.정사각형/직사각형 문제LSP를 위반하는 전형적인 문제로는 유명한 정사각형/직사각형 문제가 있다. 악명 높은 정사각형/직사각형 문제이 예제에서 Square는 Rectangle의 하위 타입으로는 적합하지 않다.Rectangle의 높이와 너비는 서로 독립적으로 변경될 수 있는 반면, Square의 높이와 너비는 반드시 함께 변경되기 때문이다.Rectangle r = ...r.setW(5);r.setH(2);assert(r.area() == 10)… 코드에서 Square를 생성한다면 assert문은 실패하게 된다.if문 등을 이용해서 Square인지 검사하는 메커니즘을 User에 추가해야 하기 때문에 User는 행위가 사용하는 타입에 의존하게 되므로, 결국 타입을 서로 치환할 수 없게 된다.LSP 아키텍처잘 정의 된 인터페이스와 그 인터페이스의 구현체끼리의 상호 치환 가능성에 기대는 사용자들이 존재하기 때문에 많은 상황에 LSP를 적용 할 수 있다.아키텍처 관점에서 LSP를 이해하는 최선의 방법은 이 원칙을 어겼을 때 시스템 아키텍처에서 무슨 일이 일어나는지 관찰하는 것이다.LSP 위배 사례LSP를 위배하여 개발을 하게 된다면 고객의 요구사항에 대해 예외 사항을 처리하는 로직을 추가해야 한다.만약 택시 파견 서비스를 통합하는 애플리케이션을 만들고 있다고 해본다.퍼플캡이라는 회사에서 아래와 같이 URL을 통해 파견 정보를 호출한다.purplecab.com/driver/Bob\t/pickupAddress/24 Maple St. /pickupTime/153 /destination/ORD또 애크미라는 택시업체가 있고 그 업체의 프로그래머들은 destination을 dest로 축약하여 사용하고 있다.그런데 이 둘 회사가 합쳐진다고 한다면 모든 파견 명령어에 아래와 같이 if 문장을 추가해야 한다.if (driver.getDispatchUri().startsWith(\"acme.com\").....실력 있는 아키텍트라면 당연히 시스템을 이런 식으로 구성하는 것을 용납하지 않는다.아키텍트는 이 같은 버그로 부터 시스템을 격리해야 한다.이때 파견 URI를 키로 사용하는 설정용 데이터베이스를 이용하는 파견 명령 생성 모듈을 만들어야 할 수도 있다. URI Dispatch Format Acme.com /pickupAddress/%s/pickupTime/%s/dest/%s *.* /pickupAddress/%s/pickupTime/%s/destination/%s 또한 아키텍트는 REST 서비스들의 인터페이스가 서로 치환 가능하지 않다는 사실을 처리하는 중요하고 복잡한 매커니즘을 추가해야 한다.결론LSP는 아키텍처 수준까지 확장할 수 있고, 반드시 확장해야만 한다.치환 가능성을 조금이라도 위배하면 시스템 아키텍처가 오염되어 상당량의 별도 메커니즘을 추가해야 할 수 있기 때문이다." }, { "title": "8장. OCP, 개방-폐쇄 원칙", "url": "/posts/PPPCleanArchitecture_ch8/", "categories": "DDD, 클린 아키텍처 소프트웨어 구조와 설계의 원칙, 3부 설계 원칙", "tags": "DDD, CleanArchitecture", "date": "2022-05-05 21:00:00 +0900", "snippet": "소개클린아키텍처: 소프트웨어 구조와 설계의 원칙 책을 읽고 정리하며 소감을 적는 포스트입니다.OCP: 개방-폐쇄 원칙개방-폐쇄 원칙(OCP)이라는 용어는 1988년에 버트란트 마이어(Bertrand Meyer)가 만들었는데, 다음과 같다.소프트웨어 개체(artifact)는 확장에는 열려 있어야 하고, 변경에는 닫혀 있어야 한다.다시 말해 소프트웨어 개체의 행위는 확장할 수 있어야 하지만, 이때 개체를 변경해서는 안 된다.소프트웨어 아키텍처를 공부하는 가장 근본적인 이유이기도 하다. 만약 요구사항을 살짝 확장하는 데 소프트웨어를 엄청나게 수정해야 한다면 그 소프트웨어 시스템을 설계한 아키텍트는 엄청난 실패에 맞닥뜨린 것이다.대다수 개발자들은 OCP가 클래스와 모듈을 설계할 때 도움되는 원칙이라고 알고 있지만 아키텍처 컴포넌트 수준에서 OCP를 고려할 때 훨씬 중요한 의미를 가진다.사고 실행제무제표를 웹 페이지로 보여주는 시스템이 있다고 가정한다.웹 페이지에 표시되는 데이터는 스크롤할 수 있으며, 음수는 빨간색으로 출력한다.하지만 이해관계자가 동일한 정보를 보고서 형태로 변환해서 흑백 프린터로 출력해 달라고 요청했다고 해보자. 페이지 번호가 있어야 한다. 페이지 마다 적절한 머리글과 바닥글이 있어야 한다. 표의 각 열에는 레이블이 있어야 한다. 음수는 괄호로 감싸야 한다.소프트웨어 악키텍처가 훌륭하다면 변경되는 코드의 양이 가능한 한 최소화 될 것이다. 이상적인 변경량은 0이다.서로 다른 목적으로 변경되는 요소를 적절하게 분리하고(단일 책임 원칙SRP), 이들 요소 사이의 의존성을 체계화함으로써(의존성 역전 원칙DIP) 변경량을 최소화 할 수 잇다. SRP 적용하기여기서 가장 중요한 영감은 보고서 생성이 두 개의 책임으로 분리된다는 사실이다.이 처럼 웹과 프린터로 분리가 되어 있다면 두 책임 중 하나에서 변경이 발생하더라도 다른 하나는 변경되지 않도록 소스 코드 의존성도 확실히 조직화해야 한다.또한, 새로운 조직화한 구조에서는 행위가 확장 될 때 변경이 발생하지 않음을 보장해야 한다. 처리 과정을 클래스 단위로 분할하고, 클래스는 컴포넌트 단위로 분리한다.위 그림에서 좌측 상단의 컴포넌트는 Controller이고 우측 상단은 Interractor 컴포넌트를, 우측 하단에서는 Database 컴포넌트를 볼 수 있다. 좌측 하단에는 Presenter와 View를 담당하는 네 가지 컴포넌트가 위치한다.여기서 주목할 점은 모든 의존성이 소스 코드 의존성을 나타낸다는 사실이다. FinancialDataMapper는 구현 관계를 통해 FinancialDataGateway를 알고 있지만, FinancialDataGateway는 FinancialDataMapper에 대해 아무것도 알지 못한다. 컴포넌트 관계는 단방향으로만 이루어진다.모든 컴포넌트 관계는 단방향으로 이루어진다. 이들 화살표는 변경으로 부터 보호하려는 컴포넌트를 향햐도록 그려진다.A 컴포넌트에서 발생한 변경으로 부터 B 컴포넌트를 보호하려면 반드시 A 컴포넌트가 B 컴포넌트에 의존해야 한다. Presenter에서 발생한 변경으로부터 Controller를 보호하고자 한다. View에서 발생한 변경으로부터 Presenter를 보호하고자 한다. Interactor는 다른 모든 것에서 발생한 변경으로부터 보호하고자 한다.Interator는 OCP를 가장 잘 준수할 수 있는 곳에 위치한다. Database, Controller, Presenter, View에서 발생한 어떤 변경도 Interator에 영향을 주지 않는다.Interactor는 업무 규칙을 포함하기 때문에 애플리케이션에서 가장 높은 수준의 정책을 포함해야 한다.아키텍트는 기능이 어떻게(how), 왜(why), 언제(when) 발생하는지에 따라서 기능을 분리하고, 분리한 기능을 컴포넌트의 계층구조로 조직화한다.컴포넌트 계층구조를 이와 같이 조직화하면 저수준 컴포넌트에서 발생한 변경으로부터 고수준 컴포넌트를 보호 할 수 있다.방향성 제어위 다이어그램은 컴포넌트 간 의존성이 제대로 된 방향으로 향하고 있음을 보여준다.예를 들어 FinancialDataGateway 인터페이스는 FinancialReportGenerator와 FinancialDataMapper 사이에 위치하는데, 이는 의존성을 역전시키기 위해서다.정보은닉FinancialReportRequester 인터페이스는 방향성 제어와는 다른 목적을 가진다. 이 인터페이스는 FinancialReportController가 Interactor 내부에 대해 너무 많이 알지 못하도록 막기 위해서 존재한다.만약 이 인터페이스가 없다면 Controller는 FinancialEntities에 대해 추이 종속성(transitive dependency)를 가지게 된다.추이 종속성을 가지게 되면, 소프트웨어 엔티티는 자신이 직접 사용하지 않는 요소에는 절대로 의존해서는 안 된다.는 소프트웨어 원칙을 위반하게 된다.결론OCP는 시스템의 아키텍처가 떠받치는 원동력 중 하나다. OCP의 목표는 시스템을 확장하기 쉬운 동시에 변경으로 인해 시스템이 너무 많은 영향을 받지 않도록 하는 데 있다.이러한 목표를 달성하려면 시스템을 컴포넌트 단위로 분리하고, 저수준 컴포넌트에서 발생한 변경으로부터 고 수준 컴포넌트를 보호 할 수 있는 형태의 의존성 계층 구조가 만들어지도록 해야 한다." }, { "title": "7장. SRP, 단일 책임 원칙", "url": "/posts/PPPCleanArchitecture_ch7/", "categories": "DDD, 클린 아키텍처 소프트웨어 구조와 설계의 원칙, 3부 설계 원칙", "tags": "DDD, CleanArchitecture", "date": "2022-05-05 20:30:00 +0900", "snippet": "소개클린아키텍처: 소프트웨어 구조와 설계의 원칙 책을 읽고 정리하며 소감을 적는 포스트입니다.SRP: 단일 책임 원칙SOLID 원칙 중에서 그 의미가 가장 잘 전달되지 못한 원칙은 바로 단일 책임 원칙(SRP)이다.프로그래머 입장에서는 모든 모듈이 단 하나의 일만 해야 한다는 의미로 받아들이기 쉽다.헷갈리면 안된다. 함수가 단 하나의 일을 해야한다는 원칙을 가지고 있고 SRP의 의미는 아래와 같다단일 모듈은 변경의 이유가 하나, 오직 하나뿐이어야 한다.변경을 요청하는 한 명 이상의 사람들을 액터(Actor)라고 부른다면 아래와 같다.하나의 모듈은 하나의, 오직 하나의 액터에 대해서만 책임져야 한다.모듈이란 가장 단순한 정의는 바로 소스 파일이다. 모듈은 단순히 함수와 데이터 구조로 구성된 응집된 집합이다.응집된(cohesive)이라는 단어가 SRP를 암시한다. 단일 액터를 책임지는 코드를 함께 묶어 주는 힘이 바로 응집성이다.징후 1: 우발적 중복 Employee 클래스위 클래스는 세 가지 메서드 calculatePay() reportHours(), save()를 가진다.이 클래스는 SRP를 위반하는데, 이들 세 가지 메서드가 서로 매우 다른 세명의 액터를 책임지기 때문이다. calculatePay() 메서드는 회계팀에서 기능을 정의하며, CFO 보고를 위해 사용한다. reportHours() 메서드는 인사팀에서 기능을 정의하고 사용하며, COO 보고를 위해 사용한다. save() 메서드는 데이터베이스 관리자(DBA)가 기능을 정의하고, CTO 보고를 위해 사용한다.세 액터가 서로 결합되어 버려 CFO 팀에서 결정한 조치가 COO팀이 의존하는 무언가에 영향을 줄 수 있다.예를 들어 calculatePay() 메서드와 reportHours() 메서드가 초과 근무를 제외한 업무 시간을 계산하는 알고리즘을 공유한다고 해보자.그리고 개발자는 코드 중복을 피하기 위해 이 알고리즘을 regularHours()라는 메서드에 넣었다고 해보자 공유된 알고리즘이제 CFO팀에서 초과 근무를 제외한 업무 시간을 계산하는 방식을 약간 수정하기로 결정했다고 하자. 반면 인사를 담당하는 COO팀에서는 초과 근무를 제외한 업무 시간을 CFO 팀과는 다른 목적으로 사용하기 때문에, 이 같은 변경을 원하지 않는다고 해보자.이 변경을 적용하는 업무를 할당받은 개발자는 calculatePay() 메서드가 펴느이 메서드인 regularHours()를 호출한다는 사실을 발견한다. 하지만 안타깝게도 이 함수가 reportHours() 메서드에서도 호출된다는 사실을 눈치채지 못한다.징후 2 : 병합소스 파일에 다양하고 많은 메서드를 포함하면 병합이 자주 발생하고 이들 메서드가 서로 다른 액터를 책임진다면 병합이 발생할 가능성이 확실히 더 높다.두 명의 서로 다른 개발자가, 그리고 아마도 서로 다른 팀에 속했을 두 개발자가 Employee 클래스를 체크아웃 받은 후 변경사항을 적용하기 시작하면 안타깝게도 이들 변경 사항이 서로 충돌한다. 결과적으로 병합이 발생한다.병합에는 위험이 따른다고 굳이 말하지 않아도 될 것이다. 어떤 도구도 병합이 발생하는 모든 경우를 해결할 수는 없다.이 문제를 벗어나는 방법은 서로 다른 액터를 뒷받침하는 코드를 서로 분리하는 것이다.해결책이 문제의 해결책은 다양한데, 그 모두가 메서드를 각기 다른 클래스로 이동시키는 방식이다. 가장 확실한 해결책은 데이터와 메서드를 분리하는 방식이다.즉, 아무런 메서드가 없는 간단한 데이터 구조인 EmployeeData 클래스를 만들어, 세 개의 클래스가 공유하도록 한다.각 클래스는 자신의 메서드에 반드시 필요한 소스 코드만 포함한다. 세 클래스는 서로의 존재를 몰라야 한다. 따라서 우연한 중복을 피할 수 있다. 세 클래스는 서로의 존재를 알지 못한다.반면 이 해결책은 개발자가 세 가지 클래스를 인스턴스화하고 추적해야 한다는 게 단점이다. 이러한 난관에서 빠져나올 때 흔히 쓰는 기법으로 퍼사드(Facade) 패턴이 있다. 퍼사드(Facade) 패턴EmployeeFacade에 코드는 거의 없다. 이 클래스는 세 클래스의 객체를 생성하고, 요청된 메서드를 가지는 객체로 위임하는 일을 책임진다.가장 중요한 엄무 규칙을 데이터와 가깝게 배치하는 방식을 선호한다면 아래와 같이 기존의 Employee 클래스를 그대로 유지하되, Employee 클래스를 덜 중요한 나머지 메서드들에 대한 퍼사드로 사용 할 수 있다. 가장 중요한 메서드는 기존의 Employee 클래스에 그대로 유지하되, Employee 클래스를 덜 중요한 나머지 메서드들에 대한 퍼사드로 사용한다.이 처럼 여러 메서드가 하나의 가족을 이루고, 메서드의 가족을 포함하는 각 클래스는 하나의 유효범위가 된다.해당 유효범위 바깥에서는 이 가족에게 감춰진 식구(private 멤버)가 있는지를 전혀 알 수 없다.결론단일 책임 원칙은 메서드와 클래스 수준의 원칙이다. 하지만 이보다 상위 두 수준에서도 다른 형태로 다시 등장한다.컴포넌트 수준에서는 공통 패쇄 원칙(Common Closure Principle)이 된다.아키텍처 수준에서는 아키텍처 경계(Architectural Boundary)의 생성을 책임지는 변경의 축(Axis of Change)이 된다." }, { "title": "6장. 함수형 프로그래밍", "url": "/posts/PPPCleanArchitecture_ch6/", "categories": "DDD, 클린 아키텍처 소프트웨어 구조와 설계의 원칙, 2부 벽돌부터시작하기:프로그래밍 패러다임", "tags": "DDD, CleanArchitecture", "date": "2022-05-02 23:30:00 +0900", "snippet": "소개클린아키텍처: 소프트웨어 구조와 설계의 원칙 책을 읽고 정리하며 소감을 적는 포스트입니다.함수형 프로그래밍이 패러다임에서 핵심이 되는 기반은 람다(lambda) 계산법으로 알론조 처치(alonzo Church)가 1930년대에 발명했다.정수를 제곱하기함수형 프로그래밍이 무엇인지 설명하기 위해 아래의 예제를 보자public class Squint { public static void main(String args[]){ for(int i=0; i&lt;25; i++) System.out.println(i*i); }}리스프에서 파생한 클로저(Clojure)는 함수형 언어로 아래와 같이 구현 할 수 있다.(println(take 25(map(fn[x](* x x)) (range))))(println :___ 출력한다. (take 25 :___ 처음부터 25까지 (map(fn[x](* x x)) :___ 제곱을 (range)))) :___ 정수의자바는 가변 변수(mutable variable)를 사용하는데, 가변 변수는 프로그램 실행 중에 상태가 변할 수 있다.반복문을 제어하는 변수인 i가 가변 변수다.하지만 클로저에서는 x와 같은 변수가 한 번 초기화 되면 절대로 변하지 않는다.불변성와 아키텍처왜 아키텍트는 변수의 가변성을 염려해야 하는가?? 단순한 이유이지만 경합(race)조건, 교착 상태(deadlock) 조건, 동시 업데이트(concurrent update) 문제가 모두 가변 변수로 인해 발생하기 때문이다.락(lock)이 가변적이지 않다면 교착상태도 일어나지 않는다.아키텍트라면 동시성(concurrency)문제에 지대한 관심을 가져야만 한다.가변성의 분리불변성과 관련하여 가장 주요한 타협 중 하나는 애플리케이션, 또는 애플리케이션 내부의 서비스를 가변 컴포넌트와 불변 컴포넌트로 분리하는 일이다. 상태 변경과 트랜잭션 메모리(transactional memory)상태 변경은 컴포넌트를 갖가지 동시성 문제에 노출하는 꼴이므로, 흔히 트랜잭션 메모리(transactional memory)와 같은 실천법을 사용하여 동시 업데이트와 경합 조건 문제로부터 가변 변수를 보호한다.트랜잭션 메모리는 데이터베이스가 디스크의 레코드를 다루는 방식과 동일한 방식으로 메모리의 변수를 처리한다. 즉, 트랜잭션을 사용하거나 또는 재시도 기법을 통해 이들 변수를 보호한다.하지만 안타깝게도 여러 변수가 상호 의존하는 상황에서는 동시 업데이트와 교착상태 문제로 부터 보호해 주지 못한다.애플리케이션을 제대로 구조화하려면 변수를 변경하는 컴포넌트와 변경하지 않는 컴포넌트를 분리해야 한다.현명한 아키텍트라면 가능한 한 많은 처리를 불변 컴포넌트로 옮겨야 하고, 가변 컴포넌트에서는 가능한 한 많은 코드를 빼내야 한다.이벤트 소싱간단한 예로, 고객의 계좌 잔고를 관리하는 은행 애플리케이션에서 입근 트랜잭션과 출금 트랜잭셩이 실행되면 잔고를 변경해야 한다.이제 계좌 잔고를 변경하는 대신 트랜잭션 자체를 저장한다고 상상해 보다.터무니 없는 접근법이다. 시간이 지날수록 트랜잭션 수는 끝없이 증가하고, 컴퓨팅 자원은 걷잡을 수 없이 커진다.하지만 이 전략이 영원히 동작할 필요는 없다. 애플리케이션의 수명주기 동안만 문제 없이 동작할 정도의 저장 공간과 처리 능력만 있으면 충분할 것이다.이것이 이벤트 소싱(event sourcing)의 기본 발상이다.이벤스 소싱은 상태가 아닌 트랜잭션을 저장하자는 전략이다. 상태가 필요해지면 단순히 상태의 시작점부터 모든 트랜잭션을 처리한다.결과적으로 애플리케이션은 CRUD가 아니라 CR만 수행한다. 저장공간과 처리능력이 충분하면 애플리케이션이 완전한 불변성을 갖도록 만들 수 있고, 따라서 완전한 함수형으로 만들수 있다.결론 구조적 프로그래밍은 제어흐름의 직접적인 전환에 부과되는 규율이다. 객체 지향 프로그래밍은 제어흐름의 간접적인 전환에 부과되는 규율이다. 함수형 프로그래밍은 변수 항당에 부과되는 규율이다.도구는 달라졌고 하드웨어도 변했지만, 소프트웨어의 핵심은 여전히 그대로다.순차(sequence), 분기(selection), 반복(iteration), 참조(indirection)으로 구성된다.그 이상도 이하도 아니다." }, { "title": "5장. 객체 지향 프로그래밍", "url": "/posts/PPPCleanArchitecture_ch5/", "categories": "DDD, 클린 아키텍처 소프트웨어 구조와 설계의 원칙, 2부 벽돌부터시작하기:프로그래밍 패러다임", "tags": "DDD, CleanArchitecture", "date": "2022-05-02 23:30:00 +0900", "snippet": "소개클린아키텍처: 소프트웨어 구조와 설계의 원칙 책을 읽고 정리하며 소감을 적는 포스트입니다.객체 지향 프로그래밍좋은 아키텍처를 만드는 일은 객체지향(OO) 설계 원칙을 이해하고 응용하는 데서 출발한다. 그럼 OO란 무엇인가?“데이터와 함수의 조합”의 답은 o.f()가 왼지 f(o)와 다르다는 의미를 내포하고 있어 별로다.“시렞 세계를 모델링하는 새로운 방법”의 답은 얼버무리는 수준이다.OO의 본질을 설명하기 위해 캡슐화(encapsulation), 상속(inheritance), 다형성(polymorphism)이 세 가지 개념을 적절하게 조합한 것이거나, 또는 OO 언어는 최소한 세 가지 요소를 반드시 지원해야 한다고 말하는 부류들이 있다.캡슐화?데이터와 함수가 응집력 있게 구성된 집단을 서로 구분 짓는 선을 그을 수 있다.구분선 바깥에서 데이터는 은니고디고, 일부 함수만이 외부에 노출된다.사실 C 언어에서도 완벽한 캡슐화가 가능하다. point.h struct Point;struct Point* makePoint(double x, double y);double distance (struct Point *p1, struct Point *p2); point.c```c#include “point.h”#include #include struct Point { double x,y;}struct Point* makepoint(double x, double y) { struct Point* p = malloc(sizeof(struct Point)); p-&gt;x = x; p-&gt;y = y; return p;}double distance(struct Point* p1, struct Point* p2){ double dx = p1 -&gt; x - p2 -&gt; x; double dy = p1 -&gt; y - p2 -&gt; y; return sqrt(dxdx+dydy);}point.h를 사용하는 측에서는 `struct Point`의 멤버에 접근할 방법이 전혀 없다.이것이 바로 완벽한 캡슐화이며, 보다시피 OO가 아닌 언어에서도 충분히 가능하다.Java와 C#은 헤더와 구현체를 분리하는 방식을 모두 버렸고, 이로 인해 캡슐화는 더웃 심하게 훼손되었다. 이들 언어에서는 클래스 선언과 정의를 구분하는게 아예 불가능하다.OO 프로그래밍은 프로그래머가 충분히 올바르게 행동함으로써 캡슐화된 데이터를 우회해서 사용하지 않을 거라는 믿음을 기반으로 하지만 실제로는 C 언어에서 누렸던 완벽한 캡슐화를 약화시켜 온 것이 틀림없다.## 상속?상속이란 단순히 어떤 변수와 함수를 하나의 유효 범위로 묶어서 재정의하는 일에 불괗다.&gt; namedPoint.h```cstruct NamedPoint;struct NamedPoint* makeNamedPoint(double x, double y, char* name);void setName(struct NamedPoint* np, char* name);char* getName(struct NamedPoint* np); namedPoint.c```c#include “namedPoint.h”#include struct NamedPoint { double x,y; char *name;};struct NamedPoint* makeNamedPoint(double x, double y, char* name) { struct NamedPoint* p = malloc(sizeof(struct NamedPoint)); p-&gt;x = x; p-&gt;y = y; p-&gt;name = name; return p;}void setName(struct NamedPoint* np, char* name) { np-&gt;name = name;}char* getName(struct NamedPoint* np) { return np -&gt; name;}&gt; main.c```c#include \"point.h\"#include \"namedPoint.h\"#include &lt;stdio.h&gt;int main(int ac, char** av) { struct NamedPoint* origin = makeNamedPoint(0.0, 0.0, \"origin\"); struct NamedPoint* upperRight = makeNamePoint(1.0, 1.0, \"upperRight\"); printf(\"distance=%f\\n\", distance( (struct Point*) origin, (struct Point*) upperRight ));}main을 보면 NamedPoint 데이터 구조가 마치 Point 데이터 구조로 부터 파생된 구조인 것처럼 동작한다는 사실을 볼 수 있다.NamedPoint는 Point의 가면을 쓴 것처럼 동작 할 수 있는데, 이는 NamedPoint가 순전히 Poiont를 포함하는 상위 집합으로, Point에 대응하는 멤버 변수의 순서가 그대로 유지되기 때문이다.다형성?#include &lt;stdio.h&gt;void copy() { int c; while ((c=getchar()) != EOF) putchar(c);}getchar() 함수는 STDIN에서 문자를 읽는다. 그러면 STDIN은 어떤 장치인가?putchar()함수는 STDOUT으로 문자를 쓴다. 그런데 STDOUT은 또 어떤 장치인가?이러한 함수는 다형적(polymorphic)이다. 즉, 행위가 STDIN과 STDOUT의 타입에 의존한다.FILE 데이터 구조는 열기(open), 닫기(close), 읽기(read), 쓰기(write), 탐색(seek)의 표준함수들을 포함한다.struct FILE { void (*open)(char* name, int mode); void (*close)(); int (*read)(); void (*write)(char); void (*seek)(long index, int mode);}콘솔용 입출력 드라이버에서는 이들 함수를 아래와 같이 정의하며, FILE 데이터 구조를 함수에 대한 주소와 함께 로드한다.#include \"file.h\"void (*open)(char* name, int mode) {/*...*/}void (*close) {/*...*/};int (*read) {/*...*/}void (*write)(char) {/*...*/}void (*seek)(long index, int mode) {/*...*/}struct FILE console = {open, close, read, write, seek};이제 STDIN을 FILE*로 선언하면, STDIN은 콘솔 데이터 구조를 가리키므로, getchar()는 아래와 같은 방식으로 구현할 수 있다.extern struct FILE* STDIN;int getchar() { return STDIN-&gt;read();}함수를 가리키는 포인터를 응용한 것이 다형성이라는 점을 말하고 있다.1940년대 후반 폰 노이만(Von Neumann) 아키텍처가 처음 구현된 이후 프로그래머는 다형적 행위를 수행하기 위해 함수를 가리키는 포인터를 사용해 왔다. 따라서 OO가 새롭게 만든 것은 전혀 없다.하지만 OO 언어는 다형성을 좀 더 안전하고 더욱 편리하게 사용할 수 있게 해준다.함수에 대한 포인터를 직접 사용하여 다형적 행위를 만드는 이 방식은 문제가 있는데, 함수 포인터가 위험하다는 사실이다. 만약 프로그래머가 특정 관례를 지키지 못한다면 버그가 발생하고, 이러한 버그는 찾아내고 없애기가 지독히 힘들다.다형성이 가진 힘다형성이 가진 매력의 진가를 알아보기 위해 복사 프로그램 예제를 다시 살펴본다.새로운 입출력 장치가 생긴다면 프로그램에는 어떤 변화가 생기는가? 새로운 장비에서도 복사 프로그램이 동작하도록 만들려면 어떻게 수정해야 하는가?아무런 변경도 필요치 않다! 복사 프로그램 소스 코드는 입출력 드라이버의 소스 코드에 의존하지 않기 때문이다.다시 말해 입출력 드라이버가 복사 프로그램의 플러그인(plugin)이 된것이다.의존성 역전다형성을 안전하고 편리하게 적용할 수 있는 메커니즘이 등장하기 전에는 main 함수가 고수준 함수를 호출하고, 고수준 함수는 다시 중간 수준 함수를 호출하며, 중간 함수는 다시 저수준 함수를 호출했다.이러한 호출 트리에서는 의존성의 방향이 반드시 제어흐름(flow of control)을 따르게 된다. 소스 코드 의존성 vs. 제어 흐름제어흐름은 시스템의 행위에 따라 결정되며, 소스 코드 의존성은 제어흐름에 따라 결정된다.하지만 다형성이 끼어들면 무언가 특별한 일이 일어난다. 의존성 역전ML1과 I 인터페이스 사이의 소스 코드 의존성(상속 관계)이 제어흐름과는 반대인 점을 주목해야 한다.이는 의존성 역전(dependency inversion)이라고 부르며, 소프트웨어 아키텍트 관점에서 이러한 현상은 심오한 의미를 갖는다.예를 들어 업무 규칙이 데이터베이스와 사용자 인터페이스(UI)에 의존하는 대신에, 시스템의 소스 코드 의존성을 반대로 배치하여 데이터베이스와 UI가 업무 규칙에 의존하게 만들 수 있다. 데이터베이스와 사용자 인터페이스가 업무 규칙에 의존한다.즉, UI와 데이터베이스가 업무 규칙의 플러그인이 된다는 뜻이다. 다시 말해 업무 규칙의 소스 코드에서는 UI나 데이터베이스를 호출하지 않는다.따라서 업무 규칙을 UI와 데이터베이스와 독립적으로 배포할 수 있다. UI나 데이터베이스에서 발생한 변경사항은 업무 규칙에 일절 영향을 미치지 않는다.즉, 이들 컴포넌트는 개별적이며 독립적으로 배포 가능하다.다시 말해 특정 컴포넌트의 소스코드가 변경되면, 해당 코드가 포함된 컴포넌트만 다시 배포하면 된다. 이것이 배포 독립성(independent deployability)다.시스템의 모듈을 독립적으로 배포할 수 있게 되면, 서로 다른 팀에서 각 모듈을 독립적으로 개발할 수 있다. 그리고 이것이 개발 독립성(independent developability)이다" }, { "title": "4장. 구조적 프로그래밍", "url": "/posts/PPPCleanArchitecture_ch4/", "categories": "DDD, 클린 아키텍처 소프트웨어 구조와 설계의 원칙, 2부 벽돌부터시작하기:프로그래밍 패러다임", "tags": "DDD, CleanArchitecture", "date": "2022-05-01 22:00:00 +0900", "snippet": "소개클린아키텍처: 소프트웨어 구조와 설계의 원칙 책을 읽고 정리하며 소감을 적는 포스트입니다.구조적 프로그래밍증명데이크스트라는 초기에 인식한 문제는 프로그래밍은 어렵고, 프로그래머는 프로그래밍을 잘하지 못한다는 사실이었다.데이크스트라는 연구를 진행하면서 goto 문장이 모듈을 더 작은 단위로 재귀적으로 분해하는 과정에 방해가 되는 경우가 있다는 사실을 발견했다.만약 모듈을 분해할 수 없다면, 합리적으로 증명할 때 필수적인 기법인 분할 정복 접근법을 사용할 수 없게 된다.반면 goto 문장을 사용하더라도 모듈을 분해할 때 문제가 되지 않는 경우도 있었다. 데이크스트라는 이런 goto문의 ‘좋은’ 사용 방식은 if/then/else와 do/while과 같은 분기와 반복이라는 단순한 제어 구조에 해당한다는 사실을 발견했다.모듈이 이러한 종류의 제어 구조만 사용한다면 증명가능한 단위로까지 모듈을 재귀적으로 세분화하는 것이 가능해 보였다.즉, 모듈을 증명가능하게 하는 바로 그 제어 구조가 모든 프로그램을 만들 수 있는 제어 구조의 최소 집합과 동일하다는 사실이였다. 구조적 프로그래밍은 이렇게 탄생했다.해로운 성명서1968년 데이크스트라는 CACM(Communications of the ACM)에 goto문에 해로움이라는 편지를 썼고, 프로그래밍 세계는 불이 붙었다.이 논쟁에서 데이크스트라가 승리했고 goto문은 사라졌다.현재는 우리 모두 구조적 프로그래머이며, 제어흐름을 제약 없이 직접 전환할 수 있는 선택권 자체를 언어에서 제공하지 않는다.기능적 분해구조적 프로그래밍을 통해 모듈을 증명 가능한 더 작은 단위로 재귀적으로 분해할 수 있게 되었고, 이는 결국 모듈을 기능적으로 분해할 수 있음을 뜻했다.드워드 요던(Ed Yourdon), 래리 콘스탄틴(Larry Constantine), 톰 드마르코(Tom DeMarco), 밀러 페이지 존스(Meilir Page-Jones) 같은 이들은 이 구조적 분석, 설계와 같은 기법을 개선했고 더 널리 알렷다.프로그래머는 대규모 시스템을 모듈과 컴포넌트로 나눌 수 있고, 더 나아가 모듈과 컴포넌트는 입증할 수 있는 아주 작은 기능들로 세분화 할 수 있다.엄밀한 증명은 없었다.대개의 프로그래머들은 세세한 기능 하나하나를 엄밀히 증명하는 고된 작업에서 이득을 얻으리라고는 보지 않았다.결국 데이크스트라의 꿈은 빛을 바랬고, 사라졌다.오늘날 이처럼 엄밀한 증명이 고품질의 소프트웨어를 생산하기 위한 적절한 방법이라고 믿는 프로그래머는 이제 거의 없다.과학이 구출하다.과학은 근본적으로 수학과 다른데, 과학 이론과 법칙은 그 올바름을 절대 증명할 수 없기 때문이다.과학은 서술된 내용이 사실임을 증명하는 방식이 아니라 서술이 틀렸음을 증명하는 방식으로 동작한다.수학은 증명 가능한 서술이 참임을 입증하는 원리라고 볼 수 있다. 반면, 과학은 증명 가능한 서술이 거짓임을 입증하는 원리라고 볼 수 있다.테스트데이크스트라는 테스트는 버그가 있음을 보여줄 뿐, 버그가 없을을 보여줄 수는 없다고 말한 적이 있다.테스트에 충분한 노력을 들였다면 테스트가 보장할 수 있는 것은 프로그램이 목표에 부합할 만큼은 충분히 참이라고 여길 수 있게 해주는 것이 전부다.예를 들어 제약 없는 goto문을 사용하는 등의 이류로 입증이 불가능한 프로그램은 테스트를 아무리 많이 수행하더라도 절대로 올바르다고 볼 수 없다.구조적 프로그래밍은 프로그램을 증명 가능한 세부 기능 집합으로 재귀적으로 분해할 것을 강요한다.결론가장 작은 기능에서부터 가장 큰 컴포넌트에 이르기까지 모든 수준에서 소프트웨어는 과학과 같고, 따라서 반증 가능성에 의해 주도된다.소프트웨어 아키텍트는 모듈, 컴포넌트, 서비스가 쉽게 반증 가능하도록(테스트하기 쉽도록) 만들기 위해 분주히 노력해야 한다." }, { "title": "3장. 패러다임 개요", "url": "/posts/PPPCleanArchitecture_ch3/", "categories": "DDD, 클린 아키텍처 소프트웨어 구조와 설계의 원칙, 2부 벽돌부터시작하기:프로그래밍 패러다임", "tags": "DDD, CleanArchitecture", "date": "2022-05-01 21:30:00 +0900", "snippet": "소개클린아키텍처: 소프트웨어 구조와 설계의 원칙 책을 읽고 정리하며 소감을 적는 포스트입니다.패러다임 개요구조적 프로그래밍(Structured Programming)최초로 적용된 패러다임은 구조적 프로그래밍으로, 1968년 에츠허르 비버 데이크스트라(Edsger Wybe Dijkstra)가 발견했다.데이크스트라는 무분별한 점프(goto)는 프로그래밍에 해롭다는 사실을 제시하고 if/then/else와 do/while/until 과 같은 더 익숙한 구조로 대체 했다. 구조적 프로그래밍은 제어흐름의 직접적인 전환에 대해 규칙을 부과 한다.객체 지향 프로그래밍(Object-Oriented Programming)1966년, 올레 요한 달(Ole Johan Dahi)과 크리스텐 니가드(Kristen Nygaard)에 의해 등장 했다.알골(ALGOL)언어의 함수 호출 스택 프레임을 힙으로 옮기면, 함수 호출이 반환된 이후에도 함수에서 선언된 지역 변수가 오랫동안 유지될 수 있음을 발견했다.바로 이러한 함수가 클래스의 생성자가 되었고, 지역 변수는 인스턴스 변수, 그리고 중첩 함수는 메서드가 되었다.함수 포인터를 특정 규칙에 따라 사용하는 과정을 통해 필연적으로 다형성이 등장하게 되었다. 객체 지향 프로그래밍은 제어흐름의 간접적인 전환에 대해 규칙을 부과한다.함수형 프로그래밍(Functional Programming)최근에야 도입되기 시작했지만 세 패러다임 중 가장 먼저 만들어졌다.알론조 처치(Alonzo Church)는 람다(lambda)계산법을 발명했는데, 함수형 프로그래밍은 이러한 영향을 받아 만들어졌다.1958년 존 매카시(John McCarthy)가 만든 LISP 언어의 근간이 되는 개념이 바로 이 람다 계산법이다.람다 계산법의 기초가 되는 개념은 불변성(immutability)으로 심볼(symbol)의 값이 변경되지 않는다는 개념이다. 함수형 프로그래밍은 할당문에 대해 규칙을 부과한다.생각할 거리각 패러다임은 프로그래머에게서 권한을 박탈한다. 어느 패러다임도 새로운 권한을 부여하지 않는다.세 가지 패러다임은 각각 우리에게 goto문, 함수 포인터, 할당문을 앗아갔다.아마 우리에게서 더 가져갈 것이 없기 때문에 이제 패러다임은 딱 이 세 가지 밖에 남지 않을 것이다.결론우리가 패러다임으로 얻을 수 있는 교훈은 관계이다.우리는 아키텍처 경계를 넘나들기 위한 메커니즘으로 다형성을 이용한다.우리는 함수형 프로그래밍을 이용하여 데이터의 위치와 접근 방법에 대해 규칙을 부과 한다.우리는 모듈 기반 알고리즘으로 구조적 프로그래밍을 사용한다.세가지 패러다임과 아키텍처의 세 가지 큰 관심사(함수, 컴포넌트 분리, 데이터 관리)가 어떻게 서로 연관되는지에 주족해야 한다." }, { "title": "EF Core Fluent API Entity Configuration", "url": "/posts/EFCore-FluentAPI-EntityConfig/", "categories": ".NET, EF Core", "tags": ".NET, C#, EF Core", "date": "2022-04-29 12:20:00 +0900", "snippet": "소개이번 포스트는 EF Core에서 Fluent API 패턴을 기반으로 한 Entity Configuration에 대해 정리하도록 하겠습니다.Entity ConfigurationEntity Configuration은 테이블 및 관계 매핑에 대해 구성합니다.PrimaryKey(기본 키), AlternateKey(대체 키), Index, Table Name, 1대1 관계, 1대N 관계, N대N 관계에 대해 정의 합니다. Methods 사용법 HasAlternateKey() 엔티티에 대한 EF 모델의 대체 키 구성. HasIndex() 지정 된 속성의 인덱스 구성 HasKey() 속성 또는 속성 목록을 기본 키로 구성 HasMany() 일대다 또는 다대다 관계에 대해 다른 유형의 참조 수집 속성을 포함하는 관계에서 여러 부분을 구성한다. HasOne() 일대일 관계 또는 일대다 관계에 대한 다른 유형의 참조 속성을 포함하는 관계 중 하나 부분 구성. Ignore() 클래스 또는 속성을 테이블 또는 열에 매핑하지 않도록 구성. OwnsOne() 이 엔티티가 대상 엔티티를 소유하는 관계 구성대상 엔티티 키 값은 해당 엔티티가 속한 엔티티에서 전파된다. ToTable() 엔티티가 매핑할 데이터베이스 테이블 구성 HasAlternateKey()EF Core의 핵심 API 중 하나인 HasAlternateKey 메서드는 기본 키를 제외하고 제약 조건을 구성하여 대체 키를 생성할 수 있도록 합니다.쉽게 말해 기본 키를 제외하고 나머지 컬럼을 조합하여 키를 생성하는 방법입니다. 이는 일반적으로 데이터의 고유성을 보장하기 위해 수행합니다.아래와 같이 Employee Entity의 경우 EmployeeId가 기본 키로 매핑이 됩니다.public class Employee{ public int EmployeeID { get; set; } public int BranchCode { get; set; } public int EmployeeCode { get; set; } public string Name { get; set; } public DateTime DOB { get; set; } public int Age { get; set; }}여기서 EmployeeCode를 사용하여 대체키를 구성하기 위해서는 아래와 같이 사용해야 합니다.protected override void OnModelCreating(ModelBuilder modelBuilder){ modelBuilder.Entity&lt;Employee&gt;() .HasAlternateKey(e=&gt; e.EmployeeCode);}대체 키의 이름은 AK_&lt;엔티티이름&gt;_&lt;속성이름&gt;으로 생성 됩니다.여러 속성을 조합하여 대체 키를 생성하고 싶다면 아래와 같이 익명 객체(new {})를 사용해서 생성하면 됩니다.protected override void OnModelCreating(ModelBuilder modelBuilder){ modelBuilder.Entity&lt;Employee&gt;() .HasAlternateKey(e =&gt; new { e.BranchCode, e.EmployeeCode });}복합 키의 경우 AK_&lt;엔티티이름&gt;_&lt;속성이름1&gt;_&lt;속성이름2&gt;로 생성됩니다.HasIndex()HasIndex 메서드는 지정된 엔티티 속성에 매핑된 열에 데이터베이스 인덱스를 만드는데 사용합니다.기본적으로 인덱스는 외래 키와 대체 키로 생성되는데 데이터 검색 속도를 높이기 위해 특정 속성을 사용 할 수 있습니다.public class SampleContext : DbContext{ public DbSet&lt;Book&gt; Books { get; set; } protected override void OnModelCreating(ModelBuilder modelBuilder) { modelBuilder.Entity&lt;Book&gt;() .HasIndex(b =&gt; b.Isbn); }}public class Book{ public int BookId { get; set; } public string Title { get; set; } public string Isbn { get; set; }}위와 같이 생성했을 때 Isbn는 중복되는 경우가 발생 할 수 있습니다.이럴 때 .IsUnique 메서드를 사용하여 고유한 값을 가질 수 있도록 설정합니다.protected override void OnModelCreating(ModelBuilder modelBuilder){ modelBuilder.Entity&lt;Book&gt;() .HasIndex(b =&gt; b.Isbn) .IsUnique();}또한 HasName 메서드로 인덱스에 이름을 지정 할 수 있습니다.protected override void OnModelCreating(ModelBuilder modelBuilder){ modelBuilder.Entity&lt;Book&gt;() .HasIndex(b =&gt; b.Isbn) .IsUnique(); .HasName(\"MyIndexName\");}복합 인덱스둘 이상의 속성으로 인덱스를 사용 하려면 익명 객체(new{})를 사용하여 지정 합니다.public class SampleContext : DbContext{ public DbSet&lt;Patient&gt; Patients { get; set; } protected override void OnModelCreating(ModelBuilder modelBuilder) { modelBuilder.Entity&lt;Patient&gt;() .HasIndex(p =&gt; new { p.Ssn, p.DateOfBirth}); }}public class Patient{ public int PatientId { get; set; } public string Ssn { get; set; } public DateTime DateOfBirth { get; set; }}HasKey()HasKey 메서드는 엔티티의 고유 식별키(EntityKey)하고 데이터베이스의 기본키 필드와 매핑하는데 사용됩니다.public class SampleContext : DbContext{ public DbSet&lt;Order&gt; Orders { get; set; } protected override void OnModelCreating(ModelBuilder modelBuilder) { modelBuilder.Entity&lt;Order&gt;() .HasKey(o =&gt; o.OrderNumber); }}public class Order{ public int OrderNumber { get; set; } public DateTime DateCreated { get; set; } public Customer Customer { get; set; } ...)위에서 Order 엔티티를 보면 OrderId가 아닌 OrderNumber이다. 이 경우 EF Core의 네이밍 룰에 맞지 않아 정상적으로 키를 인식하지 못합니다.이럴 경우 HasKey를 사용하여 지정합니다.복합키두 개 이상의 필드를 사용하여 복합 키를 만들 경우 HasKey를 사용합니다. 복합키의 경우 Annotation으로는 지정을 하지 못하기 때문에 FluentAPI에서 HasKey를 사용하는 방법 밖에 없습니다.public class SampleContext : DbContext{ public DbSet&lt;Order&gt; Orders { get; set; } protected override void OnModelCreating(ModelBuilder modelBuilder) { modelBuilder.Entity&lt;Order&gt;() .HasKey(o =&gt; new { o.CustomerAbbreviation, o.OrderNumber }); }}public class Order{ public string CustomerAbbreviation { get; set; } public int OrderNumber { get; set; } public DateTime DateCreated { get; set; } public Customer Customer { get; set; } ...)HasMany()HasMany 메서드는 1대N 관계에서 N의 측면에서 구성할 때 사용됩니다.여기서 관계를 구성하기 위해서는 Has/With 패턴을 사용하여 유효한 관계를 구성해야 합니다.public class Company{ public int Id { get; set; } public string Name { get; set; } public ICollection&lt;Employee&gt; Employees { get; set; }}public class Employee{ public int Id { get; set; } public string Name { get; set; } public Company Company { get; set; }}Employee 엔티티에서 Company 속성의 경우 역 탐색을 위해 정의한 속성입니다.회사에는 여러 직원이 있고 직원 개개인은 한 회사에 다닌다는 관계는 아래와 같이 표현 할 수 있습니다.protected override void OnModelCreating(ModelBuilder modelBuilder){ modelBuilder.Entity&lt;Company&gt;() .HasMany(c =&gt; c.Employees) .WithOne(e =&gt; e.Company);}HasOne()HasOne 메서드는 1대N 관계에서 1 또는 1대1 관계에서 한쪽 부분을 나타내는데 사용합니다.1:1관계인지 1:N 관계인지에 따라 Has/With 패턴에 따라 HasOne과 WithOne, WithMany로 구성해야 합니다.1:1 관계아래는 HasOne과 WithOne을 사용하여 1:1 관계를 표현한 예제입니다.public class SampleContext : DbContext{ public DbSet&lt;Author&gt; Authors { get; set; } protected override void OnModelCreating(ModelBuilder modelBuilder) { modelBuilder.Entity&lt;Author&gt;() .HasOne(a =&gt; a.Biography) .WithOne(b =&gt; b.Author); }}public class Author{ public int AuthorId { get; set; } public string FirstName { get; set; } public string LastName { get; set; } public AuthorBiography Biography { get; set; }}public class AuthorBiography{ public int AuthorBiographyId { get; set; } public string Biography { get; set; } public int AuthorId { get; set; } public Author Author { get; set; }}1:N 관계아래는 HasOne과 WithMany를 사용하여 1:N 관계를 표현 한 것입니다.public class SampleContext : DbContext{ public DbSet&lt;Employee&gt; Employees { get; set; } public DbSet&lt;Company&gt; Companies { get; set; } protected override void OnModelCreating(ModelBuilder modelBuilder) { modelBuilder.Entity&lt;Employee&gt;() .HasOne(e =&gt; e.Company) .WithMany(c =&gt; c.Employees); }public class Company{ public int Id { get; set; } public string Name { get; set; } public ICollection&lt;Employee&gt; Employees { get; set; }}public class Employee{ public int Id { get; set; } public string Name { get; set; } public Company Company { get; set; }}Ignore ()Ignore 메서드는 데이터베이스에 매핑되는 속성 또는 엔티티(테이블)을 무시하는데 사용되며, EF Core에서는 두가지 방법으로 사용 가능합니다. ModelBuilder를 사용하면 테이블 자체를 매핑되지 않도록 제외 할 수 있고, EntityTypeBuilder를 사용하면 개별 속성을 제외 할 수 있습니다.엔티티 제외아래 예제는 AuditLog 엔티티는 테이블 매핑에 제외 됩니다.public class SampleContext : DbContext{ public DbSet&lt;Contact&gt; Contacts { get; set; } protected override void OnModelCreating(ModelBuilder modelBuilder) { modelBuilder.Ignore&lt;AuditLog&gt;(); }}public class Contact{ public int ContactId { get; set; } public string FirstName { get; set; } public string LastName { get; set; } public string Email { get; set; } public AuditLog AuditLog { get; set; }}public class AuditLog{ public int EntityId { get; set; } public int UserId { get; set; } public DateTime Modified { get; set; }}속성 제외아래의 예제는 Contact 엔티티에서 FullName이 매핑에서 제외 됩니다.public class SampleContext : DbContext{ public DbSet&lt;Contact&gt; Contacts { get; set; } protected override void OnModelCreating(ModelBuilder modelBuilder) { modelBuilder.Entity&lt;Contact&gt;().Ignore(c =&gt; c.FullName); }}public class Contact{ public int ContactId { get; set; } public string FirstName { get; set; } public string LastName { get; set; } public string FullName =&gt; $\"{FirstName} {LastName}\"; public string Email { get; set; } }ToTable()ToTable 메서드는 매핑되어야 하는 데이터베이스 테이블의 이름을 지정하기 위해 엔티티에 적용됩니다.아래의 예제는 Book 엔티티가 tbl_Book 테이블에 매핑되어야 함을 지정합니다.public class SampleContext : DbContext{ public DbSet&lt;Book&gt; Books { get; set; } protected override void OnModelCreating(ModelBuilder modelBuilder) { modelBuilder.Entity&lt;Book&gt;() .ToTable(\"tbl_Book`\"); }}public class Book{ public int BookId { get; set; } public string Title { get; set; } public Author Author { get; set; }}아래와 같이 스키마까지 지정이 가능합니다.protected override void OnModelCreating(ModelBuilder modelBuilder){ modelBuilder.Entity&lt;Book&gt;().ToTable(\"tbl_Book\", \"library\");}" }, { "title": "2장. 두 가지 가치에 대한 이야기", "url": "/posts/PPPCleanArchitecture_ch2/", "categories": "DDD, 클린 아키텍처 소프트웨어 구조와 설계의 원칙, 1부 소개", "tags": "DDD, CleanArchitecture", "date": "2022-04-27 22:30:00 +0900", "snippet": "소개클린아키텍처: 소프트웨어 구조와 설계의 원칙 책을 읽고 정리하며 소감을 적는 포스트입니다.두 가지 가치에 대한 이야기모든 소프트웨어 시스템은 이해관계자에게 서로 다른 두 가지 가치를 제공하는데, 행위(behavior)와 구조(structure)가 바르 그것이다.행위소프트웨어의 첫 번째 가치는 바로 행위(behavior)다. 프로그래머를 고용하는 이유는 이해관계자를 위해 기계가 수익을 창출하거나 비용을 절약하도록 만들기 위해서다.이를 위해 프로그래머는 이해관계자가 기능 명세서나 요구사항 문서를 구체화 할 수 있도록 돕는다.많은 개발자들이 기계를 구현하고 버그를 수정하는 일이 자신의 직업이라고 믿지만 틀렸다.아키텍처소프트웨어의 두 번째 가치는 소프트웨어(software)와 관련 있다.부드러운(soft)와 제품(ware)의 합성어로 소프트웨어를 만든 이유는 기계의 행위를 쉽게 변경할 수 있도록 하기 위해서다.소프트웨어가 본연의 목적을 추구하려면 변경이 쉬워야 한다.이해관계자가 기능에 대해 생각을 바꾸면 변경사항을 간단하고 쉽게 적용 할 수 있어야 한다.새로운 요구사항이 발생할 때마다 바로 이전의 변경사항을 적용하는 것보다 조금 더 힘들어지는데, 시스테므이 형태와 요구사항의 형태가 서로 맞지 않기 때문이다.아키텍처가 특정 형태를 다른 형태보다 선호 할수록, 새로운 기능을 이 구조에 맞추는게 더 힘들어 진다.따라서 아키텍처는 형태에 독립적이어야 하고, 그럴수록 더 실용적이어야 한다.더 높은 가치기능인가 아니면 아키텍처인가?소프트웨어 시스템이 동작하게 만드는게 더 중요한가? 아니면 소프트웨어 시스템을 좀 더 쉽게 변경 할 수 있도록 만드는게 중요한가?대다수가 동작하는게 더 중요하다고 생각 할 것이다.이에 반박한다면, 동작은 하지 않지만 변경이 쉬운 프로그램을 내게 준다면 동작하도록 만들 수 있고, 유지보수도 할 수 있다.하지만 수정이 불가능한 시스템은 존재하기 마련인데, 변경에 드는 비용이 변경으로 창출되는 수익을 초과하는 경우가 있다.아이젠하워 매트릭스드와이트 D. 아이젠하워(Dwight D. Eisenhower) 미국 대통령이 고안한 중요성과 긴급성에 관한 아이젠하워 매트릭스를 살펴보자 아이젠하워 매트릭스 긴급하고 중요한 긴급하지 않지만 중요한 긴급하지만 중요하지 않은 긴급하지도 중요하지도 않은소프트웽어의 첫 번째 가치인 행위는 긴급하지만 매번 높은 중요도를 가지는 것은 아니다.소프트웨어의 두 번째 가치인 아키텍처는 중요하지만 즉각적인 긴급성을 필요로 하는 경우는 절대 없다.아키텍처, 즉 중요한 일은 이 항목의 가장 높은 두 순위를 차지하는 반면, 행위는 첫번 째와 세번째에 위치한다.개발자의 흔한 실수는 3번째 항목을 1번째로 격장시켜 버리는 일이다.아키텍처를 위해 투쟁하라효율적인 소프트웨어 개발자는 뻔뻔함을 무릅쓰고 다른 이해관계자들과 동등하게 논쟁한다.소프트웨어 개발자인 당신도 이해관계자임을 명심해야 한다.소프트웨어 아키텍트는 시스템이 제공하는 특성이나 기능보다는 시스템의 구조에 더 중점을 둔다. 아키텍트는 이러한 특성과 기능을 개발하기 쉽고, 간편하게 수정할 수 있으며, 확장하기 쉬운 아키텍처를 만들어야 한다." }, { "title": "1장. 설계와 아키텍처란?", "url": "/posts/PPPCleanArchitecture_ch1/", "categories": "DDD, 클린 아키텍처 소프트웨어 구조와 설계의 원칙, 1부 소개", "tags": "DDD, CleanArchitecture", "date": "2022-04-27 22:30:00 +0900", "snippet": "소개클린아키텍처: 소프트웨어 구조와 설계의 원칙 책을 읽고 정리하며 소감을 적는 포스트입니다.설계와 아키텍처란?설계(design)와 아키텍처(architecture)는 어떤 차이가 있는가?아키텍처는 저수준의 세부사항과는 분리된 고수준의 무언가를 가리킬때 사용 된다.반면, 설계는 저수준의 구조 또는 결정사항 등을 의미 할 때가 많다.소프트웨어 설계에서 저수준의 세부사항과 고수준의 구조는 모두 소프트웨어 전체 설계의 구성요소다. 이 둘은 단절 없이 이어진 직물과 같으며, 이를 통해 대상 시스템의 구조를 정의한다.개별로는 존재할 수 없고, 실제로 이 둘을 구분 짓는 경계가 뚜렿하지 않다. 고수준에서 저수준으로 향하는 의사결정의 연속성만 있을 뿐이다.목표는? 소프트웨어 아키텍처의 목표는 필요한 시스템을 만들고 유지보수하는 데 투입되는 인력을 최소화하는 데 있다.설계 품질을 재는 척도는 고객의 요구를 만족시키는 데 드는 비용을 재는 척도와 다름없다.새로운 기능을 출시할 때 마다 비용이 증가한다면 나쁜 설계다.사례 연구어떤 회사를 예를 들어 설명하면 아래의 그래프와 같이 직원의 수가 증가하는 것을 볼 수 있다. 엔지니어링 직원 수의 증가 추이그럼 이 회사는 성공했다고 할 수 있는가?? 이제 같은 기간 회사의 생산성을 보자. 생산성은 단순히 코드 라인 수로만 측정 했다. 동일한 기간의 생산성 동일한 기간의 코드 라인당 비용위 두 그래프를 보면 개발자의 수는 증가하였지만 생산성을 현저히 떨어진다. 왜 8번째 출시한 제품의 코드는 처음 제품보다 40배나 많은 비용이 드는가?엉망진창이 되어 가는 신호 출시별 생산성시스템을 급하게 만들거나, 결과물의 총량을 순전히 프로그래머 수만으로 결정하거나, 코드와 설계의 구조를 깔끔하게 만들려는 생각을 전혀 하지 않으면, 파국으로 치닫는 이비용 곡선에 올라타게 된다.경영자의 시각 출시별 월 인건비첫 번째 출시와 여덟 번째 출시의 월 인건비가 굉장히 증가한 것을 볼 수 있다.무엇이 잘 못되었을까? 생산성이 믿기 힘들 정도로 낮아진 원인은 무엇인가?무엇이 잘못되었나?개발자들은 “코드는 나중에 정리하면 돼. 당장은 시장에 출시하는 게 먼저야!”라는 흔해 빠진 거짓말에 속는다.개발자는 자신이 생상성을 유지할 수 있다고 자신의 능력을 과신한다. 하지만 엉망진창인 코드가 서서히 쌓이면 개발자 생산성은 차츰 낮아지고, 코드는 결국 엉망이 된다.개발자가 속는 더 잘못된 거짓말은 “지저분한 코드를 작성하면 단기간에는 빠르게 갈 수 있고, 장기적으로 볼 때만 생산성이 낮아진다.”는 견해다.이 거짓말을 받아 드린 개발자는 나중에 기회가 되면 엉망인 코드를 정리 할 수 있다고 자신의 능력을 과신하게 된다. 이터레이션별 걸린 시간과 TDD 적용 여부위 그래프는 제이슨 고먼(Json Gorman)이 수행한 실헝으로 TDD(테스트 주도 개발)를 했을 때 학습 곡선이 뚜렿하게 나타나는 것을 볼 수 있다.TDD를 적용한 날이 적용하지 않은 날보다 대략 10% 빠르게 작업이 완성되었고, 심지어 TDD를 적용한 날 중 가장 느렸던 날이 TDD를 적용하지 않고 가장 빨리 작업한 날보다 더 빨랐다.위 결과가 나올 수 있는 이유는 소프트웨어 개발의 단순한 진리를 알기 때문이다.빨리 가는 유일한 방법은 제대로 가는 것이다.자신을 과신한다면 재설계를 하더라도 원래의 프로젝트와 똑같이 엉망으로 내몰린다.결론소프트웨어 아키텍처를 심각하게 고려할 수 있으려면 좋은 소프트웨어 아키텍처가 무엇인지 이해해야 한다.비용은 최소화하고 생산성은 최대화 할 수 있는 설계와 아키텍처를 가진 시스템을 만들려면, 이러한 결과로 이끌어 줄 시스템 아키텍처가 지닌 속성을 알고 있어야 한다." }, { "title": "First Class Collection(일급 컬렉션)", "url": "/posts/FirstClassCollection/", "categories": "DDD", "tags": "DDD, 일급 컬렉션", "date": "2022-04-26 09:00:00 +0900", "snippet": "참조 객체지향 생활 체조 9가지 First Class Collection소개최근 DDD를 공부하면 일급 컬렉션이라는 단어가 나와 찾아보게 되었습니다.일급 컬렉션은 마틴 파울러가 쓴 소트웍스 앤솔러지 : 소프트웨어 기술과 혁신에 관한 에세이의 객체지향 생활체조 파트에서 언급되는 8번째 규칙입니다.일급 컬렉션이란?Collection을 Wrapping하면서, 그 외 다른 변수가 없는 클래스의 상태를 일급 컬렉션이라고 합니다.예를 들어 아래의 좌측 코드를 우측 코드로 변경 된 것을 일급 컬렉션이라고 합니다.그냥 봐서는 Emails라는 Class는 왜 만들어서 코드의 양만 늘어나게 했는지 의아해 할 수도 있습니다.일급 켈렉션의 이점은 아래 같습니다.1. 비즈니스에 종속적인 자료구조 상위 클래스(User)에서 컬렉션을 선언하게 되면 해당 컬렉션이 필요한 모든 장소에서 검증 로직이 들어가게 됩니다. 비즈니스에 종속적이라는 말은 생성 된 클래스의 컬렉션을 관리하는 클래스(일급 컬렉션)을 따로 만들어서 [+클래스 내부적으로 비즈니스 검증 로직을 관리 할 수 있다는 말입니다.+]As-Is User는 Email에 대해 아래와 같은 비즈니스를 가집니다. Email은 최대 10개 까지 가질 수 있다. Email은 중복값이 없어야 한다. 위와 같은 비즈니스가 있을 때 아래와 같이 작성 할 수 있습니다.public class User{ private List&lt;Email&gt; _emails = new List&lt;Email&gt;(); public bool AddEmail(Email email) { if (_emails.Count &gt;= 10) return false; if (_emails.Any(x =&gt; x.Equals(email))) return false; _emails.Add(email); return true; }}To-Be 일급 컬렉션을 사용하면 이메일 관련 요구사항은 Emails 에서만 관리하게 되면서 응집도(Cohesion)를 높히고 User 와 Email 에 대한 커플링(Coupling)을 낮출 수 있습니다.public class User{ private Emails _emails { get; set; } public bool AddEmail(Email email) { return _emails.AddEmail(email); }}public class Emails{ private List&lt;Email&gt; _emails = new List&lt;Email&gt;(); public bool AddEmail(Email email) { if (_emails.Count &gt;= 10) return false; if (_emails.Any(x =&gt; x.Equals(email))) return false; _emails.Add(email); return true; }}2. Collection의 불변성을 보장 일급 컬렉션은 컬렉션의 불변을 보장하는데, 단순히 readonly을 사용하는 것이 아니라 캡슐화를 통해 이뤄집니다. readonly은 재할당만 금지할 뿐 Add, Remove가 가능합니다. 하지만 일급 컬렉션에서 getter만 선언하고 setter를 생성하지 않으면 불변 컬렉션이 됩니다.public class Emails{ private readonly List&lt;Email&gt; _emails; public Emails(List&lt;Email&gt; emails) { _emails = emails; } public Email this[int index] { get =&gt; new Email(_emails[index].Local, _emails[index].Domain); }}3. 상태와 행위를 한 곳에서 관리 일급 컬렉션을 사용하면 값과 로직이 함께 존재 하기 때문에 응집도가 높아집니다. Emails 컬렉션을 사용하게 되면 똑같은 기능이 중복 되지 않고 한 곳에서 로직 변경이 가능합니다.As-Is 만약 Email 컬렉션을 사용하는 객체 Manager가 늘었다고 가정 합니다. User객체와 Manager 객체의 Email 관리 비즈니스가 중복 되게 됩니다.public class User{ private List&lt;Email&gt; _emails { get; set; } public bool AddEmail(Email email) { if (_emails.Count &gt;= 10) return false; if (_emails.Any(x =&gt; x.Equals(email))) return false; _emails.Add(email); return true; }}public class Manager{ private List&lt;Email&gt; _emails { get; set; } public bool AddEmail(Email email) { if (_emails.Count &gt;= 10) return false; if (_emails.Any(x =&gt; x.Equals(email))) return false; _emails.Add(email); return true; }}To-Be 일급 컬렉션을 사용하게 되면 응집도가 높아지기 때문에 비즈니스 로직이 변경 되어도 Emails Class만 수정하면 됩니다.public class User{ private Emails _emails { get; set; } public bool AddEmail(Email email) { return _emails.AddEmail(email); }}public class Manager{ private Emails _emails { get; set; } public bool AddEmail(Email email) { return _emails.AddEmail(email); }}public class Emails{ private readonly List&lt;Email&gt; _emails; public Emails() { _emails = new List&lt;Email&gt;(); } public bool AddEmail(Email email) { if (_emails.Count &gt;= 10) return false; if (_emails.Any(x =&gt; x.Equals(email))) return false; _emails.Add(email); return true; }}4. 이름이 있는 컬렉션 일급 컬렉션을 사용하게 되면 변수에만 도출되던 비즈니스가 컬렉션 자체에서 도출이 가능합니다. 예를 들어 Naver Emails에 대한 요구사항을 검색하거나 선언 할 경우 아래와 같은 문제점을 겪을 수 있습니다. 개발자에 따라 변수명이 다르다. 중요한 값이지만 명확하게 표현해둔 단어/변수명이 없다. 일급 컬렉션을 사용하면 Naver Email에 대한 요구사항이 바뀌었을 때 NaverEmails을 참조하는 코드를 모두 찾을 수 있다.As-Ispublic class User{ private List&lt;Email&gt; _mireroEmails { get; set; } private List&lt;Email&gt; _naverEmails { get; set; }}To-Bepublic class User{ private MireroEmails _mireroEmails { get; set; } private NaverEmails _naverEmails { get; set; }}예제 코드 FirstClassCollection.zip" }, { "title": "12장. 아키텍처 스타일 결정하기", "url": "/posts/MakeLearnCleanArchitecture_ch12/", "categories": "DDD, 만들면서 배우는 클린 아키텍처", "tags": "DDD, CleanArchitecture", "date": "2022-04-24 15:00:00 +0900", "snippet": "소개만들면서 배우는 클린 아키텍처 책을 읽고 정리하며 소감을 적는 포스트입니다.아키텍처 스타일 결정하기 언제 실제로 육각형 아키텍처 스타일을 사용해야 할까? 언제 육각형 아키텍처 스타일 대신 전통적인 계층형 아키텍처 스타일을 고수 해야 할까?이 두가지가 가장 궁극적인 질문 이다.도메인이 왕이다. 외부의 영향을 받지 않고 도메인 코드를 자유롭게 발전시킬 수 있다는 것은 육각형 아키텍처 스타일이 내세우는 가장 중요한 가치다!육각형 스타일과 같은 도메인 중심의 아키텍처 스타일은 DDD의 조력자라고까지 말할 수 있다. 도메인을 중심에 두는 아키텍처 없이는, 또 도메인 코드를 향한 의존성을 역전시키지 않고서는, DDD를 제대로 할 가능성이 없다. 즉, 설계가 항상 다른 요소들에 의해 주도되고 말 것이다.경험이 여왕이다.인간은 습관의 동물이다. 이전에 계층형 아키텍처 스타일을 이용했다면 새로운 애플리케이션도 계층형 아키텍처를 사용할 것이다.따라서 아키텍처 스타일에 대해서 괜찮은 결정을 내리는 유일한 방법은 다른 아키텍처 스타일을 경험해 보는 것이다. 육각형 아키텍처에 확신이 없다면 현재 개발 중인 애플리케이션에 작은 모듈에 먼저 시도해보라. 개념에 익숙해지고 스타일에 익숙해져야 한다." }, { "title": "11장. 의식적으로 지름길 사용하기", "url": "/posts/MakeLearnCleanArchitecture_ch11/", "categories": "DDD, 만들면서 배우는 클린 아키텍처", "tags": "DDD, CleanArchitecture", "date": "2022-04-23 13:00:00 +0900", "snippet": "소개만들면서 배우는 클린 아키텍처 책을 읽고 정리하며 소감을 적는 포스트입니다.의식적으로 지름길 사용하기절대 갚을 길 없는 기술 부채를 쌓아가면서 항상 지름길의 유혹을 느낀다는 사실을 저주한다.지름길을 방지하기 위해서는 먼저 지름길 자체를 파악해야 한다.왜 지름길은 깨진 창문 같을까?1969년 심리학자 필립 짐바르도(Philip Zimbardo)는 나중에 깨진 창문 이론이라고 알려진 실험을 했다. 어떤 것이 멈춘 것처럼 보이고, 망가져 보이고, [부정적인 형용사를 넣어보자], 혹은 관리되지 않는다고 여겨지면 인간의 뇌는 이를 더 멈추고, 망가뜨리고, [부정적인 형용사를 넣어보자] 해도 된다고 생각하게 된다.이 이론은 삶의 많은 부분에 적용할 수 있다. 기물 파손이 흔한 동네에서는 방치된 차를 도둑질하거나 망가뜨리는 일이 더 쉽게 일어난다. 좋은 동네라도 차의 창문이 깨져있다면 차를 망가뜨리는 일이 쉽게 일어난다. 침실이 정돈돼 있지 않으면 옷을 옷장에 넣는 대신 바닥에 아무렇게나 던져 놓기 싶다. 괴롭힘이 흔한 집단에서는 괴롭힘이 더 쉽게 일어난다.코드 작업에 적용될 때의 의미는 다음과 같다. 품질이 떨어진 코드에서 작업할 때 더 낮은 품질의 코드를 추가하기가 쉽다. 코딩 규칙을 많이 어긴 코드에서 작업할 때 또 다른 규칙을 어기기도 쉽다. 지금길을 많이 사용한 코드에서 작업할 때 또 다른 지름길을 추가하기도 쉽다.깨끗한 상태로 시작할 책임소프트웨어 프로젝트는 대개 큰 비용이 들고 장기적인 노력을 필요로 하기 때문에 깨진 창문을 막는 것이 소프트웨어 개발자들의 아주 막대한 책임이다.그리 중요하지 않거나, 프로토타이핑 작업 중이거나, 경제적인 이유로 지름길이 더 실용적일 때도 있다. 하지만 이럴 때는 세심하게 잘 기록해야 한다.마이클 나이가드(Michael Nygard)가 제안한 아키텍처 결정 기록(Architecture Decision Recordes, ADRs)의 형태도 괜찮다.유스케이스 간 모델 공유하기 유스케이스 간에 입출력 모델을 공유하게 되면 유스케이스들 사이에 결합이 생긴다.공유로 인한 영향 SendMoneyUseCase와 RevokeActivityUseCase가 결합된다는 것이다. 공유하고 있는 SendMoneyCommand 클래스가 변경되면 두 유스케이스 모두 영향을 받는다.단일 책임 원칙에서 이야기하는 변경할 이유를 공유하는 것이다.유스케이스 간 입출력 모델을 공유하는 것은 유스케이스들이 기능적으로 묶여 있을 때 유효하다. 특정 세부사항을 변경 할 경우 실제로 두 유스케이스 모두에 영향을 주고 싶은 것이다.도메인 엔티티를 입출력 모델로 사용하기 도메인 엔티티를 유스케이스의 입출력 모델로 사용하면 도메인 엔티티가 유스케이스에 결합된다.Account 엔티티에 존재하지 않은 정보를 유스케이스가 필요하다면 엔티티에 새로운 필드를 추가하고 싶은 유혹이 생긴다.간단한 생성이나 업데이트 유스케이스에서는 유스케이스 인터페이스에 도메인 엔티티가 있는 것은 괜찮을지도 모른다. 데이터베이스에 저장해야 하는 바로 그 상태 정보가 엔티티에 있기 때문이다.더 복잡한 도메인 로직을 구현해야 한다면(도메인 로직의 일부를 풍부한 도메인 엔티티로 위임할 수도 있으니), 유스케이스 인터페이스에 대한 전용 입출력 모델을 만들어야 한다.이 지름길이 위험한 이유는 시간이 지나면서 복잡한 도메인 로직 괴물이 되어 가기 때문이다. 그러므로 처음에는 도메인 엔티티를 입력 모델로 사용했더라도 도메인 모델로부터 독립적인 전용 입력 모델로 교체해야 하는 시점을 잘 파악해야 한다.인커밍 포트 건너뛰기아웃고잉 포트에 비해 인커밍 포트는 의존성 역전에 필수적인 요소는 아니다. 인커밍 포트가 없으면 도메인 로직의 진입점이 불분명해진다.전용 인커밍 포트가 있으면 진입점을 한눈에 식별이 가능하다. 또한 아키텍처를 쉽게 강제할 수 있따.애플리케이션의 규모가 작거나 인커밍 어댑터가 하나밖에 없어서 모든 제어 흐름을 인커밍 포트의 도움 없이 단숨에 파악할 수 있다면 인커밍 포트가 없는 것이 편하다.애플리케이션 서비스 건너뛰기 애플리케이션 서비스가 없으면 도메인 로직을 둘 곳이 없다.간단한 CRUD 유스케이스에서는 보통 애플리케이션 서비스가 도메인 로직 없이 생성, 업데이터, 삭제 요청을 그대로 영속성 어댑터에 전달하기 때문에 그대로 전달하는 대신 영속성 어댑터가 직접 유스케이스를 구현하게 할 수 있다.하지만 이 방법은 인커밍 어댑터와 아웃고잉 어댑터 사이에 모델을 공유해야 한다. 나아가 애플리케이션 코어에 유스케이스라고 할만할 것이 없어진다. 만약 시간이 지남에 따라 CRUD 유스케이스 점점 복잡해지면 도메인 로직을 그대로 아웃고잉 어댑터에 추가하고 싶은 생각이 들 것이다." }, { "title": "10장. 아키텍처 경계 강제하기", "url": "/posts/MakeLearnCleanArchitecture_ch10/", "categories": "DDD, 만들면서 배우는 클린 아키텍처", "tags": "DDD, CleanArchitecture", "date": "2022-04-23 11:50:00 +0900", "snippet": "소개만들면서 배우는 클린 아키텍처 책을 읽고 정리하며 소감을 적는 포스트입니다.아키텍처 경계 강제하기일정 규모 이상의 모든 프로젝트에서는 시간이 지나면서 아키텍처가 서서히 무너지게 된다.계층 간의 경계가 약화되고, 코드는 점점 더 테스트하기 어려워지고, 새로운 기능을 구현하는 데 점점 더 많은 시간이 든다.경계와 의존성 아키텍처 경계를 강제한다는 것은 의존성이 올바른 방향을 향하도록 강제하는 것을 의미한다. 아키텍처에서 허용되지 않은 의존성을 점선 화살표로 표시했다.위 그림은 육각형 아키텍처의 요소들이 클린 아키텍처 방식과 유사항 4개의 계층에 어떻게 흩어져 있는지 보여준다.가장 안쪽의 계층에는 도메인 엔티티가 있고 애플리케이션 계층은 애플리케이션 서비스 안에 유스케이스를 구현하기 위해 도메인 엔티티에 접근한다.어댑터는 인커밍 포트를 통해 서비스에 접근하고, 반대로 서비스는 아웃고잉 포트를 통해 어댑터에 접근한다. 마지막으로 설정 계층은 어댑터와 서비스 객체를 생성할 팩터리를 포함하고 있고, 의존성 주입 매커니즘을 제공한다.접근 제한자경계를 강제하기 위해 자바에서 제공하는 가장 기본적인 도구인 접근 제한자(visibility modifier)부터 시작한다.대부분의 사람들은 public, protected, private 제한자만 알고 있고, 거의 대부분이 package-private(혹은, default) 제한자를 모른다.그럼 왜 package-private 제한자가 중요할까?? 바로 클래스들을 응집적인 모듈로 만들어 주기 때문이다.이런 모듈 내에 있는 클래스들은 서로 접근 가능하지만, 패키지 바깥에서는 접근 할 수 없다. 그럼 모듈의 진입점으로 활용될 클래스들만 골라서 public으로 만들면 된다. 이렇게 하면 의존성이 잘못된 방향으로 가리켜서 의존성 규칙을 위반할 위험이 줄어든다.buckpal└─────── account ├──── adapter │ ├──── in │ │ └──── web │ │ └──── O AccountController │ │ │ └──── out │ └──── persistence │ ├──── O AccountPersistenceAdapter │ └──── O SpringDataAccountRepository │ ├──── domain │ ├──── + Account │ └──── + Activity │ └──── application ├──── O SendMoneyService └──── port ├──── in │ └──── + SendMoneyUseCase └──── out ├──── + LoadAccountPort └──── + UpdateAccountStatePort 접근 제한자를 추가한 패키지 구조persistence 패키지에 있는 클래스들은 외부에서 접근 할 필요가 없기 때문에 package-private(위에서 O)으로 만들 수 있다.영속성 어댑터는 자신이 구현하는 출력 포트를 통해 접근된다.의존성 주입 메커니즘은 일반적으로 리플렉션을 이용해 인스턴스를 만들기 때문에 package-private이라도 여전히 인스턴스로 만들 수 있다.package-private 제한자는 몇 개 정도의 클래스로만 이뤄진 작은 모듈에서 가장 효과적이다. 특정 개수를 넘어가기 시작하면 하나의 패키지에 너무 많은 클래스를 포함하는 것이 혼란스러워지게 된다.컴파일 후 체크클래스에 public 제한자를 쓰면 아키텍처 상의 의존성 방향이 잘못되더라도 컴파일러는 다른 클래스들이 이 클래스를 사용하도록 허용한다.한 가지 방법은 컴파일 후 체크(post-compile check)를 도입하는 것이다. 다시 말해, 코드가 컴파일된 후에 런타임에 체크한다는 뜻이다.이러한 체크를 도와주는 자바용 도구로 ArchUnit이라는 도구가 있다. ArchUnit은 의존성 방향이 기대한 대로 잘 설정돼 있는지 체크할 수 있는 API를 제공한다. 의존성 규칙 위반을 발견하면 예외를 던진다.아래의 예제는 도메인 계층에서 바깥쪽의 애플리케이션 계층으로 향하는 의존성이 없다는 것을 체크할 수 있다.class DependencyRuleTests {\t@Test\tvoid testPackageDependencies() {\t\tnoClasses()\t\t\t\t.that()\t\t\t\t.resideInAPackage(\"io.reflectoring.reviewapp.domain..\")\t\t\t\t.should()\t\t\t\t.dependOnClassesThat()\t\t\t\t.resideInAnyPackage(\"io.reflectoring.reviewapp.application..\")\t\t\t\t.check(new ClassFileImporter()\t\t\t\t\t\t.importPackages(\"io.reflectoring.reviewapp..\"));\t}}ArchUnit API를 이용하면 적은 작업만으로도 육각형 아키텍처 내에서 관련된 모든 패키지를 명시할 수 있는 일종의 도메인 특화 언어(DSL)을 만들수 있고, 패키지 사이의 의존성 방향이 올바른지 자동으로 체크할 수 있다.class DependencyRuleTests {\t@Test\tvoid validateRegistrationContextArchitecture() {\t\tHexagonalArchitecture.boundedContext(\"io.reflectoring.buckpal.account\")\t\t\t\t.withDomainLayer(\"domain\")\t\t\t\t.withAdaptersLayer(\"adapter\")\t\t\t\t.incoming(\"in.web\")\t\t\t\t.outgoing(\"out.persistence\")\t\t\t\t.and()\t\t\t\t.withApplicationLayer(\"application\")\t\t\t\t.services(\"service\")\t\t\t\t.incomingPorts(\"port.in\")\t\t\t\t.outgoingPorts(\"port.out\")\t\t\t\t.and()\t\t\t\t.withConfiguration(\"configuration\")\t\t\t\t.check(new ClassFileImporter()\t\t\t\t\t\t.importPackages(\"io.reflectoring.buckpal..\"));\t}}위 예제에서 먼저 바인드디 컨텍스트의 부모 패키지를 지정한다(단일 바운디드 컨텍스트라면 애플리케이션 전체에 해당한다). 그런 다음 도메인, 어댑터, 애플리케이션, 설정 계층에 해당하는 하위 패키지들을 지정한다.마지막 호출하는 check()는 몇가지 체크를 실행하고 패키지 의존성의 의존성 규칙을 따라 유효하게 설정됐는지 검증한다.컴파일 후 체크는 리팩터링에 취약하기 때문에 항상 코드와 같이 유지보수 해야 한다.빌드 아티팩트빌드 아티팩트는 (아마도 자동화된) 빌드 프로세스의 결과물이다. Java에서 인기있는 빌드도구는 메이븐(Maven)과 그레이들(Gradle)이다.빌드 도구의 주요한 기능 중 하나는 의존성 해결(dependency resolution)이다. 어떤 코드베이스를 빌드 아티팩트로 변환하기 위해 빌드 도구가 가장 먼저 할 일은 코드베이스가 의존하고 있는 모든 아티팩트가 사용 가능한지 확인하는 방법이다.이를 활용하여 모듈과 아키텍처의 계층 간의 의존성을 강제할 수 있다.(따라서 경계를 강제하는 효과가 생긴다.)각 모듈 혹은 계층에 대해 전용 코드베이스와 빌드 아티팩트로 분리된 비륻 모듈(JAR 파일)을 만들 수 있다. 각 모듈의 빌드 스크립트에서는 아키텍처에서 허용하는 의존성만 지정한다. 클래스들이 클래스패스에 존재하지 않아 컴퍼일 에러가 발생하기 때문에 개발자들은 더이상 실수로 잘못된 의존성을 만들 수 없다. 잘못된 의존성을 막기 위해 아키텍처를 여러 개의 빌드 아티팩트로 만드는 여러가지 방법위 그림의 핵심은 모듈을 더 세불화할수록, 모듈 간 의존성을 더 잘 제어할 수 있게 된다는 것이다. 하지만 더 작게 분리할수록 모듈간에 매핑을 더 많이 수행해야 한다.이 밖에도 빌드 모듈로 아키텍처 경계를 구분하는 것은 패키지로 구분하는 방식과 비교했을 때 몇 가지 장점이 있다.첫 번째로, 빌드 도구가 순환 의존성(circular dependency)를 극도로 싫어한다는 것이다. 순환 의존성은 하나의 모듈에서 일어나는 변경이 잠재적으로 순환 고리에 포함된 다른 모든 모듈을 변경하게 만들며, 단일 책임 원칙을 위배하기 때문에 좋지 않다. 그러므로 빌드 도구를 이용하면 빌드 모듈 간 순환 의존성이 없음을 확신 할 수 있다.두 번째로, 빌드 모듈 방식에서는 다른 모듈을 고려하지 않고 특정 모듈의 코드를 격리한채로 변경 할 수 있다. 특정 어댑터에서 컴파일 에러가 생기는 애플리케이션 계층을 리팩터링하고 있다고 상상해본다.만약 애플리케이션 계층이 같은 빌드 모듈에 있다면 어느 한쪽 계층의 컴파일 에러 때문에 빌드가 실패할 것이다. 그러므로 여러 개의 빌드 모듈은 각 모듈을 격리한 채로 변경할 수 있게 해준다.심지어 각 모듈은 자체 코드 리포지토리에 넣어 서로 다른 팀이 서로 다른 모듈을 유지보수하게 할 수도 있다.마지막으로, 모듈 간 의존성이 빌드 스크립트에 분명하게 선언돼 있기 때문에 새로 의존성을 추가하는 일은 우연이 아닌 의식적인 행동이 된다. 어떤 개발자가 당장은 접근 할 수 없는 특정 클래스에 접근해야 ㅎ라 일이 생기면 빌드 스크립트에 이 의존성을 추가하기에 앞서 정말로 이 의존성이 ㅍ리요한 것인지 생각할 여지가 생긴다.하지만 이런 장점에는 빌드 스크립트를 유지보수하는 비용을 수반하기 때문에 아키텍처를 여러 개의 빌드 모듈로 나누기 전에 아키텍처가 어느 정도 안정된 상태여야 한다." }, { "title": "9장. 애플리케이션 조립하기", "url": "/posts/MakeLearnCleanArchitecture_ch9/", "categories": "DDD, 만들면서 배우는 클린 아키텍처", "tags": "DDD, CleanArchitecture", "date": "2022-04-23 10:50:00 +0900", "snippet": "소개만들면서 배우는 클린 아키텍처 책을 읽고 정리하며 소감을 적는 포스트입니다.애플리케이션 조립하기유스케이스, 웹 어댑터, 영속성 어댑터를 구현해봤으니, 이제 이것들을 동작하는 애플리케이션으로 조립하는 차례이다.왜 조립까지 신경 써야 할까?필요할때 마다 인스턴스화 시켜서 사용하지 않는 것은 의존성이 올바른 방향을 가리키게 하기 위해서다.애플리케이션의 도메인 코드 방향으로 향해야 도메인 코드가 바깥 계층의 변경으로부터 안전하다.유스케이스가 영속성 어댑처를 호출해야 하고 스스로 인스턴스화한다면 코드 의존성이 잘못된 방향으로 만들어진 것이다.그럼 객체 인스턴스를 생성할 책임은 누구에게 있을까?? 중립적인 설정 컴포넌트는 인스턴스 생성을 위해 모든 클래스에 접근할 수 있다.위 그림과 같이 아키텍처에 대해 중립적이고 인스턴스 생성을 위해 모든 클래스에 대한 의존성을 가지는 설정 컴포넌트(configuration component)가 있어야 하는 것이다.설정 컴포넌트는 아래와 같은 역할을 수행해야 한다. 웹 어댑터 인스턴스 생성 HTTP 요청이 실제로 웹 어댑터로 전달되도록 보장 유스케이스 인스턴스 생성 웹 어댑터에 유스케이스 인스턴스 제공 영속성 어댑터 인스턴스 생성 유스케이스에 영속성 어댑터 인스턴스 제공 영속성 어댑터가 실제로 데이터베이스에 접근 할 수 있도록 보장하지만 위와 같이 책임(\"변경할 이유\")이 굉장히 많다. 이것은 단일 책임 원칙을 위반하는 게 아닐까?? 위반하는 게 맞다.평범한 코드로 조립하기의존성 주입 프레임워크의 도움 없이 애플리케이션을 만들고 있다면 아래와 같이 평범한 코드로 컴포넌트를 만들 수 있다.package com.book.cleanarchitecture.buckpal;import com.book.cleanarchitecture.buckpal.account.adapter.in.web.SendMoneyController;import com.book.cleanarchitecture.buckpal.account.adapter.out.persistence.AccountPersistenceAdapter;import com.book.cleanarchitecture.buckpal.account.application.port.in.SendMoneyUseCase;import com.book.cleanarchitecture.buckpal.account.application.service.SendMoneyService;public class Application { public static void main(String[] args) { AccountRepository accountRepository = new AccountRepository(); ActivityRepository activityRepository = new ActivityRepository(); AccountPersistenceAdapter accountPersistenceAdapter = new AccountPersistenceAdapter(accountRepository, activityRepository); SendMoneyUseCase sendMoneyUseCase = new SendMoneyService( accountPersistenceAdapter, accountPersistenceAdapter ); SendMoneyController sendMoneyController = new SendMoneyController(sendMoneyUseCase); startProcessingWebRequests(sendMoneyController); }}위와 같은 방식으로 애플리케이션을 조립하게 되면 아래와 같이 몇가지 단점이 존재한다. 위 코드는 웹 컴트롤러, 유스케이스, 영속성 어댑터가 단 하나씩만 있는 애플리케이션을 예로 들고 있지만 앤터프라이즈 애플리케이션은 엄청나게 많은 코드가 들어가야한다. 각 클래스가 속한 패키지 외부에서 인스턴스를 생성하기 때문에 이 클래스들은 전부 public이어야 한다.스프링의 클래스패스 스캐닝으로 조립하기스프링의 클래스패스 스캐닝으로 클래스패스에서 접근 가능한 모든 클래스를 확인해서 @Component 애너테이션이 붙은 클래스를 찾는다.@RequiredArgsConstructor@PersistenceAdapterclass AccountPersistenceAdapter implements\t\tLoadAccountPort,\t\tUpdateAccountStatePort {\tprivate final SpringDataAccountRepository accountRepository;\tprivate final ActivityRepository activityRepository;\tprivate final AccountMapper accountMapper;\t@Override\tpublic Account loadAccount(\t\t\t\t\tAccountId accountId,\t\t\t\t\tLocalDateTime baselineDate) { //...\t}\t@Override\tpublic void updateActivities(Account account) {\t\t//...\t}}클래스패스 스캐닝 방식을 이용하면 아주 편리하게 애플리케이션을 조립할 수 있다. 적절한 곳에 @Component 애너테이션을 붙이고 생성자만 잘 만들어 두면 된다.이 어노테이션 덕분에 코드를 읽는 사람들은 아키텍처를 더 쉽게 파악할 수 있지만 단점도 있다.첫 번째로, 클래스에 프레임워크에 특화된 애너테이션을 붙여야 한다는 점에서 침투적이다.라이브러리나 프레임워크를 만드는 입장에서는 사용하지 말아야 하는 방법이다." }, { "title": "한번 듣고 평생 써먹는 코드 리뷰 노하우", "url": "/posts/CodeReview/", "categories": "Code Review", "tags": "CodeReview", "date": "2022-04-21 22:00:00 +0900", "snippet": "소개이번 포스트는 한번 듣고 평생 써먹는 코드 리뷰 노하우를 시청하고 정리하는 포스트입니다.목차 왜 코드 리뷰를 해야 하나? 우리가 살고 있는 시대 개발생산성 / SW 공학의 특성 / 장인정신 코드 리뷰의 정의 / 목적 코드 리뷰의 절차 왜 코드 리뷰가 어려운가 코드 리뷰의 기법들 효율적인 PR 방법 효율적인 리뷰 방법 피드백 방법 교착상태 시 추가적인 사례 코드 리뷰를 하는 아주 재밌는 방법 왜 코드 리뷰를 해야하나?우리가 살고 있는 시대 \"Software is eating the world\" 소프트웨어에 의해 운영되는 제품과 서비스들의 영역이 늘어나고 있음 ICT의 융합으로 이뤄지는 차세대 산업 혁명 Big Data, AI, Robot 공학, IoT, 무인 운송 수단, 3D Printing, 나노 기술과 같은 7대 분야에서의 새로운 기술 혁신 Build 2021 Keynote에서 Global GDP에서의 IT 기술의 비율이 2020년 5%에서 2030: 10%까지 갈것으로 예측했습니다. Non-Tech영역에서 개발자 수 증가속도가 Tech 영역에서보다 가파르게 증가한다.VUCA란? Volatiliy(변동성) : 변화의 속도가 빠르고 다양하게 전개 될 것 Uncertainty(불확실성) : 미래 상황에 변수가 많아 예측하기 어려울 것 Complexity(복잡성) : 인과관계가 단순하지 않고 다양한 요인이 작용될 것 Ambiguity(모호성) : 뚜렷한 현상이 없어 판별하기 어려울 것\"불확실하고, 복잡하고, 모호하며 변화가 많은 세상이 될것!\" 비즈니스 성공을 위한 개발의 역할 시장 : VUCA 비즈니스 : 더 빨리 혁신해야 함 개발 DRFR 개발 조직의 성능(생산성)이 중요해짐개발 생산성아래의 그림들은 클린아키텍처에서 말하는 표입니다.X축 : 출시 회차, Y축 : 개발자 수출시를 하면 할 수록 필요한 개발자의 수가 늘어 난다.X축 : 출시 회차, Y축 : 생산성출시 회차가 늘어 날 수록 생산성이 줄어듭니다. 설계 체력 가설X축 : 시간, Y축 : 추가 된 기능 횟수시간이 가면 갈 수록 설계 수익선을 지나면 기능의 수가 줄어듭니다.설계가 좋지 못하면 새로운 기능을 추가하기 위해 시간을 쓰지 못하고 기존의 문제를 해결하기 위해 시간을 많이 소비하게 된다.SW 공학의 특성왜 SW 공학은 시간이 갈 수록 생산성이 줄어드나?건축 공학 공학 = 설계(Design) + 빌드(Build) 설계 : 예측하기 어렵고, 급여가 비싸고 창의적인 사람들을 필요 빌드 : 좀 더 예측하기 쉬움 설계와 빌드가 분리됨 빌드 비용이 비쌈(건축 90%) 유지보수 비용이 상대적으로 낮음 공학 활동의 최종 목적 빌드 할 수 있는 어떤 종류의 재생산 가능한(Reproducible) 문서 SW 공학 설계 = 완전한 소스 코드 SW 빌드 : 컴파일 좋은 설계 ~= 클린코드 SW 엔지니어 : 설계를 잘하는 사람 -&gt; 코드를 잘 작성하는 사람클린 코드의 중요성 SW의 진정한 비용 ~= 유지보수(전체의 80% 이상) 한번 작성한 코드는 10번 이상 읽음. 작성보다 이해에 10배의 노력 소요 90% 이상의 시간을 어떤 코드를 이해하는데 사용함SW 개발의 단순한 진리 “The only way to go fast, is to go well” - Rovert C. Martin 시간이 흘러도 생산성 저하, 비용 증가를 막을 수 있는 유일한 방법 SW 품질에 신중해야 SW의 비용과 품질의 관계는 비정상적, 비직관적 향후 변경 비용을 낮춤으로서 익숙한 트레이드오프를 역전 시킴 “높은 품질의 제품은 비싸다” 개발자의 전문가 정신? 비즈니스 혁신? : 이런 걸로는 경영진을 설득 할 수 없다. SW 장인정신 장인정신 지식과 경험의 공유만이 전문성을 갖춘 개발자 육성 후배들에게 지식과 경험을 공유(도제관계) 코드 리뷰 개발자가 지금부터 당장 행할 수 있는 공유 활동 Code SNS 댓글 놀이 배움을 주고 받으며 지속가능한 SW 개발자가 될 수 있는 실천법 코드리뷰의 정의 \"코드 리뷰는 한명 또는 여러사람이 스스로 소스코드 일부를 보고 읽는 방식으로 프로그램을 확인하는 소프트웨어 경진 활동으로서 구연 후에 하거나 또는 구현을 잠깐 중단 시킨 후 한다.\" Peer Reviews, Pull Requests, Merge Request라고도 한다. 목적 주목적 : 품질 문제 검수(버그, 장애) 더 나은 코드 품질 : 아키텍처 속성 개선을 위한 코드 개선(향후 변경 비용 개선) 학습 및 지식 전달 : 코드, 해결책 등과 관련된 지식 공유에 기여 공유(주고 받는 학습)를 통한 역량 증대 및 성장 참여한 모든 사람들의 배움의 기회 대개의 경우 리뷰어들도 리뷰 과정에서 지식을 얻게 됨(하드스킬, 소프트스킬) 동기부여 : 다른사람이 잘하는 사람이 있으면 그 사람처럼 잘 하려고 한다. 하드스킬 : 개발의 구체적인 영역들(실제 코드 기술) 소프트스킬 : 시니어가 주니어에게 쉽게 설명하는 방법(친절, 공감능력 등..) 상호 책임감 증대 집단 코드 오너십 및 결속 증대 내가 하고 있는 일에 관심을 가져주는 것 팀에서 일어나는 일 공유. 내 동료는 무엇을 하나? 팀웍 개발 문화 개선 설계 개선 제안코드 리뷰의 절차 저자(Author) 코드 작성, 리뷰 요청 리뷰어 코드를 읽고 머지 가능한지 결정 변경 내역(Change List, PR) 리뷰 시작 전에 작성 저자가 머지를 원하는 소스 코드에 대한 일련의 변경(잘 한것, 아쉬운 것, 눈여겨 볼 것)에 대해 기술 좋은 Pull Request의 예 저자가 고생해서 리뷰어의 시간을 아껴줘야 한다!!왜 코드 리뷰가 어려운가? 저자 본인 생각에 멋지다고 생각하는 PR을 보냄 리뷰어 왜 멋지지 않은지에 대한 장황한 이유를 작성 코드에 대한 비판을 자신에 대한 비판으로 이해 코드 리뷰는 지식 /공학적 결정을 공유하는 기회 공유(잘한것, 아쉬운 것)를 통해 서로의 지식/경험을 나누며 상호 학습을 통한 역량 증대 수단 코드 토의를 개인적 공격으로 받아들이면 물거품 생각을 글로 전달하는 것에 대한 어려움 오해의 위험이 큼(음성 톤, 표정의 부재) 피드백을 조심스럽게 표현하는 것이 더 중요 파일 Handle 닫는게 빠졌어요! -&gt; 파일 Handle을 닫는 것 깜빡하다니! 넌 바보야!로 받아드리는 경우가 있다. Git의 등장 금요일 오후 svn commit을 조사하며 리뷰 불러서 깨기, 불화/갈등 Git의 등장 Local branch에 commit 단위 리뷰할 수 있도록 SNS 댓글 놀이 코드 리뷰의 기법들효율적인 PR 방법지루한 작업은 컴퓨터로 처리코드를 읽는 것은 인지적 부담이 되는 고수준의 집중이 요구되는 작업 컴퓨터가 할 수 있는 일에 이런 노력을 낭비하지 말라 심지어 기계가 더 잘 할 수 있는 일에 리뷰어의 시간을 낭비시키지 말라. Formatting Tool 공백, 들여쓰기 오류 등 별도의 커밋/PR로 분리. 리뷰 불필요를 기술해서 리뷰를 생략 할 수 있도록 스타일 가이드를 통해 스타일 논쟁을 해소스타일에 대한 논쟁은 리뷰에서 시간 낭비 유명한 코딩 스타일을 차용하거나 자신들의 코딩 스타일을 표준화 해야한다.PR을 올릴 때 주석 달기PR을 저자가 먼저 읽어봐야 한다. 리뷰어들을 위한 설명을 커멘트로 남겨서 리뷰어들의 시간을 절약해야 한다.모두를 포함하라 많은 사람들이 볼 수록 버그를 더 잘 찾아낼 수 있다. 많은 사람들이 본다는 것을 알면 사람들은 대개 더 잘 하려는 경향이 있다.(코드, PR 작성)의미있는 커밋으로 분리 혼자하는 코드리뷰 커밋을 의미 있게 분리하면 혼자서 코드 리뷰를 할 수 있다. 2주 후에 봐도 이해가 될 수 있도록 해야한다.효율적인 리뷰 방법리뷰는 즉시 시작 코드 리뷰를 높은 우선순위로 저자는 리뷰 종료될 때까지 대기(Blocked)함 리뷰를 바로 시작하면 선순환됨 코드를 읽고 피드백을 줄 때는 시간을 가지고 진행해도 되지만 시작은 바로 해라 이상적으로 수분 내에 리뷰 라운드의 최대 시간은 하루 우선순위 높은 업무로 1일 내 불가하면 다른 리뷰어 지정 월 1회 이상 재지정을 해야한다면 속도를 줄여서 건강한 개발 관습(Practices)을 유지할 수 있어야함 Agile Pull requests by Mark Seemann “괴로우면 더 자주해라!” 아침 스탠드 미팅에 익숙 매일 아침 30분, 점심 식사 후 30분을 리뷰를 위해 미리 확보 PR에 포함된 변경이 적도록 노력 반나절 정도 작업한 양 정도 모든 팀원들이 하루에 두번 작은양의 PR을 리뷰할 수 있고 최대 4시간 안에 리뷰가 완료 ㅗ딜 것 근본적인 문제는 사람들이 리뷰할 시간이 없다고 느낀다는 것임 당신의 개인 기여로만 평가를 받고 있다면, 팀을 돕기 위해 수행하는 모든 일은 시간 낭비처럼 보임 이것은 리뷰를 하는 것의 문제라기보다는 조직적인 문제이다. Pull Requests vs Pair Programming 트레이드오프 : Latency or throughput? 내성적, 사색, 비동기 : Pull Requests 외향적, 친밀한 개인적 상호 작용 : Pair Programming 절대답은 없음. 앙상블 방식도 채택 할 수 있다. : 시간을 잡아서 같이 리뷰한다.리뷰를 할 때는 고수준으로 시작 저수준으로 내려가라 리뷰 라운드에서 많은 의견을 남길 수록, 저자가 당황할 위험 커짐 하나의 라운드에 20~50개 정도의 의견은 위험의 시작 초기 라운드에서는 고수준 피드백으로 제한 버그, 장애, 성능, 보안 등 Extract Method, Composed Method, Invert-if(복잡도) 등 고수준의 피드백이 처리된 후에 저수준 이슈를 처리 (선택적인) 설계 개선 변수명 변경, 주석을 명확하게 하는 것 등 예제 코드 제공에 관대해라 저자를 기분 좋게 하기 위한 방법 리뷰 중에 선물 주기(코드 예제) 너무 긴 예제는 관대한 것이 아니라 억압적으로 보임 라운드당 2~3개의 코드 예제로 제한 모든 PR에 예제를 제공하면 저자가 코드를 작성 할 수 없다고 생각한다는 신호 리뷰의 범위를 존중하라 자주 보이는 Anti-Pattern PR 근처의 코드를 보고 저자에게 수정을 요청 Rule of thumb PR에 포함되지 않은 라인은 리뷰 범위가 아님 예외 : PR이 둘러싼 코드에 영향을 미칠 때태그를 활용 [Nit] 고치면 좋지만 아니어도 그만을 의미 그래도 보통은 고침 리뷰어는 항상 더 개선할 수 있는 의견을 자유롭게 남길 수 있어야함 중요치 않다면 Nit 태그로 남겨서 저자가 무시할 수 있도록 할 수 잇음 교육적인 목적이나 개발자들이 지속적으로 기술을 연마하는 것을 돕는 목적 예) nit: null 대신 Optional을 쓰면 어떨까요?, OCP 준수를 위해 Strategy 도입은 어떨까요? 한두 등급만 코드 레벨을 올리는 것을 목표로 D 등급의 PR을 받으면 저자가 C나 B 등급을 받도록 도와라 Letter Grade 완전하지는 않아도 충분히 좋은 코드가 되도록 F 기능적으로 틀렸거나 너무 복잡해서 정합성에 확신이 없는 상태 승인을 보류하는 유일한 이유 수 차례의 리뷰 라운드 후에도 코드가 F 상태인 경우 피드백 방법절대 “너”라고 하지마라 리뷰의 핵심 \"무엇이 코드를 나아지게 하는가?\" “누가 그런 아이디어(잘못)를 냈는지”가 아님 저자의 방어 유발을 최소화하는 방법으로 피드백 비판의 대상은 코드. 저자가 아님 “너” : 저자의 주의를 코드에서 자신으로 바꿈 “너”만 빼라(저자에 대한 판단 -&gt; 단순한 정정) I Message 대화법 : 행동 - 결과 - 감정 ~하는 것을 제안합니다. 하는게 어떨까요? : 오픈 커뮤니케이션건설적인 피드백을 하라 동료들 간의 코드 리뷰 not 경쟁 유발 but 팀의 생산성을 높이는 것 코드 리뷰를 자신의 코드에 대해 비판이 아니라 학습의 과정으로 인지하면 전체적인 프로젝트의 성공을 기여함 건설적인 피드백은 개발자들이 그들의 실수에서 배우고 역량을 증대하도록 동기부여함 건설적인 피드백을 못하겠으면 차라리 아무말을 하지마라.진정한 칭찬을 해라 대부분의 리뷰어가 잘못된 부분에만 집중 하지만 리뷰는 긍정적 행위 강화를 위한 값진 기회이기도 함 PR에서 좋은 변경이 있을 때마다 “오 이런 API가 있나요. 정말 유용해요” “정말 좋은 해결책이네요. 생각도 못 했네요” “함수를 분리하는 것은 좋은 생각이에요. 훨씬 단순해졌어요.” 저자가 주니어 혹은 신규 입사자라면 리뷰에 매우 민감하고 방어적일 수 있음 진심어란 칭찬은 리뷰어가 잔인한 감시자가 아니라 도와주려는 팀동료라는 것을 보여서 이런 긴장감을 낮춤피드백은 명령이 아니라 요청으로 표현해라 일상에서 동료에게 명령하지 않음 명령형(How) : “12번 테이블 자리가 비어있습니다. 우리 가족은 저기에 앉을 것입니다.” 요청(What) : “네명 앉을 자리 부택해요” &lt;- 선언형. Tell, Don't Ask 하지만 리뷰에서는 강압적인 명령이 종종 발견됨 ex. 이 클래스를 별도의 파일로 분리하라 -&gt; 이 클래스를 별도의 파일로 분리할 수 있을까요? or 이 클래스는 너무 커지는 것 같은데 괜찮을까요? &lt;- 나의 걱정 의견이 아니라 원칙에 기반하여 피드백하라 저자에게 의견을 줄 때는 \"제안하는 변경\"과 “변경의 이유“를 모두 설명하라 ex) 이 클래스를 2개로 분리해야 해요 -&gt; 지금 이 클래스는 파일 다운로드와 파싱의 2가지 책임을 가지고 있어요. 다운로더와 파서 2개의 클래스로 분리하여 SRP를 준수하는 것이 어떨까요? SW는 과학인 동시에 예술 항상 원칙에 기반하여 정확히 뭐가 잘못 되었는지 언급할 수 있는 것은 아니다. 단지 그냥 보기 싫거나 직관적이지 않을 수 있다. 무엇을 할 수 있을지 객관적으로 설명하라 ex) 이 코드는 혼란스럽네요(너?) -&gt; 나는 이 코드를 이해하기 어렵네요(I Message) 반복적인 패턴에 대해서 피드백을 제한하라 저자의 실수가 동일한 패턴임을 식별 했다면 모든 경우를 언급하지는 말라 동일 패턴에 대해서 2~3개 정도의 예를 언급하라. 그 이상은 저자에게 개별 사례가 아니라 패턴에 대해서 수정을 요구하라 10개가 있으면 1개만 말하고 10개를 모두 찾아서 고치라고 하지 말라교착상태 시교착상태를 적극적으로 처리해라 교착상태로 향하는지 나타내는 표식 토론의 톤이 점차 팽팽해지고 공격적으로 됨 라운드당 커멘트가 줄어들지 않는 경향을 보임 너무 많은 커멘트에 저항이 보임 코드 리뷰의 최악의 결과는 교착상태(Stalemate) 커멘트를 반영하지 않으니 승인 거부 저자는 커멘트 반영을 거부 만나서 얘기하라 화상 혹은 만나서 논의(특히 복잡한 리뷰) 텍스트 기반 의사소통은 상태가 인간이라는 것을 잊게 함 교착상태를 적극적으로 처리해라 인정하거나 Escalate하라 교착상태가 길어지면 관계가 나빠짐(퇴사) 그냥 승인하는 비용(Agree to disagree - 갈등 해결책) 저수준 코드를 무심코 승인하면 SW품질이 낮아질 수 있음 동료와 너무 다퉈서 함께 일하지 않게 된다면 고수준의 품질을 얻을 수 없음 인정이 불가한 경우 저자에게 논의를 팀장이나 테크 리더에게 Escalation 다른 리뷰어에게 할당 교착상태로 부터 회복 상황을 관리자와 논의 하라 휴식을 가져라. 가능하다면 안정될 때까지 PR을 서로 보내지 마라 갈등 해결책을 학습하라 설계 리뷰를 고려하라 코드 리뷰 때 설계 리뷰 때 논의되었아야 할 사항을 논쟁하는가? 설계 리뷰는 있었나? 아주 심각하지 않다면 그냥 인정하고 좋은 관계로 동료와의 협업을 지속해라 Agree to disagree " }, { "title": "8장. 경계 간 매핑하기", "url": "/posts/MakeLearnCleanArchitecture_ch8/", "categories": "DDD, 만들면서 배우는 클린 아키텍처", "tags": "DDD, CleanArchitecture", "date": "2022-04-20 23:50:00 +0900", "snippet": "소개만들면서 배우는 클린 아키텍처 책을 읽고 정리하며 소감을 적는 포스트입니다.경계 간 매핑하기늘상 겪는 문제인 각 계층의 모델을 매핑하는 것에 대해서는 거의 다뤄지지 않는다.여러분도 매퍼 구현을 피하기 위해 두 계층에서 같은 모델을 사용하는 것에 대해 논의 해 본적이 있을 것이다. 매핑에 찬성하는 개발자 : 두 계층 간에 매핑을 하지 않으면 양 계층에서 같은 모델을 사용해야 하는데 이렇게 하면 두 계층이 강하게 결합됩니다. 매핑에 반대하는 개발자 : 하지만 두 계층 간에 매핑을 하게 되면 보일러플레이트 코드를 너무 많이 만들게 돼요. 많은 유스케이스들이 오직 CRUD만 수행하고 계층에 걸쳐 같은 모델을 사용하기 때문에 계층 사이의 매핑은 과합니다.모두 틀린 말이 아니며 결정에 도움이 되는 매핑 전략에 대해 알아본다.“매핑하지 않기” 전략 포트 인터페이스가 도메인 모델을 입출력 모델로 사용하면 두 계층 간의 매핑을 할 필요가 없다.위 예제는 송금하기 유스케이스와 관련된 요소들이다.웹 계층과 애플리케이션 계층 모두 Account 클래스에 접근해야 한다. 반대쪽의 영속성 계층과 애플리케이션 계층도 같은 관계이다. 모든 계층이 같은 모델을 사용하니 계층 간 매핑을 전혀 할 필요가 없다.하지만 만약 JSON으로 직렬화하기 위해 어너테이션을 모든 클래스의 특정 필드에 붙여야 할 수도 있다. 또한 ORM을 사용한다면 데이터베이스 매핑을 위해 특정 어너테이션이 필요 할 수 도 있다.이는 단일 책임 원칙을 위반한다.하지만 어너테이션으로 인해 코드가 지저분 해지지만 딱히 문제 없이 잘 돌아갈 것이다.간단한 CRUD의 경우 매핑하지 않기 전략이 더 맞을 수도 있다.“양방향” 매핑 전략 각 어댑터가 전용 모델을 가지고 있어서 해당 모델을 도메인 모델로, 도메인 모델을 해당 모델로 매핑할 책임을 가지고 있다.두 계층 모두 양방향으로 매핑하기 때문에 양방향 매핑이라고 부른다.각 계층의 전용 모델을 변경하더라도 다른 계층에는 영향이 없다.이 매핑 전략은 웨이나 영속성 관심사로 오염되지 않은 깨끗한 도메인 모델로 이어진다.하지만, 너무 많은 보일러플레이트 코드가 생긴다. 또한 도메인 모델이 계층 경계를 넘어서 통신하는 데 사용되고 있다.인커밍 포트와 아웃고잉 포트의 도메인 객체를 입력 파라미터와 반환값으로 사용되고 있다.어떤 매핑 전략도 철칙처럼 여겨져서는 안된다. 그 대신 각 유스케이스 마다 적절한 전략을 택해야 한다.“완전” 매핑 전략 각 연산이 전용 모델을 필요로 하기 때문에 웹 어댑터와 애플리케이션 계층 각각이 자신의 전용 모델을 각 연산을 실행하는 데 필요한 모델로 매핑한다.이 매핑 전략에서는 각 연산마다 별도의 입출력 모델을 사용한다. 계층 경계를 넘어 통신 할 때는 도메인 모델을 사용하지 않고 Command, Request와 같은 특화된 모델을 사용한다.한 계층을 여러 개의 커맨드로 매핑하는 데는 하나의 웹 모델과 도메인 모델 간의 매핑보다 더 많은 코드가 생기지만 유지보수하기는 쉽다.하지만 이 매핑 전략을 전역 패턴으로는 추천하지 않는다. 이 전략은 경계를 명확하게 할 때 가장 빛을 발한다.“단방향” 매핀 전략 동일한 ‘상태’ 인터페이스를 구현하는 도메인 모델과 어댑터 모델을 이용하면 각 계층은 다른 계층으로부터 온객체를 단반향으로 매핑하기만 하면 된다.이 전략에서는 모든 모델들이 같은 인터페이스를 구현한다. 도메인 모델 자체는 풍부한 행동을 구현할 수 있고, 애플리케이션 계층 내의 서비스에서 이러한 행동에 접근 할 수 있다.이 매핑은 팩터리(factory)라는 DDD 개념과 잘 어울린다. DDD 용어인 팩터리는 어떤 특정한 상태로부터 도메인 객체를 재구성할 책임을 가지고 있다.이 전략은 계층 간의 모델이 비슷할 때 가장 효과적이다." }, { "title": "7장. 아키텍처 요소 테스트하기", "url": "/posts/MakeLearnCleanArchitecture_ch7/", "categories": "DDD, 만들면서 배우는 클린 아키텍처", "tags": "DDD, CleanArchitecture", "date": "2022-04-20 23:20:00 +0900", "snippet": "소개만들면서 배우는 클린 아키텍처 책을 읽고 정리하며 소감을 적는 포스트입니다.아키텍처 요소 테스트하기많은 프로젝트의 자동화된 테스트는 규칙에 따라 작성되지만 테스트 전략을 물었을 때 제대로 답변하는 이가 없었다.이번 포스트에서는 육각형 아키텍처에서의 테스트 전략에 대해 이야기 합니다.테스트 피라미드 테스트 피라미드에 따르면 비용이 많이 드는 테스트는 지양하고 비용이 적게 드는 테스트를 많이 만들어야 한다.기본 전제는 만드는 비용이 적고, 유지보수하기 쉽고, 빨리 실행되고, 안정적인 작은 크기의 테스트들에 대해 높은 커버리지를 유지해야 한다.단위와 단위를 넘는 경계, 아키텍처의 경계, 시스템의 경계를 결합하는 테스트는 만드는 비용이 더 비싸지고, 실행이 더 느려지며 깨지기 쉬워진다.단위 테스트는 피라미드의 토대에 해당한다. 일반적으로 하나의 클래스를 인스턴스화하고 해당 클래스의 인터페이스를 통해 기능들을 테스트 한다. 만약 테스트 중인 클래스가 다른 클래스에 의존한다면 의존되는 클래스들은 인스턴스화 하지 않고 테스트하는 동안 필요한 작업들을 흉내 내는 목(mock)으로 대체한다.통합테스트는 연결된 여러 유닛을 인스턴스화하고 시작점이 되는 클래스의 인터페이스로 데이터를 보낸 후 유닛들의 네트워크가 기대한 대로 잘 동작하는지 검증한다.두 계층 간의 경계를 걸쳐서 테스트 할 수 있기 때문에 객체 네트워크가 완전하지 않거나 어떤 시점에는 목을 대상으로 수행해야 한다.시스템 테스트는 애플리케이션을 구성하는 모든 객체 네트워크를 가동시켜 특정 유스케이스가 전 계층에서 잘 동작하는지 검증한다.단위 테스트로 도메인 엔티티 테스트하기Account 엔티티를 테스트하기 위해 상태틑 과거 특정 시점의 계좌 잔고(baselineBalance)와 그 이후의 입출금 내역(activity)으로 구성돼 있다.github codeclass AccountTest{ @Test void withdrawalSucceeds(){ AccountId accountId = new AccountId(1L); Account account = defaultAccount() .withAccountId(accountId) .withBaselineBalance(Money.of(555L)) .withActivityWindow(new ActivityWindow( defaultActivity() .withTargetAccount(accountId) .withMoney(Money.of(999L)).build(), defaultActivity() .withTargetAccount(accountId) .withMoney(Money.of(1L)).build())) .build(); boolean success = account.withdraw(Money.of(555L), new AccountId(99L)); assertThat(success).isTrue(); assertThat(account.getActivityWindow().getActivities()).hasSize(3); assertThat(account.calculateBalance()).isEqualTo(Money.of(1000L)); }}특정 상태의 Account를 인스턴스화하고 withdraw()메서드를 호출해서 출금이 성공했는지 검증하고, Account 객체의 상태에 대해 기대되는 부수효과들이 잘 일어났는지 확인하는 단순한 단위 테스트다.단위 테스트는 이해하기 쉽고, 아주 빠르게 실행된다. 또한 도메인 엔티티에 녹아 있는 비즈니스 규칙을 검증하기에 가장 적절한 방법이다.단위 테스트로 유스케이스 테스트 하기계층의 바깥쪽으로 나가서, 다음으로 테스트 할 것이 아키텍처의 유스ㅔ이스다.SendMoneyService의 테스트를 살펴보면, SenMoney 유스케이스는 출금 계좌의 잔고가 다른 트랜잭션에 의해 변경되지 않도록 락(lock)을 건다. 출금 계좌에서 돈이 출금되고 나면 똑같이 입금 계좌에 락을 걸고 돈을 입금시킨다.github codeclass SendMoneyServiceTest{ // 필드 선언은 생략 @Test void transactionSucceeds() { Account sourceAccount = givenSourceAccount(); Account targetAccount = givenTargetAccount(); givenWithdrawalWillSucceed(sourceAccount); givenDepositWillSucceed(targetAccount); Money money = Money.of(500L); SendMoneyCommand command = new SendMoneyCommand( sourceAccount.getId(), targetAccount.getId(), money); boolean success = sendMoneyService.sendMoney(command); assertThat(success).isTrue(); AccountId sourceAccountId = sourceAccount.getId(); AccountId targetAccountId = targetAccount.getId(); then(accountLock).should().lockAccount(eq(sourceAccountId)); then(targetAccount).should().withdraw(eq(money), eq(targetAccountId)); then(accountLock).should().releaseAccount(eq(sourceAccountId)); then(accountLock).should().lockAccount(eq(targetAccountId)); then(targetAccount).should().deposit(eq(money), eq(sourceAccountId)); then(accountLock).should().releaseAccount(eq(targetAccountId)); thenAccountsHaveBeenUpdated(sourceAccountId, targetAccountId); } // 헬퍼 메서드 생략}테스트의 가독성을 높이기 위해 행동-주도 개발(behavior driven development)에서 일반적으로 사용하는 방식대로 given/when/then 섹셩으로 나눳다.given 섹션에서는 출금 및 입금 Account의 인스턴스를 각각 생성하고 적절한 상태로 만들고 SendMoneyCommand 인스턴스도 만들어서 유스케이스의 입력으로 사용한다.when 섹션에서는 유스케이스를 실행하기 위해 sendMoeny() 메서드를 호출한다.then 섹션에서는 트랜잭션이 성공적이었는지 확인하고, 출금 및 입금 Account, 그리고 계좌에 락을 걸고 해제하는 책임을 가진 AccountLock에 대해 특정 메서드가 호출됐는지 검증한다.서비스가 (모팅된) 의존 대상의 특정 메서드와 상호작용햇는지 여부를 검증하면, 테스트가 코드의 행동 변경 뿐만 아니라 코드의 구조 변경에도 취약해진다.그렇기 때문에 테스트에서 어떤 상호작용을 검증하고 싶은지 신중하게 생각해야 한다.통합 테스트로 웹 어댑터 테스트하기한 계층 더 바깥으로 나가면 어댑터에 도착한다. 웹 어댑터를 테스트 한다.github code@WebMvcTest(controllers = SendMoneyController.class)class SendMoneyControllerTest {\t@Autowired\tprivate MockMvc mockMvc;\t@MockBean\tprivate SendMoneyUseCase sendMoneyUseCase;\t@Test\tvoid testSendMoney() throws Exception {\t\tmockMvc.perform(post(\"/accounts/send/{sourceAccountId}/{targetAccountId}/{amount}\",\t\t\t\t41L, 42L, 500)\t\t\t\t.header(\"Content-Type\", \"application/json\"))\t\t\t\t.andExpect(status().isOk());\t\tthen(sendMoneyUseCase).should()\t\t\t\t.sendMoney(eq(new SendMoneyCommand(\t\t\t\t\t\tnew AccountId(41L),\t\t\t\t\t\tnew AccountId(42L),\t\t\t\t\t\tMoney.of(500L))));\t}}MockMvc 객체를 이용해 모킹했기 때문에 실제로 HTTP 프로토콜을 통해 테스트 한 것은 아니다. 프레임워크가 HTTP 프로토콜에 맞게 모든 것을 적절히 잘 변환한다고 믿는 것이다.이 테스트는 왜 단위 테스트가 아니라 통합 테스트 인가?? 이 테스트에서는 하나의 웹 컨트롤러 클래스만 테스트 한 것처럼 보이지만, 사실 보이지 않는 곳에서 다 많은 일들이 벌어지고 있다.웹 컨트롤럴가 스프링 프레임워크에 강하게 묶여 있기 때문에 격리된 상태로 테스트하기 보다는 이 프레임워크와 통합된 상태로 테스트 하는 것이 합리적이다.통합 테스트로 영속성 어댑터 테스트하기영속성 어댑터의 테스트는 단위 테스트보다는 통합 테스트를 적용하는 것이 합리적이다.github code@DataJpaTest@Import({AccountPersistenceAdapter.class, AccountMapper.class})class AccountPersistenceAdapterTest {\t@Autowired\tprivate AccountPersistenceAdapter adapterUnderTest;\t@Autowired\tprivate ActivityRepository activityRepository;\t@Test\t@Sql(\"AccountPersistenceAdapterTest.sql\")\tvoid loadsAccount() {\t\tAccount account = adapterUnderTest.loadAccount(new AccountId(1L), LocalDateTime.of(2018, 8, 10, 0, 0));\t\tassertThat(account.getActivityWindow().getActivities()).hasSize(2);\t\tassertThat(account.calculateBalance()).isEqualTo(Money.of(500));\t}\t@Test\tvoid updatesActivities() {\t\tAccount account = defaultAccount()\t\t\t\t.withBaselineBalance(Money.of(555L))\t\t\t\t.withActivityWindow(new ActivityWindow(\t\t\t\t\t\tdefaultActivity()\t\t\t\t\t\t\t\t.withId(null)\t\t\t\t\t\t\t\t.withMoney(Money.of(1L)).build()))\t\t\t\t.build();\t\tadapterUnderTest.updateActivities(account);\t\tassertThat(activityRepository.count()).isEqualTo(1);\t\tActivityJpaEntity savedActivity = activityRepository.findAll().get(0);\t\tassertThat(savedActivity.getAmount()).isEqualTo(1L);\t}}이 테스트는 데이터베이스를 모킹하지 않았다는 점이 중요하다. 테스트가 실제로 데이터베이스에 접근한다. 데이터베이스를 모킹했더라도 테스트는 여전히 같은 코드 라인 수만큼 커버해서 똑같이 높은 커버리지를 보여줬을 것이다.기본적으로 인메모리(in-memory) 데이터베이스를 테스트에서 사용한다. 아뭇것도 설정할 필요 없이 곧바로 테스트할 수 있으므로 아주 실용적이다.시스템 테스트로 주요 경로 테스트하기시스템 테스트는 전체 애플리케이션을 띄우고 API를 통해 요청을 보내고, 모든 계층이 조화롭게 잘 동작하는지 검증한다.github code@SpringBootTest(webEnvironment = WebEnvironment.RANDOM_PORT)class SendMoneySystemTest {\t@Autowired\tprivate TestRestTemplate restTemplate;\t@Autowired\tprivate LoadAccountPort loadAccountPort;\t@Test\t@Sql(\"SendMoneySystemTest.sql\")\tvoid sendMoney() {\t\tMoney initialSourceBalance = sourceAccount().calculateBalance();\t\tMoney initialTargetBalance = targetAccount().calculateBalance();\t\tResponseEntity response = whenSendMoney(\t\t\t\tsourceAccountId(),\t\t\t\ttargetAccountId(),\t\t\t\ttransferredAmount());\t\tthen(response.getStatusCode())\t\t\t\t.isEqualTo(HttpStatus.OK);\t\tthen(sourceAccount().calculateBalance())\t\t\t\t.isEqualTo(initialSourceBalance.minus(transferredAmount()));\t\tthen(targetAccount().calculateBalance())\t\t\t\t.isEqualTo(initialTargetBalance.plus(transferredAmount()));\t}\tprivate Account sourceAccount() {\t\treturn loadAccount(sourceAccountId());\t}\tprivate Account targetAccount() {\t\treturn loadAccount(targetAccountId());\t}\tprivate Account loadAccount(AccountId accountId) {\t\treturn loadAccountPort.loadAccount(\t\t\t\taccountId,\t\t\t\tLocalDateTime.now());\t}\tprivate ResponseEntity whenSendMoney(\t\t\tAccountId sourceAccountId,\t\t\tAccountId targetAccountId,\t\t\tMoney amount) {\t\tHttpHeaders headers = new HttpHeaders();\t\theaders.add(\"Content-Type\", \"application/json\");\t\tHttpEntity&lt;Void&gt; request = new HttpEntity&lt;&gt;(null, headers);\t\treturn restTemplate.exchange(\t\t\t\t\"/accounts/send/{sourceAccountId}/{targetAccountId}/{amount}\",\t\t\t\tHttpMethod.POST,\t\t\t\trequest,\t\t\t\tObject.class,\t\t\t\tsourceAccountId.getValue(),\t\t\t\ttargetAccountId.getValue(),\t\t\t\tamount.getAmount());\t} //일부 헬퍼 메서드는 생략}시스템 테스트라고 하더라도 언제나 서드파티 시스템을 실행해서 테스트할 수 있는 것은 아니기 때문에 결국 모킹을 해야 할 때도 있다. 육각형 아키텍처는 이러한 경우 몇 개의 출력 포트 인터페이스만 모킹하면 되기 때문에 아주 쉽게 이 문제를 해결할 수 있다.얼마만큼의 테스트가 충분할까??테스트가 코드의 80%를 커버하면 충분할까? 아니면 그보다 높아야 할까??라인 커버리지(line coverage)는 테스트 성공을 측정하는 데 있어서 잘못된 지표다.나는 얼마나 마음 편하게 소프트웨어를 배포할 수 있느냐를 테스트의 성공 기준으로 삼으면 된다고 생각한다.처음 몇 번의 배포에는 믿음의 도약이 필요하다. 그렇지만 프로덕션의 버그를 수정하고 이로부터 배우는 것 우선순위로 삼으면 제대로 가고 있는 것이다.아래는 육각형 아키텍처에서 사용하는 테스트 전략이다. 도메인 엔티티를 구현 할 때는 단위 테스트로 커버하자 유스케이스를 구현할 때는 단위 테스트로 커버하자 어댑터를 구현할 때는 통합 테스트로 커버하자 사용자가 취할 수 있는 중요 애플리케이션 경로는 시스템 테스트로 커버하자구현할 때는이라는 문구가 중요한데, 만약 테스트가 기능 개발 후가 아닌 개발 중에 이뤄진다면 하기 싫은 귀찮은 작업이 아니라 개발 도구로 느껴질 것이다." }, { "title": "6장. 영속성 어댑터 구현하기", "url": "/posts/MakeLearnCleanArchitecture_ch6/", "categories": "DDD, 만들면서 배우는 클린 아키텍처", "tags": "DDD, CleanArchitecture", "date": "2022-04-20 22:20:00 +0900", "snippet": "소개만들면서 배우는 클린 아키텍처 책을 읽고 정리하며 소감을 적는 포스트입니다.영속성 어댑터 구현하기전통적인 계층형 아키텍처의 경우 영속성 계층에 의존하게 되어 데이터베이스 주도 설계가 된다고 이야기 했었다.이번 포스트에서는 이러한 의존성을 역전시키기 위해 영속성 계층을 애플리케이션 계층의 플러그인으로 만드는 방법에 대해 살펴본다.의존성 역전 코어의 서비스가 영속성 어댑터에 접근하기 위해 포트를 사용한다.애플리케이션 서비스에서 영속성 기능을 사용하기 위해 포트 인터페이스를 호출한다. 그리고 실제 영속성 작업을 수행하고 데이터베이스와 통신할 책임을 가진 영속성 어댑터 클래스에 의해 구현된다.포트는 사실상 애플리케이션 서비스와 영속성 코드 사이의 간접적인 계층이다. 영속성 문제에 신경 쓰지 않고 도메인 코드를 개발하기 위해, 즉 영속성 계층에 대한 코드 의존성을 없애기 위해 이러한 간접 계층을 추가하고 있다는 사실을 잊어서는 안된다.영속성 어댑터의 책임 입력을 받는다. 입력을 데이터베이스 포맷으로 매핑한다. 입력을 데이터베이스로 보낸다. 데이터베이스 출력을 애플리케이션 포맷으로 매핑한다. 출력을 반환한다.1. 입력을 받는다.영속성 어댑터는 포트 인터페이스를 통해 입력 받는다. 입력 모델은 인터페이스가 지정한 도메인 엔티티나 특정 데이터베이스 연상 전용 객체가 된다.2. 입력을 데이터베이스 포맷으로 매핑한다.영속성 어댑터는 데이터베이스를 쿼리하거나 변경하는 데 사용할 수 있는 포맷으로 입력 모델을 매핑한다.핵심은 영속성 어댑터의 입력 모델이 영속성 어댑터 내부에 있는 것이 아니라 애플리케이션 코어에 있기 때문에 영속성 어댑터 내부를 변경하는 것이 코어에 영향을 미치지 않는다.3. 입력을 데이터베이스로 보낸다.영속성 어댑터는 데이터베이스에 쿼리를 날리고 쿼리 결과를 받아온다.4. 데이터베이스 출력을 애플리케이션 포맷으로 매핑한다.데이터베이스 응답을 포트에 정의된 출력 모델로 매핑해서 반환한다.5. 출력을 반환한다.출력 모델이 영속성 어댑터가 아니라 애플리케이션 코어에 위치하는 것이 중요하다.입출력 모델이 영속성 어댑터가 아니라 애플리케이션 코어에 있다는 점을 제외하면 책임은 전통적인 영속성 계층의 책임과 크게 다르지 않다.포트 인터페이스 나누기서비스를 구현하면서 생기는 의문은 데이터베이스 연산을 정의하고 있는 포트 인터페이스를 어떻게 나눌 것인가다.아래와 같인 특정 엔티티가 필요로 하는 모든 데이터베이스 연산을 하나의 리포지토리 인터페이스에 넣어 두는 것이 일반적인 방법이다. 하나의 아웃고잉 포트 인터페이스에 모든 데이터베이스 연산을 모아두면 모든 서비스가 실제로는 필요하지 않은 메서드에 의존하게 된다.하나의 리포지토리 인터페이스에 모든 것을 넣게 되면 데이터베이스 연산에 의존하는 각 서비스는 인터페이스에서 단 하나의 메서드만 사용하더라도 하나의 넓은 포트 인터페이스에 의존성을 갖게 된다.코드에 불필요한 의존성이 생겼다는 뜻이다.필요하지 않은 메서드에 생긴 의존성은 코드를 이해하고 테스트하기 어렵게 만든다. 테스트에서 작업하는 사람은 인터페이스 전체가 모킹 됐다고 기대하는 바람에 어떤 메서드가 모킹되었는지 찾지 못하고 에러를 보게 될 수 있다. “필요없는 화물을 운반하는 무언가에 의존하고 있으면 예상하지 못했던 문제가 생길 수 있다.” 로버트 C. 마틴인터페이스 분리 원칙(Interface Segregation Principle, ISP)은 이 문제의 답을 제시한다.이 원칙은 클라이언트가 오로지 자신이 필요로 하는 메서드만 알면 되도록 넓은 인터페이스를 특화된 인터페이스로 분리해야 한다고 설명한다. 인터페이스 분리 원칙을 적용하면 불필요한 의존성을 제거하고 기존 의존성을 눈에 더 잘 띄게 만들 수 있다.위와 같이 인터페이스를 나누면 각 서비스는 실제로 필요한 메서드에만 의존하게 된다. 나아가 포트의 이름이 포트의 역할을 명확하게 잘 표현하고 있다.매우 좁은 포트를 만드는 것은 코딩을 플러그 앤드 플레이(plug-and-play) 경험으로 만든다.영속성 어댑터 나누기아래와 같이 영속성 연산이 필요한 도메인 클래스(또는 DDD에서의 에그리게이트) 하나당 하나의 영속성 어댑터를 구현하는 방식을 선택할 수 있다. 하나의 애그리게이트당 하나의 영속성 어댑터를 만들어서 여러 개의 영속성 어댑터를 만들 수도 있다.위 그림과 같이 하면 영속성 어댑터들은 각 영속성 기능을 이용하는 도메인 경계를 따라 자동으로 나눠진다.도메인 코드는 영속성 포트에 의해 정의된 명세를 어떤 클래스가 충족시키는지에 관심 없다는 사실을 기억해야한다.애그리게이트당 하나의 영속성 어댑터 접근 방식 또한 나중에 여러 개의 바운디드 컨텍스(bounded context)의 영속성 요구사항을 분리하기 위한 좋은 토대가 된다. 바운디드 컨텍스트 간의 경계를 명확하게 구분하고 싶다면 각 바운디드 컨텍스트가 영속성 어댑터(들)을 하나씩 가지고 있어야 한다.각 바운디드 컨텍스트는 영속성 어댑터를 하나씩 가지고 있고 바운디드 컨텍스트라는 표현은 경계를 암시한다.account서비스가 billing 영속성 어댑터에 접근하지 않고, 반대로 billing의 서비스도 account의 영속성 어댑터에 접근하지 않는다는 의미이다.서로 접근하려면 전용 인커밍 포트를 통해 접근해야 한다.데이터베이스 트랜잭션은 어떻게 해야 할까?트랜잭션 경계는 어디에 위치시켜야 할까??트랜잭션은 하나의 특정한 유스케이스에 대해서 일어나는 모든 쓰지 작업에 걸쳐 있어야 한다. 그래야 그중 하나라도 실패할 경우 다 같이 롤백 될 수 있기 때문이다.영속성 어댑터는 어떤 데이터베이스 연산이 같은 유스케이스에 포함되는 알지 못하기 때문에 언제 트랜잭션을 열고 닫을지 결정할 수 없다.이 책임은 영속성 어댑터 호출을 관장하는 서비스에 위임해야 한다." }, { "title": "5장. 웹 어댑터 구현하기", "url": "/posts/MakeLearnCleanArchitecture_ch5/", "categories": "DDD, 만들면서 배우는 클린 아키텍처", "tags": "DDD, CleanArchitecture", "date": "2022-04-17 23:20:00 +0900", "snippet": "소개만들면서 배우는 클린 아키텍처 책을 읽고 정리하며 소감을 적는 포스트입니다.웹 어댑터 구현하기UI나 다른 시스템에서 애플리케이션을 호출하는 방식으로 상호작용하는 HTTP API가 웹 어댑터에 해당 됩니다.의존성 역전아래의 그림은 웹 어댑터와 관련된 아키텍처 요소(어댑터 자체와 애플리케이션 코어와 상호작용 하는 포트)에 조금 더 초점을 맞춘 그림이다. 인커밍 어댑터는 애플리케이션 서비스에 의해 구현된 인터페이스인 전용 포트를 통해 애플리케이션 계층과 통신한다.adapter.in.web은 주도하는 어댑터이다. 제어 흐름은 웹 어댑터에 있는 컨트롤러에서 애플리케이션 계층에 있는 서비스로 흐른다.애플리케이션 계층은 웹 어댑터가 통신할 수 있는 특정 포트를 제공한다.위 그림은 의존성 역전 원칙이 적용되어 있는데 왜 아래와 같이 직접 호출 하지 않는 것일까?? 포트 인터페이스를 삭제하고 서비스를 직접 호출할 수 있다.애플리케이션 코어가 외부 세계와 통신 할 수 있는 곳에 대한 명세가 있는 포트이기 때문이다. 포트를 적절한 곳에 위치시키면 외부와 어떤 통신이 일어나고 있는지 정확히 알 수 있고, 이는 레거시 코드를 다루는 유지보수 엔지니어에게 무척 소중한 정보이다.웹 소켓을 통해 실시간 데이터를 사용자의 브라우저로 보낸다고 가정할 때 아래와 같은 포트가 반드시 필요하다. 만약 애플리케이션이 웹 어댑터에 능동적으로 알림을 줘야 한다면 의존성을 올바른 방향으로 유지하기 위해 아웃고잉 포트를 통과해야 한다.위 그림을 보면 웹 소켓 컨트롤러는 인커밍 어댑터인 동시에 아웃고잉 어댑터가 되어 사용하고 있다.애플리케이션이 웹 어댑터에 능동적으로 알림을 줘야 한다면 의존성을 올바른 방향으로 유지하기 위해서 아웃고잉 포트를 통과해야만 한다.웹 어댑터의 책임BuckPal 애플리케이션에서 REST API를 제공한다고 했을 때 웹 어댑터의 책임은 어디서 어디까지 일까? HTTP 요청을 자바 객체로 매핑 권한 검사 입력 유효성 검증 입력을 유스케이스의 입력 모델로 매핑 유스케이스 호출 유스케이스의 출력을 HTTP로 매핑 HTTP 응답을 반환보통은 웹 어댑터가 인증과 권한 부여를 수행하고 실패할 경우 에러를 반환한다.그러고 나면 들어오는 객체의 상태 유효성 검증을 할 수 있다. 그런데 이전 포스트에서 입력 유효성 검증이 유스케이스 입력 모델의 책임이라고 했었다.유스케이스 입력 모델은 유스케이스의 맥락에서 유효한 입력만 허용해야 한다. 그러나 여기서는 웹 어댑터의 입력 모델에 대해 이야기 하고 있는 것이다.유스케이스 입력 모델의 유효성 검증을 웹 어댑터에서도 구현해야 하는 것은 아니지만 웹 어댑터의 입력 모델을 유스케이스의 입력 모델로 변활할수 있다는 것을 검증해야 한다.HTTP와 관련된 것은 애플리케이션 계층으로 침투해서는 안된다. 우리가 바깐 계층에서 HTTP를 다루고 있다는 것을 애플리케이션 코어가 알게 되면 HTTP를 사용하지 않는 또 다른 인커밍 어댑처의 요청에 대해 동일한 도메인 로직을 수행 할 수 있는 선택지를 잃게 된다.도메인과 애플리케이션 계층부터 개발하기 시작하면 이러한 계층은 자연스럽게 생기게 된다.컨트롤러 나누기웹 어댑터는 한 개 이상의 클래스로 구성해도 상관 없다. 하지만 같은 소속이라는 것을 표현하기 위해 같은 패키지 수준에 놓아야 한다.또한 가능한 적게 만드는 것이 좋다.BuckPal 애플리케이션의 Account 엔티티의 연산들을 예를 들었을 때 AccountController를 하난 만들어서 계좌에 관한 모든 요청을 받도록 만들 수 있다.계좌 리소스와 관련 된 일이 하나의 클래스로 모여 있어 괜찮아 보이지만 단점이 많다.먼저, 클래스의 코드는 적을 수록 좋다. 코드가 길어 질수록 파악하기가 어려워지고 테스트 코드 또한 파악하기 어려워 진다." }, { "title": "4장. 유스케이스 구현하기", "url": "/posts/MakeLearnCleanArchitecture_ch4/", "categories": "DDD, 만들면서 배우는 클린 아키텍처", "tags": "DDD, CleanArchitecture", "date": "2022-04-17 22:20:00 +0900", "snippet": "소개만들면서 배우는 클린 아키텍처 책을 읽고 정리하며 소감을 적는 포스트입니다.유스케이스 구현하기이전 포스트에서 만든 육각형 아키텍처에서 애플리케이션, 웹, 영속성 계층이 현재 아키텍처에서 아주 느슨하게 결합돼 있기 때문에 필요한 대로 도메인 코드를 자유롭게 모델링할 수 있다.DDD를 할 수 있고, 풍부하거나(rich), 빈약한(anemic) 도메인 모델을 구현할 수도 있다.도메인 모델 구현하기한 계좌에서 다른 계좌로 송금하는 유스케이스를 구현해 본다.입금과 출금을 할 수 있는 Account 엔티티를 만들고 출금 계좌에서 돈을 출금해서 입금 계좌로 돈을 입금하는 것이다.package buckpal.account.domain;@AllArgsConstructor(access = AccessLevel.PRIVATE)public class Account {\t@Getter private final AccountId id;\t@Getter private final Money baselineBalance;\t@Getter private final ActivityWindow activityWindow;\tpublic static Account withoutId(\t\t\t\t\tMoney baselineBalance,\t\t\t\t\tActivityWindow activityWindow) {\t\treturn new Account(null, baselineBalance, activityWindow);\t}\tpublic static Account withId(\t\t\t\t\tAccountId accountId,\t\t\t\t\tMoney baselineBalance,\t\t\t\t\tActivityWindow activityWindow) {\t\treturn new Account(accountId, baselineBalance, activityWindow);\t}\tpublic Optional&lt;AccountId&gt; getId(){\t\treturn Optional.ofNullable(this.id);\t}\tpublic Money calculateBalance() {\t\treturn Money.add(\t\t\t\tthis.baselineBalance,\t\t\t\tthis.activityWindow.calculateBalance(this.id));\t}\tpublic boolean withdraw(Money money, AccountId targetAccountId) {\t\tif (!mayWithdraw(money)) {\t\t\treturn false;\t\t}\t\tActivity withdrawal = new Activity(\t\t\t\tthis.id,\t\t\t\tthis.id,\t\t\t\ttargetAccountId,\t\t\t\tLocalDateTime.now(),\t\t\t\tmoney);\t\tthis.activityWindow.addActivity(withdrawal);\t\treturn true;\t}\tprivate boolean mayWithdraw(Money money) {\t\treturn Money.add(\t\t\t\tthis.calculateBalance(),\t\t\t\tmoney.negate())\t\t\t\t.isPositiveOrZero();\t}\tpublic boolean deposit(Money money, AccountId sourceAccountId) {\t\tActivity deposit = new Activity(\t\t\t\tthis.id,\t\t\t\tsourceAccountId,\t\t\t\tthis.id,\t\t\t\tLocalDateTime.now(),\t\t\t\tmoney);\t\tthis.activityWindow.addActivity(deposit);\t\treturn true;\t}\t@Value\tpublic static class AccountId {\t\tprivate Long value;\t}}계좌에 대한 모든 입금과 출금은 Activity 엔티티에 포착 된다.한 계좌에 대한 모든 활동(activity)들은 항상 메모리에 한꺼번에 올리는 것은 현명한 방법이 아니기 때문에 Account 엔티티는 ActivityWindow 값 객체(value object)에서 포착한 지난 며칠 혹은 몇 주간의 범위에 해당하는 활동만 보유한다.Account 엔티티실제 계좌의 현재 스냅샷을 제공ActivityWindows한 계좌에 대한 모든 활동(activity)들을 항상 메모리에 한꺼번에 올리는 것은 현명하지 않으므로 지난 며칠 혹은 몇 주간의 범위 활동만 보유baselineBalance첫번째 활동 전의 잔고현재 총 잔고는 기준 잔고(baseBalance)에 활동 창의 모든 활동들의 잔고를 합한 값withdraw (입금), deposit(출금)새로운 활동을 활동창에 추가출금 전에는 잔고를 초과하는 금액을 출금할 수 없도록 비즈니스 규칙 검사유스케이스 둘러보기일반적으로 유스케이스는 아래와 같은 단계를 따른다. 입력을 받는다. 비즈니스 규칙을 검증한다. 모델 상태를 조작한다. 출력을 반환한다.유스케이스 코드가 도메인 로직에만 신경 써야 하고 입력 유효성 검증으로 오염되면 안된다. 그래서 입력 유효성 검증은 다른 곳에서 진행해야 한다.유스케이스는 비즈니스 규칙(business rule)을 검증할 책임이 있다. 그리고 도메인 엔티티와 이 책임을 공유한다.아래는 송금하기 유스케이스를 구현한 것이다.package buckpal.account.application.service;@RequiredArgsConstructor@Transactionalpublic class SendMoneyService implements SendMoneyUseCase {\tprivate final LoadAccountPort loadAccountPort;\tprivate final AccountLock accountLock;\tprivate final UpdateAccountStatePort updateAccountStatePort;\t@Override\tpublic boolean sendMoney(SendMoneyCommand command) {\t\t// TODO: 비즈니스 규칙 검증\t\t// TODO: 모델 상태 조작\t\t// TODO: 출력 값 반환\t}} 하나의 서비스가 하나의 유스케이스를 구현하고, 도메인 모델을 변경하고, 변경된 상태를 저장하기 위해 아웃고잉 포트를 호출한다.서비스는 인커밍 포트 인터페이스인 SendMoneyUseCase를 구현하고, 계좌를 불러오기 위해 아웃고잉 포트 인터페이스인 LoadAccountPort를 호출한다.그리고 데이터베이스의 계좌 상태를 업데이트하기 위해 UpdateAccountStatePort를 호출한다.입력 유효성 검증애플리케이션 계층해서 입력 유효성을 검증해야 하는 이유는, 그렇게 하지 않을 경우 애플리케이션 코어의 바깥쪽으로부터 유효하지 않은 입력값을 받게 되고, 모델의 상태를 해칠 수 있다.따라서 애플리케이션 계층에서 유효성을 검증해야 하지만 유스케이스 클래스에서는 하면 안된다.아래는 SendMoneyCommand클래스의 생성자 내에서 입력 유효성을 검증한다.@Getterpublic class SendMoneyCommand { private final AccountId sourceAccountId; private final AccountId targetAccountId; private final Money money; public SendMoneyCommand( AccountId sourceAccountId, AccountId targetAccountId, Money money) { this.sourceAccountId = sourceAccountId; this.targetAccountId = targetAccountId; this.money = money; requireNonNull(sourceAccountId); requireNonNull(targetAccountId); requireNonNull(money); requireGraterThan(money, 0); }}SendMoneyCommand는 유스케이스 API의 일부이기 때문에 인커밍 포트 패키지에 위치한다. 그러므로 유효성 검증이 애플리케이션의 코어(육각형 아키텍처의 육각형 내부)에 남아 있지만 신성한 유스케이스 코드를 오염시키지는 않는다.생성자의 힘클래스는 불변이기 때문에 생성자의 인자 리스트에는 클래스의 각 속성에 해당하는 파라미터들이 포함돼 있다.그뿐만 아니라 생성자가 파라미터의 유효성 검증까지 하고 있기 때문에 유효하지 않은 상태의 객체를 만드는 것은 불가능하다.빌더 패턴을 사용하면 긴 파라미터 리스트를 받아야하는 생성자를 private으로 만들고 빌더의 build() 메서드 내부에 생성자를 숨길 수 있다.new SendMoneyCommandBuilder()\t\t.sourceAccountId(new AccountId(41L))\t\t.targetAccountId(new AccountId(42L))\t\t// ... 다른 여러 필드를 초기화\t\t.build();유효성 검증 로직은 생성자에 그대로 둬서 빌더가 유효하지 않은 상태의 객체를 생성하지 못하도록 막을 수 있다.그러나 빌더 패턴의 경우 코드에 새로운 필드를 추가하는 것을 잊었을 경우, 컴파일러가 유효하지 않은 불변 객체를 만들려는 시도에 대해 경고해주지는 못한다.그래서 단위테스트 혹은 런타임에서 유효성 검증 로직이 동작해서 누락된 파라미터에 대한 에러를 던질 것이다.하지만 생성자를 직접 사용한다면 컴파일 에러에 따라 나머지 코드에 즉각 변경사항을 반영 할 수 있다.유스케이스마다 다른 입력 모델계좌 등록하기와 계좌 정보 업데이트하기의 경우 거의 똑같은 계좌 상세 정보가 필요하다.그래서 두 유스케이스에서 같은 입력 모델을 공유할 수도 있다.그러나 같은 입력 모델을 공유하게 된다면 계좌 등록하기에서는 소유자 ID에 null 값을 허용해야만 한다.불변 커맨드 객체의 필드에 대해서 null은 유효한 상태로 받아들이는 것은 그 자체로 코드 냄새(code smell)다.비즈니스 규칙 검증하기입력 유효성 검증과 비즈니스 규칙 검증은 분명히 유스케이스 로직의 일부이다.그런데 언제 입력 유효성을 검증하고 언제 비즈니스 규칙을 검증해야 할까??입력 유효성 검증은 구문상의(syntactical) 유효성으 검증하는 것이라고도 할 수 있고, 반면 비즈니스 규칙은 유스케이스 맥락 속에서 의미적인(semantical) 유효성을 검증하는 일이라고 할 수 있다.예를 들면 \"출금 계좌는 초과 출금되어서는 안된다\"는 모델의 현재 상태에 접근하여 출금, 입금 계좌의 존재 유무를 판단해야 하기 때문에 비즈니스 규칙이다.반대로 \"송금되는 금액은 0보다 커야한다.\"라는 규칙은 모델의 현재 상태와 상관없이 검증 될 수 있기 때문에 입력 유효성 검증이다.비즈니스 규칙의 가장 좋은 위치는 도메인 엔티티 안에 넣는 것이다.public class Account { // ... public boolean withdraw(Money money, AccountId targetAccountId) { if (!mayWithdraw(money)){ return false; } // ... }}만약 도메인 엔티티에서 비즈니스 규칙을 검증하기가 여의치 않다면 유스케이스 코드에서 도메인 엔티티를 사용하기 전에 해도 된다.@RequiredArgConstructor@Transactionalpublic class SendMoneyService implements SendMoneyUseCase { // ... @Override public boolean sendMoney(SendMoneyCommand command){ requireAccountExists(command.getSourceAccountId()); requireAccountExists(command.getTargetAccountId()); }}풍부한 도메인 모델 vs. 빈약한 도메인 모델DDD 철학을 따르는 풍부한 도메인 모델(rich domain model)과 빈약한 도메인 모델(anemic domain model)의 구현에 대해 자주 논의 되는 사항이다.풍부한 도메인 모델에서는 애플리케이션의 코어에 있는 엔티티에서 가능한 한 많은 도메인 로직이 구현된다. 엔티티들은 상태를 변경하는 메서드를 제공하고, 비즈니스 규칙에 맞는 유효한 변경만 허용한다.또한 많은 비즈니스 규칙이 유스케이스 구현체 대신 엔티티에 위치하게 된다.빈약한 도메인 모델에서는 엔티티 자체가 굉장히 얇다. 일반적으로 엔티티는 상태를 표현하는 필드와 이 값을 읽고 바꾸기 위한 getter, setter 메서드만 포함하고 어떤 도메인 로직도 가지고 있지 않는다.이 말은 즉, 도메인 로직인 유스케이스 클래스에 구현돼 있다는 것이다. 비즈니스 규칙을 검증하고, 엔티티의 상태를 바꾸고, 데이터베이스 저장을 담당하는 아웃고잉 포트에 엔티티를 전달할 책임 역시 유스케이스 클래스에 있다.### 유스케이스 마다 다른 출력 모델유스케이스가 할 일을 다하고 나면 호출자에게 무엇을 반환해야 할까?입력과 비슷하게 출력도 가능하면 각 유스케이스에 맞게 구체적일수록 좋다. 출력은 호출자에게 꼭 필요한 데이터만 들고 있어야 한다.송금하기 유스케이스 코드에서는 boolean 값 하나만 반환했다. 업데이트 된 Account를 통째로 반환하고 싶을 수도 있다.이부분은 정답이 없다. 그러나 유스케이스를 가능한 한 구체적으로 유지하기 위해서는 계속 질문해야 한다. 만약 의심스럽다면 가능한 한 적게 반환하자.유스케이스들 간에 같은 출력 모델을 공유하게 되면 유스케이스들도 강하게 결합된다. 단일 책임 원칙을 적용하고 모델을 분리해서 유지하는 것은 유스케이스의 결합을 제거하는 데 도움이 된다.같은 이유로 도메인 엔티티를 출력 모델로 사용하고 싶은 유혹도 견뎌야 한다.### 읽기 전용 유스케이스는 어떨까?계좌 잔고 보여주기 같은 특정 유스케이스의 경우에도 다른 유스케이스와 비슷한 방식으로 구현해야 한다.package buckpal.application.service;@RequiredArgsConstructorclass GetAccountBalanceService implements GetAccountBalanceQuery {\tprivate final LoadAccountPort loadAccountPort;\t@Override\tpublic Money getAccountBalance(AccountId, accountId){\t\treturn loadAccountPort.loadAccount(accoutId, LocalDateTime.now()).calculateBalance();\t}}쿼리 서비스는 유스케이스 서비스와 동일한 방식으로 동작한다. GetAccountBalanceQuery라는 인커밍 포트를 구현하고, 데이터베이스로부터 실제로 데이터를 로드하기 위해 LoadAccountPort라는 아웃고잉 포트를 호출한다.이처럼 읽기 전용 쿼리는 쓰기가 가능한 유스케이스(또는 커맨드)와 코드 상에서 명확하게 구분된다.이러한 방식은 CQS(Command-Query Separation)나 CQRS(Command-Query Responsibility Segregation) 같은 개념과 아주 잘 맞는다. CQRS란? 흔히 말하는 CRUD(Create, Read, Update, Delete)에서 CUD(Command)와 R(Query)를 구분하자는 것. CQRS의 장점 Read와 CUD 각각에 더 최적화된 Database 구성을 통해서 성능을 더 향상시킬 수 있다. Read와 CUD에서 필요한 데이터 형식이 다를 수 있고, 특히 Read는 aggregation(집계 함수) 등의 부가적인 attribute들이 Entity에 필요하게 될 수 있다. R과 CUD를 분리함으로써 R로 인해 Entity의 구조가 변경되는 것을 막을 수 있다. R과 CUD를 분리함으로써 과도하게 복잡한 모델을 덜 복합하게 만듦으로서 시스템 복잡도를 줄일 수 있다. 출처: Log.bluayer유지보수 가능한 소프트웨어를 만드는 데 어떻게 도움이 될까?이 책의 아키텍처에서는 도메인 로직을 우리가 윈하는 대로 구현할 수 있도록 허용하지만, 입력 출력 모델을 독립적으로 모델링한다면 원치 않는 부수효과를 피할 수 있다.물론 유스케이스 간에 모델을 공유하는 것보다는 더 많은 작업이 필요하다.꼼꼼한 입력 유효성 검증, 유스케이스별 입출력 모델은 지속 가능한 코드를 만드는 데 큰 도움이 된다." }, { "title": "3장. 코드 구성하기", "url": "/posts/MakeLearnCleanArchitecture_ch3/", "categories": "DDD, 만들면서 배우는 클린 아키텍처", "tags": "DDD, CleanArchitecture", "date": "2022-04-14 22:20:00 +0900", "snippet": "소개만들면서 배우는 클린 아키텍처 책을 읽고 정리하며 소감을 적는 포스트입니다.코드 구성하기코드를 보는 것만으로도 아키텍처가 파악 된다면 굉장히 좋을 것입니다.이번 포스트는 BuckPal 예제 코드를 구조화 하기 위해 육각형 아키텍처를 직접 레이아웃을 구성하도록 하겠습니다.아래는 사용자가 본인의 계좌에서 다른 계좌로 돈을 송금할 수 있는 송금하기 유스케이스를 살펴보겠습니다.계층으로 구성하기코드를 구조화하는 첫 번째 접근법은 계층을 이용하는 것입니다.buckpal├─────── domain│ ├──── Account│ ├──── Activity│ ├──── IAccountRepository│ └──── AccountService│├─────── persistence│ └──── AccountRepository│└─────── web └──── AccountController 계층으로 코드를 구성하면 기능적인 측면들이 섞이기 쉽다.웹 계층(web), 도메인 계층(domain), 영속성 계층(persistence)로 구분하였습니다.domain 패키지에 IAccountRepository 인터페이스를 추가하고, persistence 패키지에 AccountRepository 구현체를 둠으로써 의존성을 역전시켰습니다.그러나 적어도 세 가지 이유로 이 패키지 구조는 최적의 구조가 아닙니다.첫번째애플리케이션 기능 조각(functional slice)이나 특성(feature)을 구분 짓는 패키지 경계가 없습니다.추가적인 구조가 없다면, 아주 빠르게 서로 연관되지 않은 기능들끼리 예상하지 못한 부수효과를 일으킬 수 있는 클래스들의 엉망진창 묶음으로 변모할 가능성이 큽니다.두번째애플리케이션이 어떤 유스케이스들을 제공하는지 파악 할 수 없습니다.AccountService와 AccountController가 어떤 유스케이스를 가지고 있는지 소스를 보기 전에는 알수 없습니다.세번째패키지 구조를 통해 목표로하는 아키텍처를 파악할 수 없습니다.육각형 아키텍처를 따랐다고 하지만 어떤 기능이 웹 어댑터에서 호출되는지, 영속성 어댑터가 도메인 계층에 어떤 기능을 제공하는지 한눈에 알아볼 수 없다.기능으로 구성하기계층으로 구성하기 방법의 몇 가지 문제를 해결해보겠습니다.buckpal└─────── account ├──── Account ├──── AccountController ├──── IAccountRepository ├──── AccountRepository └──── SendMoneyService 기능을 기준으로 코드를 구성하면 기반 아키텍처가 명확하게 보이지 않는다.가장 본질적인 변경은 계좌와 관련된 모든 코드를 최상위의 account 패키지에 넣었다는 점이다 계층 패키지들도 없앴다.AccountService의 책임을 좁히기 위해 SendMoneyService로 클래스명을 바꿨다. 이제 송금하기 유스케이스를 구현한 코드는 클래스명만으로도 찾을 수 있게 됐다.애플리케이션의 기능을 코드를 통해 볼 수 있게 만드는 것을 가리켜 로버트 마틴이 소리치는 아키텍처(screaming architecture)라도 명명한 바 있다.그러나 기능에 의한 패키징 방식은 사실 계층에 의한 패키징 방식보다 아키텍처의 가시성을 훨씬 더 떨어뜨린다.어댑터를 알아볼 수 없고, 심지어 도메인 코드와 영속성 코드 간의 의존성을 역전시켜서 SendMoneyService가 AccountRepository 인테페이스만 알고 있고 구현체는 알 수 없도록 했음에도 도메인 코드가 실수로 영속성 코드에 의존하는 것을 막을 수 없다.아키텍처적으로 표현력 있는 패키지 구조육각형 아키텍처에서 구조적으로 핵심적인 요소는 엔티티, 유스케이스, 인커밍/아웃고잉 포트, 인커밍/아웃고잉(혹은 주도하거나 주도되는) 어댑터다.buckpal└─────── account ├──── adapter │ ├──── in │ │ └──── web │ │ └──── AccountController │ │ │ └──── out │ └──── persistence │ ├──── AccountPersistenceAdapter │ └──── SpringDataAccountRepository │ ├──── domain │ ├──── Account │ └──── Activity │ └──── application ├──── SendMoneyService └──── port ├──── in │ └──── SendMoneyUseCase └──── out ├──── LoadAccountPort └──── UpdateAccountStatePort 아키텍처적으로 표현력 있는 패키지 구조에서는 각 아키텍처 요소들에 정해진 위치가 있다.구조의 각 요소들은 패키지 하나씩에 직접 매핑된다. domain 도메인 모델 (Account, Activity) application 도메인 모델을 둘러싼 서비스 계층 (SendMoneyService) 인커밍 포트 인터페이스 (SendMoneyUseCase) 아웃고잉 포트 인터페이스 (LoadAccountPort, UpdateAccountStatePort) adapter 어플리케이션 계층의 인커밍 포트를 호출하는 인커밍 어댑터 (AccountController) 어플리케이션 계층의 아웃고잉 포트에 대한 구현을 제공하는 아웃고잉 어댑터 (AccountPersistenceAdapter, SpringDataAccountRepository) 이러한 패키지 구조는 다양한 장점이 있는데 첫번째로 아키텍처-코드 갭(architecture-code gap) 혹은 모델-코드 갭(model-code gap)을 효과적으로 다룰 수 있다.또한 패키지간의 접근을 제어 할 수 있다.adpater 패키지의 모든 클래스는 application 패키지 내의 포트 인터페이스를 통해 외부에서 호출되기 때문에 dapter는 모두 package-private 접근 수준으로 둬도 된다.그러므로 어플리케이션 계층에서 어댑터로 향하는 우발적 의존성은 없어진다.하지만 application 패키지와 domain 패키지늬 일부 클래스는 의도적으로 어댑터에서 접근 가능해야 하므로 public으로 지정해야 한다.또한 도메인 클래스는 서비스, 그리고 잠재적으로 어댑터에서도 접근 가능하도록 public이여야 하며 서비스는 인커밍 포트 인터페이스 뒤에 숨을 수 있기 때문에 public일 필요는 없다.의존성 주입의 역할클린 아키텍처의 본질적인 요건은 어플리케이션이 인커밍/아웃고잉 어댑터에 의존성을 갖지 않아야 한다.육각형 아키텍처에서 는 애플리케이션 계층에 인터페이스를 만들고 어댑터에 해당 인터페이스 구현체를 두는데 여기서 인터페이스가 포트 역할을 하게 된다.그런데 인터페이스를 구현한 객체를 누가 애플리케이션에 제공해야 할까?? 애플리케이션 계층에 어댑터에 대한 의존성을 추가하고 싶지 않을 수 있다.이럴 때 의존성 주입을 활용 할 수 있다. 모든 계층에 의존성을 가진 중립적인 컴포넌트를 하나 도입하는 것이다.이 컴포넌트는 아키텍처를 구성하는 대부분의 클래스를 초기화하는 역할을 한다. 웹 컨트롤러가 서비스에 의해 구현된 인커밍 포트를 호출한다. 서비스는 어댑터에 의해 구현된 아웃고잉 포트를 호출한다.위 그림에서 중립적인 의존성 주입 컴포넌트는 AccountController, SendMoneyService, AccountPersistenceAdapter 클래스의 인스턴스를 만들어 주입하게 된다.그렇게 되면 Account-Contoller는 SendMoneyUseCase 인터페이스만 알면 되기 때문에 자신이 어떤 구현체의 객체를 가지게 되는지 몰라도 된다." }, { "title": "2장. 의존성 역전하기", "url": "/posts/MakeLearnCleanArchitecture_ch2/", "categories": "DDD, 만들면서 배우는 클린 아키텍처", "tags": "DDD, CleanArchitecture", "date": "2022-04-13 15:20:00 +0900", "snippet": "소개만들면서 배우는 클린 아키텍처 책을 읽고 정리하며 소감을 적는 포스트입니다.의존성 역전하기단일 책임 원칙(SRP, Single Responsibility Principle)우리가 잘 알고 있는 정의는 하나의 컴포넌트는 오로지 한 가지 일만 해야하고, 그것을 올바르게 수행해야 한다.하지만 실제 정의는 컴포넌트를 변경하는 이유는 오직 하나뿐이어야 한다.만약 컴포넌트를 변경할 이유가 한 가지라면 우리가 어떤 다른 이유로 소프트웨어를 변경하더라도 이 컴포넌트에 대해서는 전혀 신경 쓸 필요가 없다. 어떤 컴포넌트의 의존성 각각이 이 컴포넌트를 변경하는 이유 하나씩에 해당 된다. 위 그림에서 점선 화살표는 전이 의존성(transitive dependency)이다.E는 의존하는 것이 전혀 없지만 그에 비해 A의 경우는 B, C, 전의 의존 E, D를 가지고 있다.A는 모든 컴포너트에 의존하기 때문에 다른 어떤 컴포넌트가 변경 되면 같이 변경되어야 한다.많은 코드가 단일 책임 원칙을 위반하기 때문에 시간이 갈수록 변경하기가 더 어려워진다.부수효과에 관한 이야기대부분 코드의 한 영역을 변경했더니 다른 영역에서 부수효과(Side Effect)가 나타나기 일쑤이다.의존성 역전 원칙계층형 아키텍처에서 계층 간 의존성은 항상 다음 계층인 아래 방향을 가리킨다. 단일 책임 원칙을 고수준에서 적용할 때 상위 계층들이 하위 계층들에 비해 견경할 이유가 더 많다는 것을 알 수 있다.영속성 계층을 변경할 때마다 잠재적으로 도메인 계층도 변경해야 한다.그러나 도메인 코드는 애플리케이션에서 가장 중요한 코드이다. 영속성 코드가 바뀐다고 해서 도메인 코드까지 바꾸고 싶지는 않다.이때 의존성 역전 원칙(DIP, Dependency Inversion Principle)가 답을 알려준다. 코드상의 어떤 의존성이드 그 방향을 바꿀 수(역전시킬 수)있다.도메인 코드와 영속성 코드 간의 의존성을 역전시켜서 영속성 코드가 도메인 코드에 의존하고, 도메인 코드를 변경할 이유를 줄여보자위 그림에서 도메인 계층에서 영속성 계층과 상호작용하는 서비스가 하나 있다.엔티티는 도메인 객체를 표현하고 도메인 코드는 이 엔티티들의 상태를 변경하는 일을 중심으로 하기 때문에 엔티티를 먼저 도메인 계층으로 올린다.여기서 엔티티가 도메인 계층으로 올라갔기 때문에 두 계층 사이에 순환 의존성(Circular dependency)가 생기게 됩니다.이 부분이 바로 DIP를 적용하는 부분이다. 도메인 계층에 레포지토리에 대한 인터페이스를 만들고, 실제 리포지토리는 영속성 계층에서 구현하게 하는 것이다. 도메인 계층에 인터페이스를 도입함으로써 의존성을 역전시킬 수 있고, 그 덕분에 영속성 계층이 도메인 계층에 의존하게 된다.도메인 계층에 리포지토리 인터페이스를 만들고, 실제 리포지토리는 영속성 계층에서 구현하게 하는 것이다.클린 아키텍처 클린 아키텍처에서 모든 의존성은 도메인 로직을 향해 안쪽 방향으로 향한다.로버튼 C.마틴은 클린 아키텍처에서는 설계까 비즈니스 규칙의 테스트를 용이하게 하고, 비즈니스 규칙은 프레임웤, 데이터베이스, UI 기술, 그 밖의 외부 애플리케이션이나 인터페이스로부터 독립적일 수 있다고 이야기 했습니다.이는 도메인 코드가 바깥으로 향하는 어떤 의존성도 없어야 함을 의미하고 대신 의존성 역전 원칙의 도움으로 모든 의존성이 도메인 코드를 향하고 있어야 합니다. 클린 아키텍처 계열에서 도메인 계층과 애플리케이션 계층을 합쳐 application core라고 부릅니다.아키텍처의 코어(core)에는 주변 유스케이스에서 접근하는 도메인 엔티티들이 있다. 유스케이스는 앞에서 서비스라고 불렀던 것들인데, 단일 책임을 갖기 위해 좀 더 세분화돼 있다. 이를 통해 이전에 이야기 했던 넓은 서비스 문제를 피할 수 있습니다.클린 아키텍처는 도메인 계층이 영속성이나 UI같은 외부 계층과 철저하게 분리돼야 하므로 애플리케이션의 엔티티에 대한 모델을 각 계층에서 유지보수 해야한다.가령 영속성 계층에서 ORM(object-relational mapping) 프레임워크를 사용하게 된다면 도메인 계층은 영속성 계층을 모르기 때문에 두 계층에서 각각 엔티티를 따로 만들어야 한다. 즉, 도메인 계층과 영속성 계층이 데이터를 주고 받을 때, 두 엔티티를 서로 변환해서 사용해야 한다.육각형 아키텍처(헥사고날 아키텍처) 육각형 아키텍처는 애플리케이션 코어가 각 어댑터와 상호작용하기 위해 특정 포트를 제공하기 때문에 포트와 어댑터(ports-and-adapters) 아키텍처라고도 불리다.애플리케이션 코어가 육각형으로 표현되어 이 아키텍처의 이름이 되었지만 육각형이나 팔각형이나 무엇이들 상관 없다.육각형 안에는 도메인 엔티티와 이와 상호작용하는 유스케이스들이 있다. 육각형에서 외부로 향하는 의존성이 없기 때문에 마틴이 클린 아키텍처에서 제시한 의존성 규직이 그대로 적용 된다.애플리케이션 코어와 어댑터들 간의 통신이 가능하려면 애플리케이션 코어가 각각의 포트를 제공해야 한다. 주도하는 어댑터(driving adapter)에게는 그러한 포트가 코어에 있는 유스케이스 클래스들에 의해 구현되고 호출되는 인터페이스가 될 것이고, 주도되는 어댑터(driven adapter)에게는 그러한 포트가 어댑터에 의해 구현되고 코어에 의해 호출 되는 인터페이스가 될 것이다." }, { "title": "1장. 계층형 아키텍처의 문제는 무엇일까?", "url": "/posts/MakeLearnCleanArchitecture_ch1/", "categories": "DDD, 만들면서 배우는 클린 아키텍처", "tags": "DDD, CleanArchitecture", "date": "2022-04-12 22:15:00 +0900", "snippet": "소개만들면서 배우는 클린 아키텍처 책을 읽고 정리하며 소감을 적는 포스트입니다.계층형 아키텍처의 문제점 웹 계층, 도메인 계층, 영속성 계층으로 구성된 전통적인 웹 애플리케이션 구조계층형 아키텍처는 맨 위의 웹 계층에서 요청을 받아 도메인 계층에 있는 서비스로 요청을 보낸다.서비스에서는 필요한 비즈니스 로직을 수행하고, 도메인 엔티티의 현재 상태를 조회하거나 변경하기 위해 영속성 계층의 컴포넌트를 호출한다.계층을 잘 이해하고 구성한다면 다른 계층에 영향을 주지 않고 독립적으로 관리가 가능하다.하지만 계층형 아키텍처는 코드에 나쁜 습관들이 스며들기 쉽게 만들고 시간이 지날 수록 소프트웨어를 점점 더 변경하기 어렵게 만드는 수많은 허점들을 노출한다.데이터베이스 주도 설계를 유도한다.전통적인 계층형 아키텍처의 토대는 데이터베이스이다.하지만 우리는 상태(State)가 아니라 행동(behavior)을 중심으로 모델링을 한다. 어떤 어플리케이션이든 상태가 중요한 요소이긴 하지만 행동이 상태를 바꾸는 주체이기 때문에 행동이 비즈니스를 이끌어 나간다.그동안 만들어 본 유스케이스를 떠올려보면 도메인 로직보다는 데이터베이스의 구조를 먼저 생각하고, 이를 토대로 도메인 로직을 구현했을 것이다.전통적인 계층형 아키텍처에서는 합리적인 방법이지만 비즈니스 관점에서는 전혀 맞지 않는 방법이다.그래서 다른 무엇보다 도메인 로직을 먼저 만들어야 한다. 그래야 로직을 제대로 이해했는지 확인할 수 있다.데이터베이스 중심적인 아키텍처를 만드는 가장 큰 원인은 ORM(object-relational mapping)이다. 도메인 계층에서 데이터베이스 엔티티를 사용하는 것은 영속성 계층과의 강한 결합을 유발한다.위 그림과 같이 ORM에 의해 관리되는 엔티티들은 일반적으로 영속성 계층에 둔다.계층은 아래 방향으로만 접근 가능하기 때문에 도메인 계층에서는 엔티티에 접근 할 수 있다. 그렇게 되면 영속성 계층과 도메인 계층 사이에 강한 결합이 생긴다.이는 도메인 로직을 구현하면서 즉시로딩(eager loading)/지연로딩(lazy loading), 데이터베이스 트랜잭션, 캐시 플러시(flush) 등등 영속성 계층과 관련된 작업을 계속해야만 한다.지름길을 택하기 쉬워진다.계층형 아키텍처는 같은 계층에 있는 컴포넌트나 아래에 있는 계층에만 접근이 가능하다. 이 규칙 외의 다른 규칙은 강제하지 않는다. 그래서 상위 계층에 위치한 컴포넌트에 접근해야 한다면 간단하게 컴포넌트를 아래로 내려버리는 경우가 생긴다. 영속성 계층에서는 모든 것에 접근 가능하기 때문에 시간이 지나면서 점점 비대해진다.영속성 계층은 수년에 걸친 개발과 유지보수로 위 그림과 같이 될 가능성이 많다.테스트하기 어려워 진다.계층형 아키텍처에서 나타나는 일반적인 현상은 계층을 건너뛰는 것이다.엔티티의 필드를 단 하나만 조작하면 되는 경우에 웹 계층에서 바로 영속성 계층에 접근하면 도메인 계층을 건드릴 필요가 없지 않을까? 도메인 계층을 건너뛰는 것은 도메인 로직을 코드 여기저기에 흩어지게 만든다.위와 같이 계층을 무시하게 되면 두가지 문제가 생긴다.첫 번째는 단 하나의 필드를 조작하는 것에 불과하더라도 도메인 로직을 웹 계층에 구현하게 된다는 것이다.유스케이스가 확장 된다면 더 많은 도메인 로직을 웹 계층에 추가해서 핵심 도메인 로직들이 퍼저나갈 확률이 높다.두번째 문제는 웹 계층 테스트에서 도메인 계층뿐만 아니라 영속성 계층도 모킹(mocking) 해야 한다는 것ㅇ디ㅏ.이렇게 되면 단위 테스트의 복잡도가 올라가게 된다.유스케이스를 숨긴다.개발자는 새로운 유스케이스를 구현하는 새로운 코드를 짜는 것을 선호한다. 그러나 새로운 코드를 짜는 시간보다 기존 코드를 바꾸는데 더 많은 시간을 쓰게 된다.계층형 아키텍처에서 도메인 로직이 여러 계층에 흩어지게 되면 새로운 기능을 추가할 적당한 위치를 찾는 일이 어려워 진다. 넓은 서비스는 코드 상에서 특정 유스케이스를 찾는 것을 어렵게 만든다.넓은 서비스는 영속성 계층에 많은 의존성을 갖게 되고, 다시 웹 계층의 많은 컴포넌트가 이 서비스에 의존하게 된다.동시 작업이 어려워 진다. “지연되는 소프트웨어 프로직트에 인력을 더하는 것은 개발을 늦출 뿐이다.” «맨머스 미신: 소프트웨어 공학에 관한 에세이», 프레더릭 P.브룩스모든 상황에서 50명 정도 되는 큰 규모의 개발팀이 10명 정도 되는 작은 규모의 개발팀보다 5배 빠를 거라고 기대할 수는 없다. 하지만 적절한 규모에서는 인원을 더 투입하면 더 빨리진다고 기대 할 수 있다.이러한 기대를 충족하기 위해서는 아키텍처가 동시 작업을 지원해야 하지만 계층형 아키텍처는 이런 측면에선 도움이 되지 않는다.계층형 아키텍처는 모든 것이 영속성 계층 위에 만들어지기 때문에 영속성 계층을 먼저 개발해야 한다. 그렇기 때문에 특정 기능을 동시에 한명의 개발자만 작업이 가능하다." }, { "title": ".NET Serilog 사용법", "url": "/posts/Serilog/", "categories": ".NET", "tags": ".NET, C#, Serilog", "date": "2022-04-12 01:00:00 +0900", "snippet": "Seriloghttps://serilog.net/아래의 예제는 .NET Worker Service 프로젝트에서 사용하는 방법에 대해 소개하도록 하겠습니다.Serilog란?파일, 콘솔 등의 다양한 저장소의 로깅을 지원합니다. 그리고 설정하기 쉬운 API로 되어 있으며 다양한 플랫폼에 이식이 가능합니다.또한 구조화 된 로깅으로 다른 플랫폼에서 읽기 쉽도록 로깅을 생성할 수 있습니다.사용법Worker Service를 먼저 생성합니다.그리고 Nuget Package에서 Serilog.AspNetCore를 설치합니다.Program.cs에 아래와 같이 코드를 추가합니다.using Collector.Service;using Serilog;IHost host = Host.CreateDefaultBuilder(args) .UseSerilog() .ConfigureServices((hostContext, services) =&gt; { Log.Logger = new LoggerConfiguration().ReadFrom.Configuration(hostContext.Configuration).CreateLogger(); }) .ConfigureServices(services =&gt; { services.AddHostedService&lt;Worker&gt;(); }) .Build();await host.RunAsync();.UseSerilog()로 Serilog를 사용한다고 정의합니다.ConfigureServices에서 (hostContext, services)를 가져와 Log Config의 정보를 셋팅 합니다.hostContext.Configuration에는 아래와 같은 json파일을 자동으로 읽어 Configuration 정보를 구성합니다.우리는 여기서 appsettings.json의 정보를 가져와 사용할 예정이기 때문에 appsettings.json에 아래와 같이 설정합니다.{ \"Logging\": { \"LogLevel\": { \"Default\": \"Information\", \"Microsoft.Hosting.Lifetime\": \"Information\" } }, \"Serilog\": { \"MinimumLevel\": \"Debug\", \"Enrich\": [ \"WithMachineName\" ], \"WriteTo\": [ { \"Name\": \"Console\", \"Args\": { \"theme\": \"Serilog.Sinks.SystemConsole.Themes.AnsiConsoleTheme::Code, Serilog.Sinks.Console\", \"outputTemplate\": \"[{Timestamp:HH:mm:ss} {Level:u3}] {Message:lj} &lt;s:{SourceContext}&gt;{NewLine}{Exception}\" } }, { \"Name\": \"File\", \"Args\": { \"path\": \"logs/log.txt\", \"rollingInterval\": \"Day\", \"retainedFileCountLimit\": 10, \"outputTenokate\": \"{Timestamp} [{Level}] - Message: {Message}{NewLine}{Exception}\" } } ] }}Console과 File 모두 Log를 출력하도록 하여 outputTemplate으로 로그의 구조를 정의합니다.실행시키기 되면 아래와 같이 Console과 파일 모두 생성되어 Log가 기록되는 것을 확인 할 수 있습니다." }, { "title": "PostgreSQL Docker DB 초기화", "url": "/posts/Postgre_Init/", "categories": "Database, PostgreSQL", "tags": "Docker, PostgreSQL", "date": "2022-04-07 12:00:00 +0900", "snippet": "소개요즘은 간단한 프로젝트나 테스트를 하기 위해 Docker를 사용하여 Database를 띄우는 경우가 많습니다.그럴때 마다 백업 된 데이터를 다시 넣어주거나 데이터를 일일이 다시 넣어주는 일은 매우 귀찮은 일입니다.Database를 가장 맨 처음 딱 한번만 데이터를 넣고 싶을 때 사용하는 방법에 대해 알아보도록 하겠습니다.Init Data 준비CREATE TABLE USERS( index SERIAL PRIMARY KEY, id VARCHAR NOT NULL, name VARCHAR NOT NULL, email VARCHAR NOT NULL );INSERT INTO USERS(index, id, name, email)VALUES(DEFAULT, 'hgsp', '박혁거세', 'ysp@google.com');INSERT INTO USERS(index, id, name, email)VALUES(DEFAULT, 'ssl', '이순신', 'shl@google.com');INSERT INTO USERS(index, id, name, email)VALUES(DEFAULT, 'skl', '이성계', 'gwl@google.com');INSERT INTO USERS(index, id, name, email)VALUES(DEFAULT, 'jj', '조조', 'bhj@google.com');INSERT INTO USERS(index, id, name, email)VALUES(DEFAULT, 'ska', '안성기', 'sya@google.com');INSERT INTO USERS(index, id, name, email)VALUES(DEFAULT, 'jjk', '김좌진', 'syk@google.com');위 데이터는 USERS라는 테이블을 만들고 사람들의 id, name, email을 넣어주는 sql 문입니다.docker-compose 파일 준비services: postgres: image: postgres:13 container_name: postgres environment: - POSTGRES_PASSWORD=passwd ports: - '5432:5432' volumes: - ./init_data/createdb.sql:/docker-entrypoint-initdb.d/createdb.sql pgadmin: container_name: pgadmin image: dpage/pgadmin4 ports: - 8088:80 environment: - PGADMIN_DEFAULT_EMAIL=my@mail.com - PGADMIN_DEFAULT_PASSWORD=passwdPOSTGRES_PASSWOR는 postgresql에서 사용 될 암호입니다.volumes에 보시면 컨테이너의 docker-entrypoint-inidb.d라는 곳에 우리가 작성한 sql파일을 넣게 되는데 postgresql은 생성 되는 최초 한번만 저기의 파일을 읽어 사용하게 됩니다.pgadmin의 경우 web으로 된 postgresql의 editor 입니다.실행docker-compose 파일이 있는 곳에서 아래와 같이 명령어를 입력하여줍니다.$ docker-compose uppostgres | The files belonging to this database system will be owned by user \"postgres\".postgres | This user must also own the server process.postgres |postgres | The database cluster will be initialized with locale \"en_US.utf8\".postgres | The default database encoding has accordingly been set to \"UTF8\".postgres | The default text search configuration will be set to \"english\".postgres |postgres | Data page checksums are disabled.postgres |postgres | fixing permissions on existing directory /var/lib/postgresql/data ... okpostgres | creating subdirectories ... okpostgres | selecting dynamic shared memory implementation ... posixpostgres | selecting default max_connections ... 100postgres | selecting default shared_buffers ... 128MBpostgres | selecting default time zone ... Etc/UTCpostgres | creating configuration files ... okpostgres | running bootstrap script ... okpostgres | performing post-bootstrap initialization ... okpostgres | syncing data to disk ... initdb: warning: enabling \"trust\" authentication for local connectionspostgres | You can change this by editing pg_hba.conf or using the option -A, orpostgres | --auth-local and --auth-host, the next time you run initdb........pgadmin | NOTE: Configuring authentication for SERVER mode.pgadmin |pgadmin | [2022-04-06 12:44:52 +0000] [1] [INFO] Starting gunicorn 20.1.0pgadmin | [2022-04-06 12:44:52 +0000] [1] [INFO] Listening at: http://[::]:80 (1)pgadmin | [2022-04-06 12:44:52 +0000] [1] [INFO] Using worker: gthreadpgadmin | [2022-04-06 12:44:52 +0000] [88] [INFO] Booting worker with pid: 88이미지가 없다면 자동으로 다운받게 되고 컨테이너가 실행되게 됩니다.위와 같이 postgres와 pgadmin이 정상적으로 실행 된것을 볼 수 있습니다.Postgre 콘솔 접속$ docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES4ef0ee78dad7 dpage/pgadmin4 \"/entrypoint.sh\" 2 minutes ago Up 2 minutes 443/tcp, 0.0.0.0:8088-&gt;80/tcp pgadminc96f8fa62108 postgres:13 \"docker-entrypoint.s…\" 2 minutes ago Up 2 minutes 0.0.0.0:5432-&gt;5432/tcp postgres저는 postgre의 CONTAINER ID가 c96f8fa62108이기 때문에 아래와 같이 명령어를 입력하여 접속하도록 하겠습니다.$ docker exec -it c96 psql -U postgrespostgres=# SELECT * FROM USERS; index | id | name | email-------+------+----------+---------------- 1 | hgsp | 박혁거세 | ysp@google.com 2 | ssl | 이순신 | shl@google.com 3 | skl | 이성계 | gwl@google.com 4 | jj | 조조 | bhj@google.com 5 | ska | 안성기 | sya@google.com 6 | jjk | 김좌진 | syk@google.compgAdmin 접속$ docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES4ef0ee78dad7 dpage/pgadmin4 \"/entrypoint.sh\" 7 minutes ago Up 7 minutes 443/tcp, 0.0.0.0:8088-&gt;80/tcp pgadminc96f8fa62108 postgres:13 \"docker-entrypoint.s…\" 7 minutes ago Up 7 minutes 0.0.0.0:5432-&gt;5432/tcp postgrespgadmin의 포트가 8088이 포워딩 되어 있는 것을 볼 수 있습니다.http://localhost:8088위 주소로 접속하게 되면 아래와 같은 Login화면을 볼 수 있습니다.docker-compose에서 설정한 email과 password로 접속하면 됩니다.Add New Server를 통해 postgre의 서버를 설정하도록 하겠습니다.Connection에서 Host name/address 부분은 docker-compose에 적혀있는 서비스 명을 적으면 됩니다.docker-compose를 사용하여 띄웠기 때문에 Docker 내부의 서비스명으로 도메인이 자동으로 생성됩니다." }, { "title": "Stream, FileStream, BufferedStream, MemoryStream", "url": "/posts/Stream/", "categories": ".NET", "tags": ".NET, C#, Stream", "date": "2022-04-04 13:30:00 +0900", "snippet": "Stream이란?프로그램을 개발하다보면 Stream을 사용하는 일이 많습니다.Java와 .NET 에서는 입풀력 작업을 Stream이란 개념을 통해서 추상화하여 사용합니다.대표적으로 파일을 읽고 쓸 때 많이 사용하는데, 자세히 알아보도록 하겠습니다.먼저 사전적인 의미를 보자면 아래와 같습니다. A stream is a small narrow river. A stream of smoke, air, or liquid is a narrow moving mass of it. A stream of vehicles or people is a long moving line of them.(액체 등의) 좁은 흐름 우리 말로하면 작은 시냇물 같은 의미를 가지고 있습니다.즉, 프로그램에서 Stream이란 데이터가 끊기지 않고 연속적으로 작은 단위로 주고 받는 것을 말합니다.Stream은 일반적으로 대용량 파일에서 데이터를 읽고 쓸 때 사용됩니다. 대용량의 파일을 작은 단위로 쪼개어 데이터를 전송하는데 큰 파일을 한번에 읽거나 쓰는 것은 시스템에 큰 부담을 줍니다.만약 100MB의 파일을 한번에 읽게 된다면 프로그램을 중단되거나 불안정하게 동작할 수 잇습니다.Stream ReaderStream Reader는 파일에서 데이터를 읽는 데 사용이 됩니다. 파일의 데이터를 먼저 Stream에 읽은 후 프로그램이 Stream의 데이터를 읽게 됩니다.예를 들어 C#에서 Example.txt라는 파일을 읽을 때는 아래와 같이 코드를 작성합니다.var path = @\"D:\\Example.txt\";using(StreamReader sr = File.OpenText(path)){ string s = \"\"; while((s = sr.ReadLine()) != null) { Console.WriteLine(s); }}코드 설명 StreamReader의 대상이 될 파일 경로를 설정합니다. OpenText는 읽기 전용으로 파일을 읽을 때 사용됩니다. 그런 후 파일에서 모든 데이터를 읽는데 사용 될 임시변수 s를 선언합니다. StreamReader의 ReadLine을 통해 Stream Buffer에서 한줄 한줄 읽게 되는데 ReadLine을 할 때마다 파일에서 Stream으로 기록 됩니다. 그리고 s 변수로 데이터가 쓰여집니다.Stream WriteStream Writer는 Stream을 사용하여 파일에 데이터를 쓰기 작업 할 때 사용됩니다. 프로그램에서 데이터를 먼저 Stream에 기록 후 Stream은 파일에 데이터를 쓰게 됩니다.var path = @\"D:\\Example.txt\";using(StreamWriter sw = File.AppendText(path)){ sw.WriteLine(\"AAAA\"); sw.WriteLine(\"BBBB\"); sw.WriteLine(\"CCCC\"); sw.Close();}코드 설명 StreamWrite의 대상이 될 파일 경로를 설정합니다. ApendText는 파일에 라인을 추가 할 때 사용합니다. 그런 후 WriteLine을 통해 Stream에 쓰기작업을 합니다. 이 때 파일에 한줄 한줄 쓰기 작업이 진행됩니다. 작업이 끝나면 StreamWriter를 Close 해줘야 합니다.FileStreamStream은 파일, 네트워크 연결, 메로리, 파이프, 콘솔, 디버그 및 추적 수신기 등 다른 유형의 데이터 소스에 읽기/쓰기용으로 존재하는 합니다.반면 FileStream은 Stream을 상속 받았으며 byte array를 사용하여 파일을 읽고 쓰는 것에만 사용되는 Stream입니다.using System.Text;var path = @\"D:\\Example.txt\";using (FileStream fs = new FileStream(path, FileMode.OpenOrCreate)){ string str = \"AAAA\"; byte[] writeBuffer = Encoding.UTF8.GetBytes(str); fs.Write(writeBuffer, 0, writeBuffer.Length); fs.Close();}코드 설명 FileStream을 선언하고 파일을 Open및 Create 모드로 생성합니다. str을 byte Array로 변경합니다. Write(buffer, offset, count)로 byte array에서 어디서 부터 얼만큼 기록을 할 것인지 지정합니다. 사용이 끝나 FileStream을 Close해 줍니다.BufferedStreamBufferedStream는 입출력시 Buffer를 두어 입출력 횟수를 줄여 성능을 향상 시킬 때 사용됩니다.FileStream의 경우 Byte 단위로 데이터를 읽고 쓰기 때문에 바이트당 read/write 횟수가 발생하기 때문에 오버헤드가 발생합니다.기본적인 Buffer 사이즈는 (1024*4) 바이트 입니다.Buffer의 크기가 128KB일 경우 버퍼링 된 작업은 버퍼링 되지 않은 작업보다 10~20% 정도 속도가 빠릅니다.BufferedStream(Stream stream);BufferedStream(Stream strea, int buffersize);using System.Text;var path = @\"D:\\Example.txt\";using (FileStream fs = new FileStream(path, FileMode.OpenOrCreate)){ using(BufferedStream bs = new BufferedStream(fs)) { string str = \"AAAA\"; byte[] writeBuffer = Encoding.UTF8.GetBytes(str); bs.Write(writeBuffer, 0, writeBuffer.Length); bs.Close(); } }코드설명 FileStream을 사용하여 파일을 Open or Create 모드로 선언합니다. BufferedStream을 선언하고 FileStream을 지정하여 줍니다. AAAA를 byte[]로 변환합니다. bs.Write를 사용하여 파일에 쓰기 작업을 수행합니다.AAAA를 byte Array로 변환하게 되면 4개의 배열이 생성됩니다.FileStream을 사용하여 Write 작업을 하여 File을 4번 쓰기작업을 하게 됩니다.하지만 BufferedStream을 사용하면 1번의 쓰기 작업만으로 끝나게 됩니다.MemoryStreamMemoryStream은 디스크나 네티워크 연결 대신 메모리를 백업 저장소로 사용 하는 Stream입니다.메모리에 바이트 데이터를 순서대로 읽고 쓰는 작업을 수행하는 클래스다. 이를 이용하면 데이터를 메모리에 직렬화/역직렬화 하는 것이 가능하다.MemoryStream을 사용하게 되면 프로그램의 임시 버퍼 및 파일의 필요성을 줄일 수 있습니다. 멤버 설명 Capacity 이 스트림에 할당된 바이트 수를 가져오거나 설정합니다. GetBuffer 스트림에 할당된 내용을 바이트 배열로 반환합니다. ToArray 전체 문자열의 내용을 바이트 배열로 반환합니다. WriteTo MemoryStream의 모든 내용을 다른 문자열 파생 타입에 출력합니다. using (System.IO.MemoryStream ms = new System.IO.MemoryStream()){ System.IO.StreamWriter sw = new System.IO.StreamWriter(ms, System.Text.Encoding.UTF8); sw.WriteLine(\"AAAA\"); sw.WriteLine(\"BBBB\"); sw.WriteLine(\"CCCC\"); sw.Flush(); sw.Close(); sw.Dispose();}" }, { "title": "Docker Container Exit Code", "url": "/posts/Container-ExitCode/", "categories": "Docker", "tags": "Docker", "date": "2022-04-01 01:15:00 +0900", "snippet": "소개이번 포스팅에서는 Docker Container의 Exit Code에 대해 알아봅니다.Docker를 사용하다보면 예기치 않게 Container가 내려가거나 내려가 있어도 무슨 원인으로 내려갔는지 모를 경우가 많습니다.이때 Exit Code를 확인하여 원인을 알아 볼 수 있습니다.Docker 종료 된 Container 목록 확인&gt; docker ps -a --filter \"status=exited\"docker ps -a로 모든 컨테이너 목록을 가져오고 --filter 옵션으로 exited 된 컨테이너 목록만 가져 올 수 있습니다.Exit Code 종류Exited (0)0 코드는 가장 일반적인 경우로, 컨테이너 내부의 init process가 자신의 역할을 끝낸 후 정상적으로 종료 되었을 때, 또는 docker stop 명령어로 종료 시켰을 때 해당됩니다.Exited (125)125 코드는 docker run 명령어의 실패로 실제 docker container가 띄워지지 않았을 때 발생합니다.Exited (126)126 코드는 Container 내부의 명령어를 실행하지 못하는 경우 발생합니다.권한, 접근, 파일, 옵션 등등이 발생 가능합니다.Exited (127)127 코드는 Container 내부의 명령어 자체가 없을 경우 발생합니다.Exited (128 + n)128 + n는 Linux Signal에 의해 종료 되었을 때 발생합니다.n의 의미즌 Linux Signal Number를 의미합니다.Exited (130)128 + 2 코드는 컨테이너가 실행되었을 때, 인터럽트 루틴(Control + C) 에 의해 init 프로세스가 전달된 경우이다. 인터럽트 신호인 SIGINT의 코드가 2이므로 종료 코드는 130이 된다. 사실상 개발자가 의도적으로 컨테이너를 종료시키는 경우가 아니면 거의 볼 수 없다.mysql과 같은 컨테이너를 interactive하게 (-it) 생성하고 Control + C를 연속적으로 입력하면 이 코드를 인위적으로 만들어 낼 수 있다.Exited (137)128 + 9로 Linux Signal num 9인 SIGKILL이 발생하였을 경우입니다. 자주 사용하는 kill -9로 인해 종료되었을 경우를 의미합니다. docker kill, docker rm -f를 사용했을때 발생 가능합니다.Exited (143)128 + 15로 Linux Signal num 15인 SIGTERM이 발생하였을 경우입니다.Exited (255)255 코드는 종료 코드가 범위를 벗어나는 경우 발생합니다." }, { "title": "DataGrid ColumnItem의 버튼으로 해당 행 삭제", "url": "/posts/wpf-RemoveItem-In-DataGrid/", "categories": ".NET, WPF", "tags": ".NET, C#, WPF, MVVM", "date": "2022-03-31 11:30:00 +0900", "snippet": "개요이 포스트는 WPF-MVVM에서 DataGrid의 행들이 각각 버튼을 가지고 있고 그 버튼을 클릭 했을 때 해당 행이 삭제되는 예제입니다.WPF 프로젝트 생성MVVM 패턴으로 하기 때문에 아래와 같이 파일을 생성합니다. 파일명 설명 DelegateCommand ICommand의 구현체이며 Button의 Click 바인딩으로 사용합니다. Item DataGrid에 들어가는 데이터 입니다. PropertyChangeHelper INotifyPropertyChanged 구현체로 바인딩 객체의 변화에 대해 이벤트를 발생하여 UI를 갱신합니다. MainWindow.xaml&lt;Window x:Class=\"ItemRemove.MainWindow\" xmlns=\"http://schemas.microsoft.com/winfx/2006/xaml/presentation\" xmlns:x=\"http://schemas.microsoft.com/winfx/2006/xaml\" xmlns:d=\"http://schemas.microsoft.com/expression/blend/2008\" xmlns:mc=\"http://schemas.openxmlformats.org/markup-compatibility/2006\" xmlns:local=\"clr-namespace:ItemRemove\" mc:Ignorable=\"d\" Title=\"MainWindow\" Height=\"450\" Width=\"800\"&gt; &lt;Grid&gt; &lt;Grid.RowDefinitions&gt; &lt;RowDefinition Height=\"30\"/&gt; &lt;RowDefinition Height=\"*\"/&gt; &lt;/Grid.RowDefinitions&gt; &lt;Grid Grid.Row=\"0\" &gt; &lt;Grid.ColumnDefinitions&gt; &lt;ColumnDefinition Width=\"*\"/&gt; &lt;ColumnDefinition Width=\"50\"/&gt; &lt;/Grid.ColumnDefinitions&gt; &lt;TextBox Grid.Column=\"0\" Text=\"{Binding InputText}\" Width=\"Auto\"/&gt; &lt;Button Grid.Column=\"1\" Command=\"{Binding InputCommand}\" Content=\"Input\" Width=\"50\" /&gt; &lt;/Grid&gt; &lt;DataGrid Grid.Row=\"1\" AutoGenerateColumns=\"False\" CanUserAddRows=\"False\" Margin=\"5\" HorizontalAlignment=\"Stretch\" VerticalAlignment=\"Stretch\" RowBackground=\"#fff\" FontWeight=\"Bold\" Foreground=\"#525252\" ScrollViewer.CanContentScroll=\"True\" Height=\"390\" MaxHeight=\"390\" AlternatingRowBackground=\"#f2f2f2\" BorderBrush=\"#000\" BorderThickness=\"1\" ScrollViewer.HorizontalScrollBarVisibility=\"Visible\" ScrollViewer.VerticalScrollBarVisibility=\"Auto\" SelectedItem=\"{Binding Path=SelectedItem}\" ItemsSource=\"{Binding Path=Items}\"&gt; &lt;DataGrid.Columns&gt; &lt;DataGridTextColumn Header=\"Id\" Binding=\"{Binding Path='Id'}\" IsReadOnly=\"True\"/&gt; &lt;DataGridTextColumn Header=\"Value\" Binding=\"{Binding Path='Value'}\" IsReadOnly=\"True\"/&gt; &lt;DataGridTemplateColumn Header=\"View\"&gt; &lt;DataGridTemplateColumn.CellTemplate&gt; &lt;DataTemplate&gt; &lt;Button Content=\"Remove\" Command=\"{Binding Path=DataContext.RemoveCommand, RelativeSource={RelativeSource FindAncestor, AncestorType={x:Type DataGrid}}}\"/&gt; &lt;/DataTemplate&gt; &lt;/DataGridTemplateColumn.CellTemplate&gt; &lt;/DataGridTemplateColumn&gt; &lt;/DataGrid.Columns&gt; &lt;/DataGrid&gt; &lt;/Grid&gt;&lt;/Window&gt;DataTemplate은 데이터의 틀을 지정해주는 Template입니다. DataGrid에서 View라는 Column을 따로 Template을 만드는데 이때 DataTemplate으로 틀을 만들어주면 됩니다.RelativeSource란MainViewModelpublic class MainViewModel : PropertyChangedHelper{ private int _itemIndex = 0; private string _inputText; public string InputText { get { return _inputText; } set { SetField(ref _inputText, value, \"ItemsSource\"); } } private ObservableCollection&lt;Item&gt; _items; public ObservableCollection&lt;Item&gt; Items { get { return _items; } set { SetField(ref _items, value, \"ItemsSource\"); } } private Item _selectedItem; public Item SelectedItem { get { return _selectedItem; } set { SetField(ref _selectedItem, value, \"ItemsSource\"); } } public ICommand RemoveCommand { get; set; } public ICommand InputCommand { get; set; } public MainViewModel() { Items = new ObservableCollection&lt;Item&gt;(); RemoveCommand = new DelegateCommand(RemoveCommandAction); InputCommand = new DelegateCommand(InputCommandAction); } private void InputCommandAction() { if(InputText != null) Items.Add(new Item(_itemIndex++, InputText)); } private void RemoveCommandAction() { if(SelectedItem != null) Items.Remove(SelectedItem); }}InputCommandAction은 InputText에 글자를 넣고 Input 버튼을 누르면 DataGrid에 행이 추가 됩니다.그리고 추가 된 행에서 Remove 버튼을 누르면 선택 된 행을 DataGrid에서 삭제합니다.예제ItemRemoveInDataGrid.zip" }, { "title": ".NET Core에서 Redis Job Queue 사용하기", "url": "/posts/Redis-NET/", "categories": ".NET", "tags": ".NET, C#, Redis", "date": "2022-03-31 11:30:00 +0900", "snippet": "소개Redis는 Key, Value 구조의 비정형 데이터를 저장하고 관리하기 위한 오픈 소스 기반의 비관계형 데이터베이스 관리 시스템(DBMS)입니다.데이터베이스, 캐시, 메시지 브로커로 사용되며 인메모리 데이터 구조를 가진 저장소입니다.많이들 Redis의 자료구조 중 List를 가지고 Queue나 Stack을 만들어 사용합니다.속도는 O(n)의 속도를 가지며 이 포스트에서는 Job Queue를 만들어 Message Queue 처럼 사용하는 방법에 대해 소개하도록 하겠습니다.flowchart LR Client -- 3, 2, 1 --&gt; Queue Queue -- 1 --&gt; Worker1 Queue -- 2 --&gt; Worker2 Queue -- 3--&gt; Worker3Redis Nuget Package.NET에서 Redis를 지원하는 패키지는 많이 있으나 가장 많이 사용하는 StackExchange.Redis를 사용하여 구연하도록 하겠습니다.Redis 연결StackExchange.Redis로 Redis에 연결하기 위해서는 아래와 같은 방법으로 Connection을 생성하면 됩니다.ConnectionMultiplexer.Connect(\"localhost:6379\");Connection이 생성 되었다면 아래와 같이 메서드를 정의 할 수 있습니다.public void Enqueue(string value){ _connection.GetDatabase().ListLeftPush(_queueName, value.ToString());}public string Dequeue(){ var result = _connection.GetDatabase().ListRightPop(_queueName); return result.ToString();}Enqueue의 경우 List의 왼쪽에 Push를 하고 Dequeue의 경우 오른쪽에서 Pop을 하면 됩니다. Stack 구현 시 Push의 경우 ListLeftPush Pop의 경우 ListLeftPop을 하면 되겠죠?메시지 삭제Redis의 경우 Message Queue 처럼 사용하지만 중간의 데이터를 삭제 할 수 있습니다.예를 들어 RabbitMQ의 경우는 메시지를 Publish하면 메시지를 Queue에서 강제로 삭제가 불가능합니다.하지만 Redis는 List이기 때문에 O(n)의 속도로 삭제가 가능합니다.public int Remove(string value, long count = 1){ var removeItems = _connection.GetDatabase().ListRemove(_queueName, value.ToString(), count); return Convert.ToInt32(removeItems);}ListRemove를 사용하면 삭제가 가능하며 count는 삭제하려는 value를 몇개까지 지우는지 설정합니다.예제 소스https://github.com/Jandari91/Redis-.NET예제 소스 설명Client-WPF의 경우 WPF로 만들었고 textbox에 글자를 넣고 Input 버튼을 누르면 Redis로 Message가 Enqueue 됩니다.그리고 WorkerService는 위 그림과 같이 메시지를 하나하나씩 가져와 처리됩니다.docker-compose.yml은 아래와 같이 정의하여 Worker를 3개 띄우도록 하였습니다.version: '3.4'services: workerservice: image: ${DOCKER_REGISTRY-}workerservice build: context: . dockerfile: WorkerService/Dockerfile workerservice2: image: ${DOCKER_REGISTRY-}workerservice build: context: . dockerfile: WorkerService/Dockerfile workerservice3: image: ${DOCKER_REGISTRY-}workerservice build: context: . dockerfile: WorkerService/Dockerfile redis: image : redis:latest ports: - 6379:6379" }, { "title": "Could not load dynamic library 'libcudnn.so.8'", "url": "/posts/Cuda-CNN-Trouble/", "categories": "DeepLearning", "tags": "CUDA, Setup, Linux, TroubleShooting", "date": "2022-03-30 22:50:00 +0900", "snippet": "환경 OS : RHEL 8.5 GPU : Nvidia GeForce GTX 1060 6GB CUDA : 11.6문제발생Tensorflow를 실행 시킬 때 아래와 같은 로그가 뜨면서 GPU 동작을 하지 않고 CPU로만 동작합니다.2022-03-29 16:21:12.448227: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda-11.6/lib642022-03-29 16:21:12.448246: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.Skipping registering GPU devices...2022-03-29 16:21:12.448855: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMATo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.Found 3670 files belonging to 5 classes.Using 734 files for validation.일단 위 로그를 확인해보면 아래와 같이 해석이 됩니다.Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda-11.6/lib64 동적라이브러리 libcudnn.so.8을 로드할 수 없습니다. 해당 파일 또는 디렉토리가 없어 공유 객체를 열수 없습니다. 경로는 LD_LIBRARY_PATH: :/usr/local/cuda-11.6/lib64 입니다.이건 CuDNN을 설치하지 않았거나 잘 못 설치가 되었을 때 생깁니다.CuDNN 설치https://developer.nvidia.com/rdp/cudnn-archive해당 사이트에서 tar로 되어 있는 파일로 설치하거나 rpm으로 받아 설치하는 방법이 있습니다.저는 tar 파일을 다운받아 설치하도록 하겠습니다.tar 설치Local Installer for Linux x86_64 (Tar) 파일을 다운 받아 리눅스 서버로 전송합니다.wget으로는 리눅스에서 직접 받아지지 않습니다.$ tar -xvf cudnn-linux-x86_64-8.3.2.44_cuda11.5-archive.tar.xz$ cd cudnn-linux-x86_64-8.3.2.44_cuda11.5-archive/$ sudo cp include/cudnn*.h /usr/local/cuda-11.6/include$ sudo cp lib/libcudnn* /usr/local/cuda-11.6/lib64sudo chmod a+r /usr/local/cuda-11.6/include/cudnn*.h /usr/local/cuda-11.6/lib64/libcudnn*" }, { "title": "WPF Binding의 RelativeSource 속성", "url": "/posts/wpf-RelativeSource/", "categories": ".NET, WPF", "tags": ".NET, C#, WPF, MVVM", "date": "2022-03-30 22:30:00 +0900", "snippet": "소개WPF에서 Binding의 태그 중 RelativeSource 속성은 바인딩 할 객체를 찾을 때 사용됩니다.자기 자신&lt;TextBlock Text=\"{Binding RelativeSource={RelativeSource self}, Path=FontFamily}\" /&gt;자기 자신이 바인딩 소스인 경우 self로 자정하고 Path로 어떤 것을 바인딩 할 지 지정하면 됩니다.상위 객체&lt;StackPanel Orientation=\"Horizontal\"&gt; &lt;TextBlock Text=\"{Binding Path=Orientation, RelativeSource={RelativeSource AncestorType={x:Type StackPanel}}}\"/&gt;&lt;/StackPanel&gt;자신의 부모 객체의 경우 감싸고 있는 Control의 이름을 AncestorType로 지정해주면 됩니다.하지만 StackPanel이 StackPanel로 감싸고 있을 경우는 어떻게 할까요??&lt;StackPanel Orientation=\"Vertical\"&gt; &lt;StackPanel Orientation=\"Horizontal\"&gt; &lt;TextBlock Text=\"{Binding Path=Orientation, RelativeSource={RelativeSource AncestorType={x:Type StackPanel}, AncenstorLevel=2}}\"/&gt; &lt;/StackPanel&gt;&lt;/StackPanel&gt;위와 같을 때는 AncenstorLevel=2처럼 몇번 째 부모 Control인지 지정해주면 됩니다.ControlTemplate 정의 엘리먼트 일 경우&lt;ControlTemplate TargetType=\"{x:Type Button}\"&gt; &lt;Border x:Name=\"_pBorder\" BorderThickness=\"2\" BorderBrush=\"Black\" CornerRadius=\"20\"&gt; &lt;Border.Background&gt; &lt;LinearGradientBrush StartPoint=\"0 0.5\" EndPoint=\"1 0.5\"&gt; &lt;GradientStop Offset=\"0.0\" Color=\"{Binding RelativeSource={RelativeSource TemplatedParent}, Path=Background.Color}\" /&gt; &lt;GradientStop Offset=\"0.9\" Color=\"White\" /&gt; &lt;/LinearGradientBrush&gt; &lt;/Border.Background&gt; &lt;ContentPresenter Margin=\"2\" HorizontalAlignment=\"Center\" VerticalAlignment=\"Center\" RecognizesAccessKey=\"True\" /&gt; &lt;/Border&gt;&lt;/ControlTemplate&gt;x:Name으로 Control 찾기&lt;StackPanel x:Name=\"Panel1\" Orientation=\"Vertical\"&gt; &lt;StackPanel x:Name=\"Panel2\" Orientation=\"Horizontal\"&gt; &lt;TextBlock Text=\"{Binding Path=Orientation, ElementName=Panel1}\"/&gt; &lt;/StackPanel&gt;&lt;/StackPanel&gt;&lt;TextBlock Text=\"{Binding Path=Orientation, ElementName=Panel2}\"/&gt;위와 같이 상대 경로로 찾지 않고 ElementName으로 바로 찾을 수 있습니다." }, { "title": "NUMA node read from SysFS had negative value -1", "url": "/posts/Cuda-NUMA-Trouble/", "categories": "DeepLearning", "tags": "CUDA, Setup, Linux, TroubleShooting", "date": "2022-03-30 22:30:00 +0900", "snippet": "환경 OS : RHEL 8.5 GPU : Nvidia GeForce GTX 1060 6GB CUDA : 11.6문제발생Tensorflow를 실행 시킬 때 아래와 같은 로그가 뜨면서 GPU 동작을 하지 않고 CPU로만 동작합니다.Found 3670 files belonging to 5 classes.Using 2936 files for training.2022-03-29 16:21:12.425272: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zeroSkipping registering GPU devices...2022-03-29 16:21:12.448855: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMATo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.Found 3670 files belonging to 5 classes.Using 734 files for validation.일단 위 로그를 확인해보면 아래와 같이 해석이 됩니다.NUMA node 정보가 올바르지 않지만, 너 적어도 한 개의 NUMA node 있다.그러니 일단 되게끔 해 보겠다.NUMA (Non-Uniformed Memory Access) 란? 불균일 기억 장치 접근(Non-Uniform Memory Access, NUMA)는 멀티프로세서 시스템에서 사용되고 있는 컴퓨터 메모리 설계 방법중의 하나로, 메모리에 접근하는 시간이 메모리와 프로세서간의 상대적인 위치에 따라 달라진다. NUMA구조에서 프로세서는 자기의 로컬 메모리에 접근할 때가 원격 메모리에 접근할 때보다 더 빠르다. 원격 메모리는 다른 프로세서에 연결되어 있는 메모리를 말하고 로컬 메모리는 자기 프로세서에 연결되어 있는 메모리를 말한다.즉, 하나의 메인보드에서 여러 프로세서를 사용하면서 메모리 접근 효율을 높이기 위한 기술로 특정 프로세서가 메모리를 다 잡게되면 버스를 자기 혼자 독점하고있으니 다른 프로세서는 놀아야하는 상황이 발생하기 때문에 각 프로세서마다 메모리 구역을 나눠주고 ‘여기만 접근해’ 라고 지정하고 그걸 NUMA 노드라고 함.해결방법$ lspci | grep -i nvidia01:00.0 VGA compatible controller: NVIDIA Corporation GP106 [GeForce GTX 1060 6GB] (rev a1)01:00.1 Audio device: NVIDIA Corporation GP106 High Definition Audio Controller (rev a1)첫번째 줄 VGA 호환 장치, NVIDIA Geforce 의 주소가 01:00.0 으로 나온다. 이는 각자 다를 것이므로 이 부분을 잘 변경해 주자.NUMA 설정 값 확인 및 변경$ cd /sys/bus/pci/devices/$ ls0000:00:00.0 0000:00:14.2 0000:00:1b.0 0000:00:1f.0 0000:00:1f.5 0000:01:00.10000:00:01.0 0000:00:16.0 0000:00:1c.0 0000:00:1f.3 0000:00:1f.6 0000:04:00.00000:00:14.0 0000:00:17.0 0000:00:1d.0 0000:00:1f.4 0000:01:00.0위에서 확인한 01:00.0 이 보인다. 다만 앞에 0000:이 붙어있다.연결되어있는지 다시 확인해 본다.$ cat /sys/bus/pci/devices/0000\\:01\\:00.0/numa_node-1-1은 연결이 안되있다는 의미, 0이 잘 되어있다는 의미다. 즉, 안되어있다.아래의 명령어로 고쳐 준다.$ echo 0 | sudo tee -a /sys/bus/pci/devices/0000\\:01\\:00.0/numa_node$ cat /sys/bus/pci/devices/0000\\:01\\:00.0/numa_node0" }, { "title": "FastAPI Docker 이미지 제작", "url": "/posts/fastapi-docker-build/", "categories": "FastAPI", "tags": "FastAPI, Python, Docker", "date": "2022-03-30 05:00:00 +0900", "snippet": "소개이번 포스트는 FastAPI 서비스를 Docker Image로 만들어 띄우는 방법에 대해 소개합니다.main.py 생성main.py 파일을 생성하여 기본 코드를 작성합니다.from fastapi import FastAPIapp = FastAPI()@app.get(\"/\")def root(): return {\"hello root\"}@app.get(\"/world\")def world(): return {\"hello world\"}해당 코드는 /로 접속하면 [hello root]가 출력 되고 /world로 접속하면 [hello world]가 출력 되는 간단한 프로그램입니다.pip 모듈 정의pip는 필요 모듈을 따로 정의하여 자동으로 패키지 추가가 가능합니다.requirements.txt 파일을 생성하고 필요한 패키지를 정의 합니다.uvicornfastapiFastAPI는 uvicorn과 fastapi 모듈이 기본적으로 필요합니다.Docker Image 생성Docker Image를 만들기 위해서는 Dockerfile을 정의하고 Docker build를 통해 자신만의 이미지를 생성하면 됩니다.Dockerfile 정의Dockerfile을 생성합니다.FROM python:latestWORKDIR /app/COPY ./main.py /app/COPY ./requirements.txt /app/RUN pip install -r requirements.txtCMD uvicorn --host=0.0.0.0 --port 8000 main:app FROM python:latest : 베이스가 되는 Docker Image로 python 이미지를 사용합니다. WORKDIR /app/ : 처음 실행 시 사용 되는 경로 정보 입니다. COPY ./main.py /app/ : 현재 경로의 main.py를 /app 경로로 복사합니다. COPY ./requirements.txt /app/ : 현재 경로의 requirements.txt를 /app 경로로 복사합니다. RUN pip install -r requirements.txt: 복사 된 requirements.txt를 사용하여 pip로 패키지를 추가합니다. CMD uvicorn --host=0.0.0.0 --port 8000 main:app : uvicorn을 사용하여 main.py의 app을 실행시킵니다.Docker BuildDockerfile이 있는 경로에서 docker build 명령어를 실행합니다.&gt; docker build --tag fastapi:0.1 . --tag : 생성한 이미지의 이름을 설정합니다. 설정하지 않으면 None으로 생성됩니다.Docker Container 생성Dockerfile의 정의를 보면 기본 포트는 8000으로 되어 있습니다.Container를 실행 할 때 Port 포워딩을 통해 원하는 포트를 지정하여 실행 할 수 있습니다.&gt; docker run --rm -p 8080:8000 fastapi:0.1INFO: Started server process [8]INFO: Waiting for application startup.INFO: Application startup complete.INFO: Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit) --rm : 이미지가 stop 되면 자동으로 Container가 삭제 됩니다. -p 8080:8000 : FastAPI의 기본 포트인 8000과 자신의 로컬 포트 8080을 포워딩 합니다.http://localhost:8080[\"hello root\"]http://localhost:8080/world[\"hello world\"]docker-compose 추가docker-compose는 여러 컨테이너를 한번에 띄워야 할 때 하나의 파일로 정의하여 관리하기 위해 사용합니다.docker image 생성 부터 실행까지 자동으로 할 수 있습니다.docker-compose.yml 파일을 생성합니다.services: fastapi: build: context: . dockerfile : . ports: - 8080:8000 services : service를 정의합니다. fastapi: service의 이름입니다. build : docker image를 생성 할 build에 대해 정의합니다. context : build를 실행 할 경로 입니다. dockerfile : dockerfile의 경로 입니다. ports : 포트포워딩 정보 입니다.docker-compose.yml 파일이 있는 곳에서 아래의 명령어를 실행합니다.&gt; docker-compose upCreating src_fastapi_1 ... doneAttaching to src_fastapi_1fastapi_1 | INFO: Started server process [8]fastapi_1 | INFO: Waiting for application startup.fastapi_1 | INFO: Application startup complete.fastapi_1 | INFO: Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)예제fastapi_docker.zip" }, { "title": "FastAPI 실행하기", "url": "/posts/fastapi_start/", "categories": "FastAPI", "tags": "FastAPI, Python", "date": "2022-03-30 04:00:00 +0900", "snippet": "소개이번 포스트는 FastAPI를 python 코드로 실행하고 확인하는 방법에 대해 설명합니다.시작하기FastAPI는 실행 방법이 두가지 있습니다.python에서 uvicorn 모듈을 사용하여 직접 실행하는 방법과 디버깅을 위해 main 함수에 uvicorn 실행 코드를 넣는 방법 입니다.직접 실행아래와 같이 main.py 파일에 코드를 입력 합니다.from fastapi import FastAPIapp = FastAPI()@app.get(\"/\")async def root(): return {\"message\": \"Hello World\"}위 코드는 FastAPI의 간단한 코드 입니다.VS Code에서 F5를 눌러 실행시키면 서비스가 실행 되지 않고 바로 종료가 됩니다.실행 시키기 위해서는 main.py를 uvicorn을 통해 실행 시켜야 합니다.&gt; python.exe -m uvicorn main:app --reloadINFO: Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)INFO: Started reloader process [26272] using watchgodINFO: Started server process [15080]INFO: Waiting for application startup.INFO: Application startup complete.디버깅위 직접 실행의 경우 디버깅이 불가능 하기 때문에 main 함수에 uvicorn을 호출하여 실행하는 방법이 있습니다.import uvicornfrom fastapi import FastAPIapp = FastAPI()@app.get(\"/\")def root(): a = \"a\" b = \"b\" + a return {\"hello world\": b}if __name__ == \"__main__\": uvicorn.run(app, host=\"0.0.0.0\", port=8000)위와 같이 선언하면 바로 실행이 가능합니다.INFO: Started server process [504]INFO: Waiting for application startup.INFO: Application startup complete.INFO: Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)살펴보기아래와 같이 main.py를 만들어 실행 시킵니다.import uvicornfrom fastapi import FastAPIapp = FastAPI()@app.get(\"/\")def root(): return {\"hello root\"}@app.get(\"/world\")def world(): return {\"hello world\"}if __name__ == \"__main__\": uvicorn.run(app, host=\"0.0.0.0\", port=8000)RestAPI 호출위에서 실행시킨 코드를 살펴보면 8000 포트로 접속하였을 때 FastAPI로 실행시킨 서비스에 접근이 가능합니다./로 접근하였을 때는 hello root라는 리턴값이 반환 되고 /world로 접근하였을 때는 hello world라는 리턴값이 반환 됩니다.http://localhost:8000[\"hello root\"]http://localhost:8000/world[\"hello world\"]SwaggerFastAPI는 Swagger를 기본적으로 지원합니다.http://localhost:8000/docsSwagger를 통해 Web UI에서 RestAPI들을 테스트 할 수 있습니다.RedocsOpenAPI의 경우 서비스를 사용하는 곳에 스펙에 대해 문서로 전달해야 하는 경우가 많습니다.이 때 Redocs를 사용하게 되면 자동으로 API와 동기화가 이뤄지는 문서를 배포 가능합니다.http://localhost:8000/redoc" }, { "title": "VS Code에서 Python Type Check 기능 활성화", "url": "/posts/python-typecheck-vscode/", "categories": "VSCode", "tags": "VSCode, Python", "date": "2022-03-30 01:00:00 +0900", "snippet": "소개python은 기본적으로 동적(dynamic)프로그래밍 언어로써 인터프리터(interpreter)가 코드를 실행하면서 Type을 추론하여 체크하기 때문에 Type이 고정되어 있지 않습니다.하지만 Python 3.5 부터 Python에서도 Type을 체크할 수 있도록 Type Hints라는 기능이 도입되어 ㅆ습니다.데이터형에 주석을 붙여 사용하게 됩니다.def greeting(name:str) -&gt; str: return 'Hello' + name name:str : 인수 name의 Type이 str이라는 것을 어노테이션합니다. -&gt; str : 함수 반환값의 Type이 str이라는 것을 어노테이션 합니다.VSCode Type Check 활성화VS Code에서 아래와 같이 코딩을 합니다.def get_name_with_age(name: str, age: int) -&gt; str : name_with_age = name + \" is this old \" + age return name_with_ageget_name_with_age(\"Jhon\", 19)위 코드를 동작시키면 age의 형변환을 하지 않아 오류가 생기기 됩니다.하지만 VS Code에서는 따로 Run Time 전에 따로 인텔리전스가 되지 않습니다.해당 기능을 활성화 시키기 위해서는 파일 -&gt; 기본설정 -&gt; 설정으로 이동하거나 Ctrl + ,를 사용합니다.검색에서 Type Checking Mode를 검색합니다.위와 같이 Type Checking Mode가 Off 상태 인것을 알 수 있습니다.basic으로 상태를 변경하여 줍니다.VS Code에서 런타임 전에 오류를 체크해주는 것을 확인 할 수 있습니다." }, { "title": "FastAPI의 Type hits", "url": "/posts/Typehints-Fastapi/", "categories": "FastAPI", "tags": "FastAPI, Python", "date": "2022-03-30 00:00:00 +0900", "snippet": " https://fastapi.tiangolo.com/ko/python-types/Python Types란FastAPI는 Python의 type hints를 사용합니다.python은 기본적으로 동적(dynamic)프로그래밍 언어로써 인터프리터(interpreter)가 코드를 실행하면서 Type을 추론하여 체크하기 때문에 Type이 고정되어 있지 않습니다.FastAPI에서는 type을 선언하여 사용하므로 Editor와 Tools에서 디버깅에 대해 더 나은 경험을 제공 할 수 있습니다.인텔리센스(IntelliSense) 지원def get_full_name(first_name, last_name): full_name = first_name.title() + \" \" + last_name.title() return full_nameprint(get_full_name(\"john\", \"doe\"))John Doe위의 예제는 first_name과 last_name을 가져오고 각 문자의 첫 글자를 대문자로 변환 후 출력하는 간단한 예제입니다.Type을 추가 했을 경우위 프로그램은 간단한 코드이기 때문에 금방 쓰게 되었지만 만약 처음부터 쓰고 있다고 했을 때 아래와 같이 인텔리젠스에서 힌트를 얻을 수가 없습니다.first_name, last_name매개변수에 아래와 같이 유형을 추가하여 줍니다.first_name: str, last_name: strtype hints를 추가하는 것 만으로도 코드를 작성 할 때 인텔리전스에서 어떤 것을 사용 할 수 있는지 지원이 가능합니다.런타임 전 에러 체크VS Code Type Check 활성화VS Code에서 Python Type Check를 사용하기 위해서는 아래의 포스트를 참고해 주시기 바랍니다.VS Code에서 Python Type Check 기능 활성화코드 추가def get_name_with_age(name: str, age: int) -&gt; str : name_with_age = name + \" is this old \" + age return name_with_ageget_name_with_age(\"Jhon\", 19)위와 같이 코드를 추가하고 실행을 시킵니다.하지만 age에서 TypeError가 발생하게 됩니다.VS Code에서 런타임 전 아래와 같이 오류를 미리 볼 수 있습니다.표준 Type 지원Python의 표준 타입 뿐만 아니라 모든 타입을 정의 할 수 있습니다. int float bool bytesdef get_items(item_a: str, item_b: int, item_c: float, item_d: bool, item_e: bytes): return item_a, item_b, item_c, item_d, item_d, item_e변수를 포함한 Typedict, list, set, tuple 등 내부 Type을 정의하여 사용하는 데이터 구조도 내부 유형에 대해 정의가 가능합니다.list python3.9+def process_items(items: list[str]): for item in items: print(item)list 안의 타입이 str이라고 정의 하여 사용 할 수 있습니다.tuple &amp; set python3.9+def process_items(items_t: tuple[int, int, str], items_s: set[bytes]): return items_t, items_sdict python3.9+def process_items(prices: dict[str, float]): for item_name, item_price in prices.items(): print(item_name) print(item_price)Union python3.10+def process_item(item: int | str): print(item)Union의 경우 변수가 여러 유형 중 하나가 있다는 것을 정의 할 수 있습니다.위 예제는 item의 Type이 int 이거나 str 일 때 사용합니다.사용자 정의 DataTypeclass Person: def __init__(self, name: str): self.name = namedef get_person_name(one_person: Person): return one_person.name사용자 정의 DataType도 위 그림과 같지 인텔리센스를 사용 할 수 있습니다.Pydantic ModelsPydantic은 Data Type에 속성이 있을 경우 사용합니다.Pydantic은 데이터를 검증하고 설정들을 관리하는 라이브러리로 런타임 환경에서 타입을 강제하고 타입이 유효하지 않을 때 에러를 발생시켜 줍니다.from datetime import datetimefrom pydantic import BaseModelclass User(BaseModel): id: int name = \"John Doe\" signup_ts: datetime | None = None friends: list[int] = []external_data = { \"id\": \"123\", \"signup_ts\": \"2017-06-01 12:22\", \"friends\": [1, \"2\", b\"3\"],}user = User(**external_data)print(user)# &gt; User id=123 name='John Doe' signup_ts=datetime.datetime(2017, 6, 1, 12, 22) friends=[1, 2, 3]print(user.id)# &gt; 123" }, { "title": "FastAPI 소개", "url": "/posts/fastapi/", "categories": "FastAPI", "tags": "FastAPI, Python", "date": "2022-03-29 13:00:00 +0900", "snippet": "이번 포스트는 FastAPI에 대한 소개와 Docker Image를 제작하여 간단하게 서비스화를 시켜보도록 하겠습니다.FastAPI문서 : https://fastapi.tiangolo.com소스 코드 : https://github.com/tiangolo/fastapi깃허브에서는 아래와 같이 한 줄로 요약이 되어 있습니다.\"FastAPI는 표준 파이썬 타입 힌트를 바탕으로 한 파이썬 3.6이상에서 작동하는, 현대적이고 빠른(고성능) API 서버 웹 프레임워크다.\"이름에서 보이는 것과 같이 빠른 API 서비스를 구축하는 프레임 워크라고 설명하고 있습니다.FastAPI에서 말하는 특징은 아래와 같습니다. NodeJS 및 Go와 비슷한 성능, 현존하는 파이썬 웹 프레임워크 중 가장 빠르다. 개발 속도가 빠르다 버그가 적다. 직관적이다 간편하다. 코드 중복을 최소화한다. 견고하다, 대화형 자동 설명서를 사용해서 실행 가능한 코드를 구축할 수 있다. 개방형 API 표준(OpenAPI&amp;JSON)을 기반으로 한다.아직 Python 웹 프레임워크인 Django나 Flask보다 레퍼런스는 적어 공식문서에 굉장한 공을 들인 느낌입니다.Swagger 지원Swagger는 OpenAPI에 맞게 디자인Fast API는 기본적으로 Swagger를 탑제하고 있습니다.그래서 아래와 같이 따로 설치하지 않아도 Swagger UI를 통해 사용이 가능합니다.Redoc 지원Redoc은 API를 자동으로 문서화 시켜주는 툴이다.Fast API로 서비스를 개발 한 뒤 이 API를 사용 할 다른 프로젝트 팀에게 문서화를 하여 줄 때 사용합니다.FastAPI는 Redoc을 기본적으로 내장하고 있기 때문에 쉽고 빠르게 개발이 가능합니다.쉬운 디버깅FastAPI는 Python type hints를 사용하기 때문에 파마미터의 타입을 명시할 수 있습니다.그래서 Type Check가 가능하며, data의 validation을 자동으로 해주고 오류 시 Error를 생성합니다.from typing import List, Dictfrom datetime import datefrom pydantic import BaseModel# Declare a variable as a str# and get editor support inside the functiondef main(user_id: str): return user_id# A Pydantic modelclass User(BaseModel): id: int name: str joined: date" }, { "title": "C# Clipboard 및 Serialize", "url": "/posts/Clipboard/", "categories": ".NET, WPF", "tags": ".NET, C#, WPF, MVVM", "date": "2022-03-29 07:34:00 +0900", "snippet": "개요이 포스트는 WPF-MVVM에서 UI의 색상을 복사하여 붙여넣기 예제 프로그램 및 설명입니다.C#에서 클립보드를 사용하기 위해서는 System.Windows의 Clipboard Class를 사용합니다.복사하기클립보드에 복사하기 위해서는 SetDataObject를 사용합니다.Clipboard.SetDataObject(object data, bool copy)두번째 매개 변수인 copy의 경우 true 이면 프로그램을 종료하여도 클립보드에 계속 남아 있고 false 인 경우 프로그램이 종료하면 클립보드의 데이터도 같이 없어집니다.Clipboard.Clear();var dataObject = new DataObject();dataObject.SetData(\"SelectedColor\", SelectedColor, true);Clipboard.SetDataObject(dataObject, true);클립보드에 데이터를 넣을 때는 DataObject를 통해 구분이 가능하도록 넣을 수 있습니다.DataObject의 dataObject.SetData() 의 경우 그냥 넣어도 되고 format 을 지정하여 구분을 가능하도록 하여 여러 데이터를 넣고 원하는 것만 빼서 쓸 수 있습니다.예제에서는 SelectedColor라는 format을 지정하여 사용하였습니다.예제CopyTest.zip" }, { "title": "RHEL8.5 FTP 설치", "url": "/posts/ftp_setup_rhel8/", "categories": "Infra, FTP", "tags": "FTP, RHEL8", "date": "2022-03-29 07:21:00 +0900", "snippet": "vsftpd 패키지 설치먼저 vsftpd가 실행 중인지 확인 합니다.$ ps -ax | grep vsftpd 46688 pts/1 S+ 0:00 grep --color=auto vsftpdgrep 명령어만 뜨는 걸 봐서는 설치가 되어 있지 않습니다.dnf 명령어를 통해 설치 합니다.$ sudo dnf -y install vsftpdFTP 서버 설정config 파일을 설정하여 줍니다.$ sudo vi /etc/vsftpd/vsftpd.conf아래 설정 3개를 변경하여 줍니다.anonymous_enable=NO local_enable=YESwrite_enable=YESlocal_umask=022anon_upload_enable=YESdirmessage_enable=YESxferlog_enable=YESxferlog_file=/var/log/xferlogconnect_from_port_20=YESlisten=YESchroot_local_user=YESchroot_list_enable=YESchroot_list_file=/etc/vsftpd/chroot_listchroot_list에 허용할 아이디 리스트를 입력하여 줍니다.$ sudo vi /etc/vsftpd/chroot_listmirero방화벽 설정기본적으로 FTP는 21번 포트를 사용 합니다.firwall-cmd 명령어로 방화벽을 해제 하여 줍니다.$ sudo firewall-cmd --permanent --add-service=ftpsuccess$ sudo firewall-cmd --permanent --add-port=21/tcpsuccess$ sudo firewall-cmd --reloadsuccessSELINUX 해제SELINUX는 보안을 강화해주는 커널입니다.zero-day 공격 및 buffer overflow 등 어플리케이션 취약점으로 인한 해킹을 방지해주는 핵심 구성요소 입니다.$ sudo vi /etc/selinux/configSELINUX=disabled로 변경한다.서비스 시작$ sudo systemctl restart vsftpd " }, { "title": "RHEL8.5 IP 셋업", "url": "/posts/RHEL_ip_setup/", "categories": "Infra", "tags": "Setup, Linux", "date": "2022-03-29 04:37:00 +0900", "snippet": "RHEL8.5 IP 셋팅sudo vi /etc/sysconfig/network-scripts/ifcfg-eno1TYPE=EthernetPROXY_METHOD=noneBROWSER_ONLY=noBOOTPROTO=noneDEFROUTE=yesIPV4_FAILURE_FATAL=noIPV6INIT=yesIPV6_AUTOCONF=yesIPV6_DEFROUTE=yesIPV6_FAILURE_FATAL=noNAME=eno1UUID=8f55df94-9ffa-4ae3-8c42-7974aa8605c4DEVICE=eno1ONBOOT=yesIPADDR=192.168.90.5PREFIX=24GATEWAY=192.168.90.1DNS1=168.126.63.1DNS2=203.239.173.1IPV6_PRIVACY=no설정이 끝나면 아래와 같은 명령어로 네트워크를 재시작 합니다.$ sudo systemctl restart NetworkManager.service설정 된 DNS 확인자신이 설정한 DNS의 ip 주소는 ifconfig -a를 사용해도 나오지 않습니다.$ cat /etc/resolv.conf# Generated by NetworkManagernameserver 168.126.63.1nameserver 8.8.8.8확인 가능합니다." }, { "title": "RHEL8.5 Docker 및 docker-compose v2 설치", "url": "/posts/docker/", "categories": "Docker", "tags": "Docker, docker-compose, Setup, Linux", "date": "2022-03-29 03:00:00 +0900", "snippet": "https://docs.docker.com/engine/install/rhel/위 사이트는 docker에서 RHEL에 대한 docker 설치에 대해 설명하지만 정상적으로 동작하지 않습니다.그래서 rhel repo를 centos repo로 변경하였습니다.OS 요구사항도커 엔진을 설치하기 위해서는 RHEL 7 또는 8 버전이 필요합니다.이전 버전 제거docker가 설치되어 있지 않다면 넘어가셔도 상관없습니다.$ sudo dnf remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-engine \\ podman \\ runc설치Repository 추가RHEL용 레포지토리가 동작하지 않아 centos로 변경합니다.$ sudo dnf config-manager --add-repo=https://download.docker.com/linux/centos/docker-ce.repo$ sudo dnf repolist -vRepo-id : docker-ce-stableRepo-name : Docker CE Stable - x86_64Repo-revision: 1549905809Repo-updated : Mon 11 Feb 2019 06:23:29 PM CETRepo-pkgs : 30Repo-size : 618 MRepo-baseurl : https://download.docker.com/linux/centos/7/x86_64/stableRepo-expire : 172,800 second(s) (last: Mon 18 Feb 2019 10:23:54 AM CET)Repo-filename: /etc/yum.repos.d/docker-ce.repoDocker 설치$ sudo dnf -y install docker-ce docker-ce-cli containerd.ioDocker 실행$ sudo systemctl restart dockerDocker 권한 추가일반 계정에서 아래와 같이 docker ps를 사용하면 권한 에러가 출력됩니다.$ docker psGot permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get \"http://%2Fvar%2Frun%2Fdocker.sock/v1.24/containers/json\": dial unix /var/run/docker.sock: connect: permission denied먼저 docker group을 추가하고 그 그룹에 일반 계정을 추가합니다.$ sudo groupadd docker$ sudo usermod -aG docker $계정명docker.sock을 사용할 수 있도록 docker 그룹에 권한을 추가합니다.$ sudo chown root:docker /var/run/docker.sock$ sudo chmod 666 /var/run/docker.sock$ docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESdocker-compose 설치https://github.com/docker/compose/releasesdocker-compose v2의 경우 기존의 v1과 설치 방법이 다릅니다.https://docs.docker.com/compose/cli-command/#install-on-linux$ DOCKER_CONFIG=${DOCKER_CONFIG:-$HOME/.docker}$ mkdir -p $DOCKER_CONFIG/cli-plugins$ curl -SL https://github.com/docker/compose/releases/download/v2.3.4/docker-compose-linux-x86_64 -o $DOCKER_CONFIG/cli-plugins/docker-compose실행 권한을 부여합니다.$ chmod +x $DOCKER_CONFIG/cli-plugins/docker-composedocker-compose를 실행하고 버전을 확인합니다.$ docker compose versionDocker Compose version v2.3.4" }, { "title": "RHEL8.5 Python 및 Tensorflow 설치", "url": "/posts/tensorflow/", "categories": "DeepLearning", "tags": "CUDA, Setup, Linux, Python, Tensorflow", "date": "2022-03-29 00:00:00 +0900", "snippet": "이 글은 RHEL(Red Hat Enterprise Linux)에 Tensorflow를 설치하기 위한 글입니다.먼저 이전에 작성한 블로그를 참고하여 CUDA를 설치하여야 합니다.Python 설치RHEL에 python을 설치하기 위해서는 yum 또는 dnf를 통해 쉽게 설치가 가능합니다.$ sudo yum -y install python3$ sudo dnf -y install python3하지만 2022-03-28 기준 최신 버전인 3.10.4를 설치하도록 하겠습니다.Python Source 설치 전 패키지 설치$ sudo dnf -y install gcc openssl-devel bzip2-devel libffi-devel해당 패키지는 소스 파일의 Makefile을 컴파일하기 위해 필요한 패키지 입니다/패키지를 설치 하지 않으면 make파일을 컴파일 할 때 아래와 같은 에러가 발생할 수 있습니다.Python-3.10.4/Modules/_ctypes/_ctypes.c:107:10: fatal error: ffi.h: No such file or directory #include &lt;ffi.h&gt; ^~~~~~~compilation terminated.Python 소스파일 다운로드먼저 Python Download 사이트로 들어가 해당 버전의 url를 가져옵니다.https://www.python.org/downloads/source/해당 url로 들어간 후 가장 아래로 스크롤을 내리면 Files라고 보입니다.OS에 맞춰 파일을 다운 받을 수 있는데 저는 tar.xz 파일을 받도록 하겠습니다.해당 부분에서 마우스 오른쪽 키로 링크를 복사 한후 wget으로 다운 받습니다.$ sudo wget https://www.python.org/ftp/python/3.10.4/Python-3.10.4.tar.xz$ lsPython-3.10.4.tar.xzPython 설치위에서 받은 압축을 풀어 줍니다.$sudo tar xvf Python-3.10.4.tar.xz압축이 풀린 폴더로 들어가 Makefile 파일을 만들기 위해 configure를 실행합니다.$ cd Python-3.10.4$ ./configure --enable-optimizations$ ls | grep MakefileMakefileMakefile.preMakefile.pre.inMakefile을 컴파일 및 설치를 진행합니다.$ sudo make altinstall$ which python3.10/usr/local/bin/python3.10$ python3.10Python 3.10.4 (main, Mar 28 2022, 09:47:54) [GCC 8.5.0 20210514 (Red Hat 8.5.0-4)] on linuxType \"help\", \"copyright\", \"credits\" or \"license\" for more information.&gt;&gt;&gt;설치가 정상적으로 되었고 실행도 정상적으로 가능합니다.Tensorflow 설치가상환경 설정Tensorflow에서는 Python을 가상환경으로 설치하여 사용하는 것을 권장한다.그래서 아래와 같은 명령어로 가상환경을 설치하여 Tensorflow를 설치하겠습니다.$ python -m venv --system-site-packages ~/python/venv$ source ~/python/venv/bin/activate가상 환경을 활성화하게 되면 프롬프트가 (venv)로 변경됩니다.(venv) $ pip install --upgrade pip(venv) $ pip install --upgrade tensorflow(venv) $ python -c \"import tensorflow as tf;print(tf.reduce_sum(tf.random.normal([1000, 1000])))\"가상환경 python 기본으로 설정하지만 python3.10이라는 명령으로 사용해야 하기 때문에 alias를 변경하여 python으로만 실행이 가능하도록 설정합니다.현재 가상환경은 ~/python/venv에 설정이 되어 있습니다.$ vi ~/.bashrc가장 아래에 alias python=\"\"를 추가합니다.# .bashrc# Source global definitionsif [ -f /etc/bashrc ]; then . /etc/bashrcfi# User specific environmentif ! [[ \"$PATH\" =~ \"$HOME/.local/bin:$HOME/bin:\" ]]then PATH=\"$HOME/.local/bin:$HOME/bin:$PATH\"fiexport PATH# Uncomment the following line if you don't like systemctl's auto-paging feature:# export SYSTEMD_PAGER=# User specific aliases and functionsalias python=\"$HOME/python/venv/bin/python3.10\" # 추가이제 설정 파일을 적용합니다.$ source ~/.bashrc$ pythonPython 3.10.4 (main, Mar 28 2022, 09:47:54) [GCC 8.5.0 20210514 (Red Hat 8.5.0-4)] on linuxType \"help\", \"copyright\", \"credits\" or \"license\" for more information.&gt;&gt;&gt;import tensorflow&gt;&gt;&gt;pip 오프라인 설치pip를 사용 할 때 아래와 같은 에러가 뜰 경우가 있다.이것은 사내에서 인트라넷을 사용하는 경우 pip 패키지에서 신뢰 할 수 없어 패키지 다운로드가 안되는 것입니다.이런경우 오프라인으로 설치가 가능합니다.기존의 pip로 패키지를 다운받아 사용 중이던 PC에서 모듈 리스트를 추출합니다.$ pip freeze &gt; requirements.txtrequirements.txt 파일을 열어보면 아래와 같이 설치되어 있는 패키지의 목록이 나오게 됩니다.absl-py==1.0.0astunparse==1.6.3(... 생략 ...)tensorboard==2.8.0tensorboard-data-server==0.6.1tensorboard-plugin-wit==1.8.1tensorflow==2.8.0tensorflow-datasets==4.5.2tensorflow-io-gcs-filesystem==0.24.0tensorflow-metadata==1.7.0tensorflow-serving-api==2.8.0termcolor==1.1.0해당 목록의 패키지를 다운로드 받습니다.$ pip download -r requirements.txt그럼 .whl이나 .tar.gz으로 현재 경로에 다운로드가 받아집니다.이제 모든 파일을 오프라인으로 설치하고 싶은 PC로 이동시킵니다.$ python -m pip install --no-index --find-links=\"./\" -r requirements.txtrequirements.txt에 있는 목록이 일괄 설치 되게 됩니다.python -m pip install --no-index --find-links=\"./\" schedule-0.6.0-py2.py3-none-any.whl위와 같이 특정 모듈을 지정하여 설치도 가능합니다." }, { "title": "RHEL8.5 CUDA 및 CuDNN설치", "url": "/posts/cuda/", "categories": "DeepLearning", "tags": "CUDA, CuDNN, Setup, Linux", "date": "2022-03-28 23:00:00 +0900", "snippet": "이 글은 RHEL(Red Hat Enterprise Linux)에 Tensorflow를 설치하기 위한 글입니다.먼저 이전에 작성한 블로그를 참고하여 Nvidia Driver를 설치해야 합니다.CUDA란?CUDA(Computed Unified Device Architecture)는 NVIDIA에서 개발한 GPU 개발 툴이다.아래는 NVIDIA 블로그에서 나온 글입니다.CUDA는 범용 컴퓨팅을 위해 GPU를 간단하고 우아하게 사용하는 병렬 컴퓨팅 플랫폼 및 프로그래밍 모델입니다.개발자는 여전히 친숙한 C, C ++, Fortran 또는 계속 확장되는 지원되는 언어 목록을 프로그래밍하고 몇 가지 기본 키워드의 형태로 이러한 언어의 확장을 통합합니다. 이 키워드를 통해 개발자는 대량의 병렬 처리를 표현하고 GPU를 매핑하는 응용 프로그램 부분으로 컴파일러를 보낼 수 있습니다.CUDA 다운로드https://developer.nvidia.com/cuda-toolkit해당 사이트로 들어가 Download Now를 클릭 합니다.자신에게 맞는 Platform 을 선택합니다.저는 RHEL 8.5이기 때문에 아래와 같이 선택하엿습니다.선택을 하게 되면 아래와 같이 명령어가 나오게 됩니다.$ sudo dnf config-manager --add-repo https://developer.download.nvidia.com/compute/cuda/repos/rhel8/x86_64/cuda-rhel8.repo$ sudo dnf clean all$ sudo dnf -y module install nvidia-driver:latest-dkms$ sudo dnf -y install cudaCUDA 설치dnf에 해당 repository를 등록합니다.$ sudo dnf config-manager --add-repo https://developer.download.nvidia.com/compute/cuda/repos/rhel8/x86_64/cuda-rhel8.repoUpdating Subscription Management repositories.Adding repo from: https://developer.download.nvidia.com/compute/cuda/repos/rhel8/x86_64/cuda-rhel8.repodnf의 캐시를 제거합니다. 저는 19개의 패키지가 정리되었습니다.$ sudo dnf clean allUpdating Subscription Management repositories.19 files removed전 이전에 매뉴얼로 nvidia-driver를 설치하였기 때문에 아래의 명령어는 생략하도록 하겠습니다.$ sudo dnf -y module install nvidia-driver:latest-dkms 이제 CUDA를 설치합니다.$ sudo dnf -y install cuda모든 패키지 설치가 끝난 후 아래의 명령으로 CUDA가 정상적으로 설치가 되었는지 확인합니다.$ nvcc --version-bash: nvcc: command not found$ ls /usr/local/ | grep cudacudacuda-11cuda-11.6저의 경우 cuda-11.6이 정상적으로 설치가 되었지만 현재 계정에서 nvcc를 사용 할 수 없습니다.아래의 명령어를 통해 정상적으로 사용 할 수 있도록 설정합니다.$ sudo sh -c \"echo 'export PATH=$PATH:/usr/local/cuda-11.6/bin' &gt;&gt; /etc/profile\"$ sudo sh -c \"echo 'export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda-11.6/lib64' &gt;&gt; /etc/profile\"$ sudo sh -c \"echo 'export CUDADIR=/usr/local/cuda-11.6' &gt;&gt; /etc/profile\"$ source /etc/profile정상적으로 설정이 되었는지 확인합니다.$ nvcc --versionnvcc: NVIDIA (R) Cuda compiler driverCopyright (c) 2005-2022 NVIDIA CorporationBuilt on Tue_Mar__8_18:18:20_PST_2022Cuda compilation tools, release 11.6, V11.6.124Build cuda_11.6.r11.6/compiler.31057947_0CuDNN 설치https://developer.nvidia.com/rdp/cudnn-archive해당 사이트에서 tar로 되어 있는 파일로 설치하거나 rpm으로 받아 설치하는 방법이 있습니다.저는 tar 파일을 다운받아 설치하도록 하겠습니다.tar 설치Local Installer for Linux x86_64 (Tar) 파일을 다운 받아 리눅스 서버로 전송합니다.wget으로는 리눅스에서 직접 받아지지 않습니다.$ tar -xvf cudnn-linux-x86_64-8.3.2.44_cuda11.5-archive.tar.xz$ cd cudnn-linux-x86_64-8.3.2.44_cuda11.5-archive/$ sudo cp include/cudnn*.h /usr/local/cuda-11.6/include$ sudo cp lib/libcudnn* /usr/local/cuda-11.6/lib64sudo chmod a+r /usr/local/cuda-11.6/include/cudnn*.h /usr/local/cuda-11.6/lib64/libcudnn*" }, { "title": "FTP Active vs Passive", "url": "/posts/ftp/", "categories": "Infra, FTP", "tags": "FTP", "date": "2022-03-28 07:21:00 +0900", "snippet": "FTP(File Transfer Protocol)란FTP는 하나의 호스트에서 다른 호스트로 파일을 복사 하기위해 TCP/IP에 의해 제공되는 표준 기능이다.FTP 호스트 간에 두개의 연결을 설정한다는 점에서 다른 클라이언트 서버 응용들과 다르다. 이러한 제어와 데이터 전송의 분리는 FTP를 좀 더 효율적으로 사용할 수 있다.클라이언트와 서버가 Control Session을 맺고 dir, get, put등의 명령을 수행하면 실제 데이터를 전송할 Data Session을 생성한다.이 때 Active Mode냐 Passive Mode냐에 따라 통신 구조가 달라진다.Active 모드 FTP Client에서는 FTP Server의 21번 포트로 인증 요청을 한다. 그리고 Client 자신의 DATA 전송 포트번호(2223)를 패킷에 포함하여 서버에 전송한다. FTP Server에서는 FTP Client에게 OK 응답을 보낸다. FTP Server에서 생성한 20번 포트에서 -&gt; Client의 2223포트로 데이터 채널 연결을 요청한다. FTP Client는 Server에게 OK 응답을 보내고, 이로서 데이터 채널 연결까지 완료한다. Client PC에서 사용되는 포트번호 222, 2223은 PC에서 생성된 포트번호입니다. Client에서 생성되는 포트번호 “1024이상” 중에서 사용 가능한 임의의 포트로 사용됩니다. FTP의 21/tcp, 20/tcp는 사용자가 마음대로 설정 가능합니다. Passive Mode FTP Client에서는 FTP Server의 21 포트로 인증 요청을 한다. 그리고 Client 자신이 연결하려는 서비스가 Passive Mode로 연결 할 것임을 알린다. FTP Server에서는 FTP Client에게 OK 응답을 보낸다. 그리고 FTP Server는 데이터 채널 포트번호가 1025라는 것을 Client에게 알려준다. FTP Client에서 생성한 2223번 포트에서 -&gt; Server의 1025포트로 데이터채널 연결을 요청한다. FTP SErver는 Client에게 OK응답을 보내고, 이로서 데이터 채널 연결까지 완료한다. Client PC에서 사용되는 포트번호 222, 2223은 PC에서 생성된 포트번호입니다. Client에서 생성되는 포트번호 “1024이상” 중에서 사용 가능한 임의의 포트로 사용됩니다. FTP의 21/tcp, 20/tcp는 사용자가 마음대로 설정 가능합니다. Passive Mode에서는 데이터 채널 포트번호를 특별하게 지정하지 않을 경우, “1023 &lt; x &lt; 65536” 중에서 사용가능한 임의의 포트로 자동 사용된다. 방화벽 설정 주의Active ModeActive Mode에서는 데이터 채널 요청을 Server -&gt; Client 방향으로 접속 한다.그래서 Client PC에서 20번 포트가 차단되어 있을 경우 데이터 채널 연결이 불가능하다.따라서 Server에서는 20번 포트가 OUTPUT 방향으로 허용, Client에서는 20번 포트가 INPUT 방향으로 허용 되어야 한다.Passive ModePassive Mode는 데이터 채널 요청을 Client -&gt; Server 방향으로 접속 한다.그래서 Server에서 데이터채널 포트가 차단 되어있을 경우에는 데이터 채널 연결이 불가능하다.별도로 지정하지 않을 경우 Server에서 1023 &lt; x &lt; 65535 포트들을 INPUT방향으로 허용되어야 한다.Client PC에서는 1024~65534 범위를 모두 OUTPUT 방향으로 허용되어야 한다.언어별 Default 모드 C# : Passive Mode Java : Active Mode Python : Passive Mode참조 https://madplay.github.io/post/ftp-active-passive https://goitgo.tistory.com/37 https://www.omnisecu.com/tcpip/ftp-active-vs-passive-modes.php" }, { "title": "RHEL8.5 NVIDIA 설치", "url": "/posts/nvidia/", "categories": "DeepLearning", "tags": "RHEL, Setup, Linux, Nvidia Driver, CUDA", "date": "2022-03-26 06:04:00 +0900", "snippet": "이 글은 RHEL(Red Hat Enterprise Linux)에 Tensorflow를 설치하기 위한 글입니다.먼저 이전에 작성한 블로그를 참고하여 BIOS에서 보안부팅을 해제해야 합니다.RHEL 8.5에 NVIDIA 그래픽 드라이브 설치1. dnf 업데이트Red Hat 계열은 이전에는 yum을 사용했지만 현재는 dnf를 사용합니다.RHEL 최신 버전에서도 yum 사용이 가능하긴 합니다.$ sudo dnf -y update2. 필수 패키지 설치$ sudo dnf -y groupinstall \"Development Tools\"$ sudo dnf -y install elfutils-libelf-devel libglvnd-devel3. nouveau를 grub에서 비활성화grub 파일에서 GRUB_CMDLINE_LINUX 줄에 nouveau.modeset=0 추가합니다.$ sudo vi /etc/default/grubGRUB_TIMEOUT=5GRUB_DISTRIBUTOR=\"$(sed 's, release .*$,,g' /etc/system-release)\"GRUB_DEFAULT=savedGRUB_DISABLE_SUBMENU=trueGRUB_TERMINAL_OUTPUT=\"console\"GRUB_CMDLINE_LINUX=\"crashkernel=auto resume=UUID=8fb51673-7c37-4420-ae33-760e99d3d29d rd.lvm.lv=rhel/root rhgb quiet nouveau.modeset=0\"GRUB_DISABLE_RECOVERY=\"true\"GRUB_ENABLE_BLSCFG=true변경 된 grub 설정은 적용 합니다.sudo grub2-mkconfig -o /boot/grub2/grub.cfgsudo grub2-mkconfig -o /boot/efi/EFI/redhat/grub.cfg4. RHEL 서버를 재부팅 합니다.$ sudo reboot5. Xorg Server 중지Nvidia 드라이버를 설치 할 때는 반드시 Xorg Server가 내려가 있어야 합니다.그래서 테스트 모드로 전환 합니다.$ sudo systemctl isolate multi-user.target6. Nvidia 그래픽 카드 확인$ lspci -vnn | grep VGA01:00.0 VGA compatible controller [0300]: NVIDIA Corporation GP106 [GeForce GTX 1060 6GB] [10de:1c03] (rev a1) (prog-if 00 [VGA controller])7. 그래픽 드라이버 다운로드https://www.nvidia.com/Download/index.aspx위 경로에서 자신에게 맞는 그래픽 드라이버를 검색합니다.SEARCH 버튼을 누르게 되면 아래의 DOWNLOAD 화면까지 나오게 됩니다.저의 경우 RHEL 서버에 설치해야 하기 때문에 다운로드 경로를 복사하겠습니다.다운로드 버튼에서 마우스 오른쪽 키 후 링크 주소 복사를 누릅니다.$ sudo wget https://us.download.nvidia.com/XFree86/Linux-x86_64/510.60.02/NVIDIA-Linux-x86_64-510.60.02.run8. NVIDIA Driver 설치다운로드 받은 설치파일을 실행 시킵니다.$ sudo bash NVIDIA-Linux-x86_64-*위와 같이 선택 한 후 설치가 완료되면 nvidia-smi 명령어로 확인한다.$ nvidia-smiFri Mar 25 16:47:30 2022+-----------------------------------------------------------------------------+| NVIDIA-SMI 510.60.02 Driver Version: 510.60.02 CUDA Version: 11.6 ||-------------------------------+----------------------+----------------------+| GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC || Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. || | | MIG M. ||===============================+======================+======================|| 0 NVIDIA GeForce ... Off | 00000000:01:00.0 Off | N/A || 47% 39C P0 30W / 130W | 0MiB / 6144MiB | 0% Default || | | N/A |+-------------------------------+----------------------+----------------------++-----------------------------------------------------------------------------+| Processes: || GPU GI CI PID Type Process name GPU Memory || ID ID Usage ||=============================================================================|| No running processes found |+-----------------------------------------------------------------------------+" }, { "title": "RHEL(RedHat Enterprise Linux) 설치", "url": "/posts/RHEL/", "categories": "DeepLearning", "tags": "RHEL, Setup, Linux, CUDA", "date": "2022-03-26 05:04:00 +0900", "snippet": "이 글은 RHEL(Red Hat Enterprise Linux)에 Tensorflow를 설치하기 위한 글입니다.먼저 이전에 작성한 블로그를 참고하여 BIOS에서 보안부팅을 해제해야 합니다.RHEL iso 다운로드https://developers.redhat.com/products/rhel/downloadRHEL은 기존에는 한 사용자당 한 대의 소프트웨어 개발 목적으로만 한정되어 있었지만, 앞으로는 최대 16개의 프로덕션 환경에서 사용 할 수 있다.RHEL을 무료로 사용하려면 Individual Developer Subscription에 등록해야 하고 등록 비용은 발생하지 않는다.지금까지 개인 개발자만 대상으로 Red Hat Developer 프로그램을 제공하였으나 앞으로는 고객의 시스템을 개발하는 개발팀도 등록 가능하다.위 링크에서 iso 파일을 다운 받습니다.부팅 USB 만들기저는 Rufus를 사용하여 부팅 USB를 만들도록 하겠습니다.https://rufus.ie/ko/위 링크에서 다운 받은 후 실행 합니다. 장치에서 자신이 원하는 USB를 선택합니다. 선택 버튼을 클릭하여 다운로드 받은 iso 파일을 선택합니다. 시작 버튼을 클릭합니다.RHEL(Red Hat Enterprise Linux) 설치서버에 부팅 USB를 연결하고 전원 버튼을 누릅니다.저의 경우 메인보드가 ASUS 이기 때문에 F8을 누르면 부팅 메뉴가 나타납니다.여기서 자신의 USB를 선택 합니다. Install Red Hat Enterprise Linux 8.5를 선택 합니다. 저는 영어로 설치하기 위해 English로 선택 했습니다. 설치 메인 메뉴를 확인 할 수 있다. Time &amp; Date 메뉴에서 서울로 시간을 변경합니다. 먼저 Network를 활성화 하기 위해 Network &amp; Host Name을 클릭하여 활성화 시킨다. Root Password 메뉴에서 패스워드를 설정한다. Create User 메뉴에서 아이디와 암호를 지정한다. 또한 Make this user administrator를 체크하여 일반 계정으로 admin 권한을 사용 할 수 있도록 지정한다. Installation Destination 메뉴를 선택하여 파티션을 나눕니다.RHEL에서 파티션을 나누는 방법은 3가지가 있습니다. 종류 설명 Standard Partition 물리적은 볼륨을 여러개의 논리 드라이브로 나누는 리눅스의 일반적인 파티셔닝 방식 LVM 디스크를 표준파티션보다 더 효율적이고 유연하게 관리할 수 있는 방식으로 필요에 따라 사용자가 파티션 용량을 줄이거나 늘리는게 간단하고 여러 물리적 볼륨을 하나의 논리적 볼륨으로 묶을 수 있는 방식 LVM Thin Provisioning 디스크 저장공간의 낭비를 해결하기위해 나온 방식으로 볼륨에 특정 용량을 할당을 하더라도 사용하는 사용자가 할당받은 그 용량을 전부 사용하지 않고 일정부분 남겨둔다면 그 만큼 낭비가 발생하는 것이기 때문에 볼륨에 10gb의 용량을 할당을 한다고 하면 실제 할당한 크기는 10gb가 아니라 현재 사용자가 사용하는 만큼의 용량이고 디스크에 파일을 저장을 해서 용량이 늘어나면 그때마다 유동적으로 저장공간 크기가 늘어남 저는 Standard Patition으로 생성하도록 하겠습니다 전 총 20GB이기 때문에 아래와 같이 나눴습니다. 종류 설명 root 모든 리눅스 파일체제의 최상위 디렉토리 boot 부팅에 필요한 커널, 모듈 등이 존재하는 디렉토리 home 사용자의 홈 디렉토리가 위치하는 디렉토리 var 로그 및 사용자 데이터, 가변적인 데이터들이 저장되는 공간 swap 메모리 용량이 부족할 때 하드디스크 일정공간을 스왑메모리로 사용 biosboot GPT로 장치를 부팅하는데 필요한 파티션 끝난 후 좌측 상단의 Done을 클릭하여 끝냅니다. Installation Source의 경우 설치 시 Software를 Network로 설치하거나 iso에 포함 된 Software를 설치하거나 선택하는데 전 iso 포함이므로 설정하지 않겠습니다. Software Selection 버튼을 클릭하여 원하는 소프트웨어를 선택 합니다. 전 Server용도에 FTP Server만 있으면 되기 때문에 FTP만 선택하겠습니다. 이제 모든 셋팅이 끝났고 메인 메뉴에서 Begin Installation 버튼으로 설치를 시작합니다.설치가 끝나면 Rebbot System으로 시작합니다." }, { "title": "ASUS 보안 부팅 해제", "url": "/posts/asus_secure_boot/", "categories": "DeepLearning", "tags": "CUDA, Setup", "date": "2022-03-26 01:04:00 +0900", "snippet": "이 글은 RHEL(Red Hat Enterprise Linux)에 Tensorflow를 설치하기 위한 글입니다.먼저 NVIDIA를 Linux에 설치하기 위해서는 BIOS에서 보안부팅을 해제해야 합니다.ASUS SECURE BOOT 해제 서버 부팅 시 검은 화면에서 [DEL] 키 혹은 [F2] 키를 연타하게 되면 BIOS 부팅 메뉴에 진입 할 수 있습니다. 아래와 같은 BIOS 메인 메뉴에서 마우스로 우측 하단의 [Advanced Mode(F7)]를 클릭 하거나 F7 키를 누릅니다. [Boot] or [부팅]을 클릭 합니다. [Secure Boot] or [보안 부팅 메뉴]를 클릭합니다. [Secure Boot State] or [안전 부팅 상태]를 보시면 활성화가 되어 있는 것을 확인 할 수 있습니다. [Key Management] or [키 관리]를 클릭합니다. 키 관리 메뉴에서 [Clear Secure Boot Keys] or [안전 부팅 키 지우기] 메뉴를 클릭 후 [Yes]를 클릭합니다. [Secure Boot State] or [안전 부팅 상태]를 확인 후 [F10]키를 눌러 [Save &amp; reset] 창이 뜨면 [OK]를 클릭 합니다.이미지 출처 https://blog.naver.com/tolikeu/222292344943" }, { "title": "docker-compose 작성 시 환경 변수 지정", "url": "/posts/Environment/", "categories": "Docker, docker-compose", "tags": "Docker, Postgres", "date": "2022-03-25 08:46:00 +0900", "snippet": "개요docker-compose는 IT 관리자가 여러 개의 컨테이너를 한번의 명령으로 실행 시키기 위해 정의해 놓은 파일을 실행시키는 툴입니다.이때 IT 관리자가 정의 되어 있는 파일을 수정하지 않고 환경 변수를 통해 재사용 할 수 있습니다.이때 환경변수를 정의하기 위해 사용하는 파일이 환경 변수 파일 입니다.설명아래와 같은 Postgres 컨테이너를 띄우기 위한 docker-compose 파일이 있다.services: postgres: image: postgres:13 container_name: postgres ports: - '5432:5432' environment: - POSTGRES_PASSWORD=pw1234여기서 Postgres의 암호는 pw1234로 정의 되어 있다.하지만 비밀번호를 변경하기 위해서는 docker-compose.yml 파일을 수정해야 한다.위에는 서비스가 1개여서 복잡하지 않지만 서비스가 굉장히 많을 때는 실수가 생기기 마련이다.이 때 .env 파일을 생성하여 환경변수로 비밀번호를 지정 할 수 있다.docker-compose와 동일 레벨에 있을 때는 따로 옵션을 주지 않아도 되지만 파일 경로를 지정하고 싶을 때는 --env-file 옵션을 사용하면 된다.환경변수 파일 사용아래와 같이 파일을 구성한다.postgres(Directory)└─.env└─docker-copmose.yml아래와 같이 docker-compose.yml 파일에 환경변수를 사용하도록 수정한다.services: postgres: image: postgres:13 container_name: postgres ports: - '5432:5432' environment: - POSTGRES_PASSWORD=${PASSWD}그리고 아래와 같이 .env 파일을 작성한다.PASSWD=pw1234그리고 docker-compose up로 실행시키면 된다.예제example.zip" }, { "title": "값 객체란?", "url": "/posts/DDD_Ch2/", "categories": "DDD, 도메인 주도 설계 철저 입문", "tags": "DDD", "date": "2022-03-25 08:26:00 +0900", "snippet": "1. 값 객체란?프로그래밍 언어에는 원시 데이터 타입이 있다. 이 원시 데이터 타입만 사용해 시스템을 개발 할 수 있지만, 때로는 시스템 특유의 값을 정의해야 한다.이러한 시스템 특유의 값을 표현하기 위해 정의하는 객체를 값 객체라고 한다.var fullName = \"naruse masanodu\";Console.WriteLine(fullName);&gt; naruse masanodu위에서는 성명인 naruse masanodu을 출력 하지만 여기서 성씨만 출력을 해야 한다고 하면 어떻게 되는가?var fullName = \"naruse masanodu\";var tokens = fullName.Split(' ');var lastName = tokens[0];Console.WriteLine(lastName);&gt; naruse위와 같이 fullName에서 성씨 부분만 떼어내 출력해야 한다.하지만 여기서 john smith의 경우는 어떻게 되는가? john smith의 성은 smith이기 때문에 위 로직에는 문제가 있다.그래서 우리는 이러한 문제를 해결하기 위해 일반적으로 클래스를 사용한다.class FullName{ public string FirstName { get; } public string LastName { get; } public FullName(string firstName, string lastName) { FirstName = firstName; LastName = lastName; }}var fullName = new FullName(\"masanobu\", \"naruse\");Console.WriteLine(fullName.LastName);&gt; naruse변수 fullName은 이름 그대로 성명을 나타내는 객체로, 값을 표현한다.도메인 주도 설계에서 말하는 값 객체는 이렇듯 시스템 특유의 값을 나타내는 객체이다.2. 값의 성질과 값 객체 구현 값의 성질 변하지 않는다. 주고 받을 수 있다. 등가성을 비교 할 수 있다. 2.1 값의 불변성var greet = \"안녕하세요.\";Console.WriteLine(greet); // '안녕하세요' 출력geet = \"Hello\";Console.WriteLine(greet); // Hello 가 출력우리가 일반적으로 값을 수정하는 방법이다. 우리는 값을 수정 할 때 새로운 값을 대입한다.사실 대입은 값을 수정하는 과정이 아니며 수정 된 것은 변수의 내용이지, 값 자체가 수정 되는 것은 아니다.쉽게 생각하면 영수증을 떠올리면 된다.우리는 물건을 사고 영수증을 받는데 영수증에 값이 잘 못 찍혔을 때, 영수증을 새로 발급 받지 이미 받은 영수증을 수정하지 않는다.var fullName = new FullName(\"masanobu\", \"naruse\");fullName.ChangeLastName(\"sato\");개발자들은 위 코드를 자연스럽게 생각할 것이다. 하지만 FullName 클래스를 값으로 생각하면 부자연스러운 부분이 생긴다.바로 값이 수정 됐기 때문이다.FullName은 시스템 특유의 값을 표현하는 객체이므로 변하지 않아야 한다. 그러므로 ChangeLastName 같은 메서드는 존재해서는 안된다.2.2 교환 가능하다.값은 불변이다. 그러므로 값 객체의 수정 역시 대입문을 통해 이루어져야 한다.var fullName = new FullName(\"masanobu\", \"naruse\");fullName = new FullName(\"masanobu\", \"sato\");2.3 등가성 비교 가능시스템 고유의 값인 값 객체는 구성하는 속성(인스턴스 변수)을 통해 비교가 가능해야 한다.var nameA = new FullName(\"masanobu\", \"naruse\");var nameB = new FullName(\"john\", \"smith\");var compareResult = nameA.FirstName == nameB.FirstName &amp;&amp; nameA.LastName == nameB.LastName;Console.WriteLine(compareResult);위와 같이 값 객체의 속성을 꺼내 비교하는 코드는 틀린점이 없고 자연스러워 보이지만 FullName 객체가 값이라고 생각하면 아래와 같이 부자연스러운 코드다.Console.WriteLine(1.Value == 0.Value); //false?값 객체는 시스템 고유의 값이다. 따라서 값의 속성을 꺼내 비교하는 것이 아니라, 직접 값끼리 비교해야 자연스럽다.var nameA = new FullName(\"masanobu\", \"naruse\");var nameB = new FullName(\"john\", \"smith\");var compareResult = nameA.equals(nameB);Console.WriteLine(compareResult);이렇게 값 객체 내부에서 비교 메서드를 제공하면 한곳만 수정하면 되기 때문에 변화에 쉽게 반응 할 수 있다.예를 들어 MiddleName을 추가해야 한다면 코드 곳곳에 숨겨진 비교 부분을 찾지 않고 값 객체 내부의 Equals 메서드만 수정하면 된다.3. 값 객체가 되기 위한 기준현재 FullName 클래스를 구성하는 firstName이나 lastName 등의 속성은 원시타입인 문자열로 되어 있다.아래의 코드는 가능한 모든 속성을 값 객체로 만든 FullName 클래스이다.class FullName : IEquatable&lt;FullName&gt;{ private readonly FirstName firstName; private readonly LastName lastName; public FullName(FirstName firstName, LastName lastName) { this.firstName = fitstName; this.lastName = lastName }}class FirstName{ private readonly string value; public FirstName(string value) { if(string.IsNullOrEmpty(value)) throw new ArgumentException(\"최소 한글자 이상이여야 함.\", nameof(value)); this.value = value; }}class LastName{ private readonly string value; public LastName(string value) { if(string.IsNullOrEmpty(value)) throw new ArgumentException(\"최소 한글자 이상이여야 함.\", nameof(value)); this.value = value; }}위 코드를 보고 지나치다라고 생각 할 수도 있다. 하지만 firstName과 lastName에 조건이 들어 갈 때는 좀 더 복잡해 진다.class FullName : IEquatable&lt;FullName&gt;{ private readonly string firstName; private readonly string lastName; public FullName(string firstName, string lastName) { if(firstName == null) throw new ArgumentNullException(nameof(firstName)); if(lastName == null) throw new ArgumentNullException(nameof(lastName)); if(ValidateName(firstName)) throw new ArgumentException(\"허가되지 않은 문자 사용됨.\", nameof(value)); if(ValidateName(lastName)) throw new ArgumentException(\"허가되지 않은 문자 사용됨.\", nameof(value)); this.firstName = fitstName; this.lastName = lastName } private bool ValidateName(string value) { return Regex.IsMatch(value, @\"^[a-zA-Z]+$\"); }}위와 같이 원시타입아라도 인자를 전달 받는 시점에서 검사하면 규칙을 강제할 수 있다.물론 값 객체로 정의해도 문제는 없다. 하지만 성과 이름을 따로 다룰 필요가 없다면 하나의 타입으로 다룰 수도 있다.class Name{ private readonly string value; public Name(string value) { if(value == null) throw new ArgumentNullException(nameof(value)); if(!Regex.IsMatch(value, @\"^[a-zA-Z]+$\")) throw new ArgumentException(\"허가되지 않은 문자 사용됨.\", nameof(value)); this.value = value; }}class FullName{ private readonly Name firstName; private readonly Name lastName; public FullName(Name firstName, Name lastName) { if(firstName == null) throw new ArgumentNullException(nameof(firstName)); if(lastName == null) throw new ArgumentNullException(nameof(lastName)); this.firstName = firstName; this.lastName = lastName; }}4. 행동이 정의 된 값 객체값 객체는 독자적인 행위를 정의 할 수 있다. 값 객체는 데이터만 저장하는 컨테이너가 아니라 행동을 가질 수도 있는 객체이다.class Money{ private readonly decimal amount; private readonly string currency; (... 생략 ...) public Money Add(Money arg) { if(arg == null) throw new ArgumentNullException(nameof(arg)); if(currency != arg.currency) throw new ArgumentException($\"화폐 단위가 다름 (this:{currency}, arg:{arg.currency})\"); return new Money(amount + arg.amount, currency); }}돈을 더하려면 화폐의 단위가 일치해야 하므로 조건을 추가한다.또한 값 객체는 불변이므로 계산된 결과는 새로운 인스턴스로 반환한다.5. 값 객체를 도입 했을 때의 장점 표현력이 증가한다. 무결성이 유지된다. 잘못된 대입을 방지한다. 로직이 코드 이곳저곳에 흩어지는 것을 방지한다.5.1 표현력의 증가var modelNumber = \"a20421-100-1\";위 제품번호는 원시타입으로 나타내기 때문에 각각 어떤 것을 의미하고 있는지 알 수가 없다.class ModelNumber{ private readonly string productCode; private readonly string branch; private readonly string lot; (... 생략 ...) public override string ToString() { return productCode + \"-\" + branch + \"-\" + lot; }}ModelNumber 클래스의 정의를 보면 제품번호가 제품코드(productCode)와 지점번호(branch), 로트번호(lot)으로 구성되는 것을 알 수 있다.값 객체는 자기 정의를 통해 자신이 무엇인지에 대한 정보를 제공하는 자기 문서화를 돕는다.5.2 무결성의 유지만약 사용자 명이 3글자 이상이여야 한다는 조건이 붙으면, 아래와 같이 두 글자 일 때는 따로 if문으로 비교를 해서 처리를 계속하야 한다.var userName = \"me\"if(userName.Length &gt;= 3){ // 유효 하므로 계속 진행}else{ throw new Exception(\"유효하지 않은 값\");}값의 유효성을 매번 확인 할 수는 있지만 이 if문 조건은 코드 이곳저곳 흩어지게 된다.값 객체 내부에 조건을 추가하면 값 객체만 수정하면 되므로 유효하지 않은 값을 걱정 할 필요가 없다.5.3 잘못된 대입 방지하기개발자라면 대입문을 잘 못 사용한 적이 많을 것이다.User CreateUser(string name){ var user = new User(); user.Id = name; return user;}위 코드는 Id에 name을 넣어 버리는 오류를 범했다.class User{ public UserId Id {get; set;} public UserName Name {get; set;}}User CreateUser(UserName name){ var user = new User(); user.Id = name; // 컴파일 에러 발생 return user;}값 객체를 정의하여 사용하면 IDE가 이러한 에러는 컴파일에서 잡아 낼 수 있다.5.4 로직을 한곳에 모아두기코드의 중복이 많아지면 코드를 수정하는 난이도가 급상승하게 된다.아래의 코드는 User를 생성하는 곳과 수정하는 곳의 중복 코드가 들어가게 된다.void CreateUser(string name){ if(name == null) throw new ArgumentNullException(nameof(name)); if(name.Length &lt; 3) throw new ArgumentException(\"3글자 이상이어야 함.\", nameof(name)); (... 생략 ...)}void UpdateUser(string id, string name){ if(name == null) throw new ArgumentNullException(nameof(name)); if(name.Length &lt; 3) throw new ArgumentException(\"3글자 이상이어야 함.\", nameof(name)); (... 생략 ...)}이 처럼 같은 조건을 확인해야 하는 코드 일 경우 값 객체를 활용하면 로직을 한 곳에 모을 수 있다.class UserName{ private readonly string value; public UserName(string value) { if(value == null) throw new ArgumentNullException(nameof(value)); if(value.Length &lt; 3) throw new ArgumentException(\"3글자 이상이어야 함.\", nameof(value)); this.value = value; }}void CreateUser(string name){ var userName = new UserName(name); var user = new User(userName);}void UpdateUser(string id, string name){ var userName = new UserName(name);}참고C# 9.0부터 record 형식이 도입 되었습니다. https://docs.microsoft.com/ko-kr/dotnet/csharp/whats-new/csharp-9record의 경우 불변성, 값 비교, with문을 통한 새로운 인스턴스 생성 등 값 객체에 가장 적합한 타입으로 보입니다.고민값 객체를 Interface로 만들 필요가 있는가? 값 객체는 원시 데이터 만큼 시스템의 가장 아래에 위치하는 도메인 객체로 보여집니다. 값 객체에는 특별한 로직이 들어가지 않을 것으로 보이는데 만약 비슷한 값 객체를 만들어야 한다면 Interface로 만들어야 하나? 아님 코드 중복을 감수하더라도 따로 만들어야 하는가?값 객체의 단위 테스트 값 객체의 경우 특별한 로직이 들어가지 않을 것으로 보입니다. 값 객체 하나하나 단위 테스트를 하게 된다면 많은 리소스가 필요 할 것으로 보이는데 값 객체도 단위 테스트를 하는 것이 좋은가?" }, { "title": "도메인 주도 설계란?", "url": "/posts/DDD_Ch1/", "categories": "DDD, 도메인 주도 설계 철저 입문", "tags": "DDD", "date": "2022-03-25 08:15:00 +0900", "snippet": "1 도메인 주도 설계란 무엇인가?개발자는 소프트웨어 이용자의 세계에 대해 기본적으로 무지하다.그래서 개발자는 유용한 소프트웨어를 만들기 위해 이용자의 문제가 무엇인지 파악하고, 이를 해결할 수 있는 최선의 수단을 생각해야 한다.[+도메인 주도 설계는 이러한 고찰을 반복하는 설계를 통해 이용자의 세계와 소프트웨어 구현을 연결 짓는 것이 목적이다.+]2 도메인 지식에 초점을 맞춘 설계 기법도메인이란 무엇인가? 도메인은 영역이란 뜻이다. 특히 소프트웨어 개발에서 말하는 도메인은 프로그램이 쓰이는 대상 분야라는 의미로 쓰인다.예를 들어 회계 시스템에서 도메인은 금전 혹은 장부 같은 개념이다.그리고 물류 시스템에서는 화물이나 창고, 운송수단 등의 개념이 도메인에 속한다.소프트웨어에는 반드시 이용자가 있고 소프트웨어의 목적은 도메인에서 이용자들이 직면한 문제를 해결해야 한다. 이용자의 문제를 해결하기 위해서는 개발자는 이용자의 문제를 정확히 이해 해야 한다.2.1 도메인 모델링이란 무엇인가?모델은 현실에서 일어나는 사건 혹은 개념을 추상화한 개념이다. 추상이란 여러 사물 혹은 개념에서 공통적인 것을 뽑아 파악하는 것이다.예를 들어, 트럭은 화물을 나를 수 있다.는 성질만 표현해도 충분하다. 차 키를 돌리면 엔진에 시동이 걸린다.와 같은 정보까지 나타낼 필요는 없다.이렇게 사건 혹은 개념을 추상화 하는 작업을 모델링이라고 한다.2.2 지식을 코드로 나타내는 도메인 객체소프트웨어 이용자의 요구사항은 바뀌기 쉽고, 시간에 따라 변화하기 쉽다. 이럴 때 도메인 객체가 도메인 모델을 충분히 반영하고 있다면 도메인의 변화를 코드로 쉽게 옮길 수 있다.도메인 개념의 변화는 도메인 객체까지 연쇄적으로 전달 된다.반대로, 도메인 객체가 도메인의 대한 태도를 변화시키는 경우도 있는데, 이는 도메인 개념이 어중간하면 프로그램에 의해 도메인 개념이 변화 할 수도 있다.이 처럼 서로 영향을 주고 받으면 반복적으로 개발되어야 한다.flowchart LR; id1((도메인 개념)) id2((도메인 모델)) id3((도메인 객체)) id1 &lt;--&gt; id2 id2 &lt;--&gt; id33. 도메인 주도 설계의 대표적인 패턴graph LR linkStyle default interpolate basissubgraph 네비게이션맵 MDD((Model-Driven-Design)) SV((SERVICE)) SUI((Smart UI)) ENT((ENTITY)) VO((VALUE OBJECT)) LA((LAYERED ARCHITECTURE)) RP((REPOSITORY)) AG((AGGREGATE)) FT((FACTORY)) MDD -- 모델을 표현하는 데 활용 --&gt; SV MDD -- 모델을 표현하는 데 활용 --&gt; ENT MDD -- 모델을 표현하는 데 활용 --&gt; VO MDD -- 모델을 격리하는 데 활용 --&gt; LA MDD -- 상호배타적인 선택 --&gt; SUI ENT -- 접근하는 데 활용 --&gt; RP ENT -- 무결성을 유지하는 데 활용 --&gt; AG ENT -- 루트 역할을 함 --&gt; AG ENT -- 캡슐화하는데 활용 --&gt; FT VO -- 캡슐화하는데 활용 --&gt; AG VO -- 캡슐화하는데 활용 --&gt; FT AG -- 접근하는 데 활용 --&gt; RP AG -- 캡슐화하는데 활용 --&gt; FTend 지식을 표현하기 위한 패턴 값 객체(Value Object) 엔티티(Entity) 도메인 서비스(Domain Service) 애플리케이션을 구성하는 패턴 리포지토리(Repository) 애플리케이션 서비스(Application Service) 팩토리(Factory) 지식 표현을 위한 고급 패턴 애그리게이트(Aggregate) 명세(Satisfied) " }, { "title": "TorchServe 맛보기", "url": "/posts/TorchServe/", "categories": "DeepLearning, PyTorch, TorchServe", "tags": "PyTorch, TorchServe", "date": "2022-03-23 07:04:00 +0900", "snippet": "TorchServe 맛보기TorchServe를 간단히 시작하기 위한 정리입니다.pytorch/serve에서 제공해주는 학습 모델을 사용하여 RestApi로 추론하는 방법입니다.Torchserve는 Docker 이미지를 사용합니다.참고https://github.com/pytorch/serve/tree/master/examples/image_classifier/densenet_161모델압축모델을 학습하게 되면 로컬에 pth 파일이 생성이 됩니다. 이 모델 파일을 그대로 TorchServe에서는 사용 할 수 없기 때문에 먼저 Training이 끝난 모델을 압축해야 합니다.densenet161 학습 모델 다운로드model.pyTorchServe에서 제공해주는 모델을 다운로드 받습니다.저는 D:\\save_model 경로에 넣어두겠습니다.로컬 경로와 pytorch/torchserve 컨테이너의 볼륨을 -v 옵션으로 마운트 후 컨테이너를 실행 시킵니다.&gt; docker run --rm -it -v D:\\save_model:/models/model pytorch/torchserve bash 옵션 설명 –rm 컨테이너가 내려가면 바로 컨테이너 삭제 -it -i와 -t를 동시에 사용해 컨테이너 터미널에 붙어 명령어를 사용가능하다. -v 호스트의 로컬과 컨테이너의 디렉터리를 연결한다(마운트) bash -it를 사용하기 위해 마지막 bash 명령을 실행시킵니다. 컨테이너를 실행 후 컨테이너 안에서 아래의 명령어를 실행합니다.$ torch-model-archiver --model-name densenet161 --version 1.0 --model-file /models/model/model.py --serialized-file /models/model/densenet161-8d451a50.pth --export-path /models/model/ --handler image_classifier 옵션 설명 –model-name 모델이름 모델이름으로 mar 파일이 생성됩니다. –version 1.0 버전 정보 –model-file state_dict을 포함하는 .pth의 경우 사용합니다. –serialized-file .pt 또는 .pth 파일 위치 –export-path mar 파일 생성 위치 –handler data가 들어왔을 때 전처리/추론/후처리를 관리하는 파일 커스텀으로 생성이 가능합니다. D:\\save_model에 densenet161.mar 파일이 생성됐다면 준비는 다 끝난겁니다.TorchServe 실행이제 Inference Serving을 하기 위해 다시 컨테이너를 띄웁니다.&gt; docker run --rm -p 8080:8080 -p 8081:8081 -v D:\\save_model\\:/tmp/models pytorch/torchserve torchserve --model-store=/tmp/models/ --models /tmp/models/densenet161.marTorchserve version: 0.5.3TS Home: /home/venv/lib/python3.8/site-packagesCurrent directory: /home/model-serverTemp directory: /home/model-server/tmpNumber of GPUs: 0Number of CPUs: 16Max heap size: 6384 MPython executable: /home/venv/bin/pythonConfig file: config.propertiesInference address: http://0.0.0.0:8080Management address: http://0.0.0.0:8081Metrics address: http://0.0.0.0:8082Model Store: /tmp/modelsInitial Models: /tmp/models/densenet161.marLog dir: /home/model-server/logsMetrics dir: /home/model-server/logsNetty threads: 32Netty client threads: 0Default workers per model: 16Blacklist Regex: N/AMaximum Response Size: 6553500Maximum Request Size: 6553500Limit Maximum Image Pixels: truePrefer direct buffer: falseAllowed Urls: [file://.*|http(s)?://.*]Custom python dependency for model allowed: falseMetrics report format: prometheusEnable metrics API: trueWorkflow Store: /tmp/modelsModel config: N/A2022-03-22T01:53:50,124 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: /tmp/models/densenet161.mar위와 같은 로그가 찍히면 정상적으로 컨테이너 실행이 된 상태입니다.http://localhost:8080/ping{ \"status\": \"Healthy\"}위 경로에서 추론 서버의 상태 체크가 가능합니다.http://localhost:8080/predictions/densenet161{ \"code\": 503, \"type\": \"InternalServerException\", \"message\": \"Prediction failed\"}모델 경로로 들어가면 예측이 실패 했지만 정상적으로 동작하는 것을 확인 할 수 있습니다.REST API 추론추론 할 이미지 다운로드해당 이미지를 추론하게 되면 0 이 나와야 합니다.import jsonimport requestsimport numpy as npimport cv2from PIL import Imagefrom io import BytesIOdef preprocess(img_path_or_buf): # Check whether image is a path or a buffer raw_image = ( Image.fromarray(cv2.imread(img_path_or_buf)) if isinstance(img_path_or_buf, str) else img_path_or_buf ) # If buffer was np.array instead of PIL.Image, transform it if type(raw_image) == np.ndarray: raw_image = Image.fromarray(raw_image) raw_image = raw_image.convert(\"RGB\") raw_image_bytes = BytesIO() raw_image.save(raw_image_bytes, format=\"PNG\") raw_image_bytes.seek(0) return raw_image_bytes.read()data = preprocess('test_data/torch_dataset/kitten.jpg')headers = {\"content-type\": \"image/png\"}url = \"http://localhost:8080/predictions/densenet161\"response = requests.post(url, data=data, headers=headers)predictions = json.loads(response.text)print('실제 값 : {} / 예측 값 : {}'.format('0', np.argmax(predictions)))해당 파이썬 코드는 로컬의 이미지를 읽어 byte로 변경해 RESTAPI 경로로 보내 예측값을 가져오는 코드입니다.실제 값 : 0 / 예측 값 : 0" } ]
